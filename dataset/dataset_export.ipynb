{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset export\n",
    "Gather all independent JSON files into a big single one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ref = Path(\"10-ner_ref/all_with_nested_ner_2023.json\")\n",
    "path_pero = Path(\"31-ner_align_pero/all.json\")\n",
    "path_tess = Path(\"32-ner_align_tess/all.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: Path) -> list:\n",
    "    with open(filename, mode='r', encoding=\"utf8\") as file_in:\n",
    "        return json.load(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref, data_pero, data_tess = [load_data(filename) for filename in (path_ref, path_pero, path_tess)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8772, 8765, 8765)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_ref), len(data_pero), len(data_tess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataset parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parts = {\n",
    "    \"pero\": data_pero,\n",
    "    \"tess\": data_tess,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(data_ref: list, dataset_parts: dict[str, list]) -> list:\n",
    "    \"\"\"Merge several dataset parts together.\n",
    "\n",
    "    Args:\n",
    "        data_ref (list): base dataset to join on\n",
    "        dataset_parts (dict[str, list]): name -> entries\n",
    "\n",
    "    Returns:\n",
    "        list: merged parts\n",
    "    \"\"\"\n",
    "    # Keep only elements with valid content (filters 7 buggy entries)\n",
    "    result = [e for e in data_ref if e[\"valid_box\"]]\n",
    "    # Rename keys for text_ocr and nested_ner_xml\n",
    "    for e in result:\n",
    "        e[\"nested_ner_xml_ref\"] = e[\"nested_ner_xml\"]\n",
    "        del e[\"nested_ner_xml\"]\n",
    "        e[\"text_ocr_ref\"] = e[\"text_ocr\"]\n",
    "        del e[\"text_ocr\"]\n",
    "        # delete flat reference from original dataset (not the one used for evaluation here)\n",
    "        del e[\"ner_xml\"]\n",
    "    # Build fast access index\n",
    "    ref_index = {(e[\"book\"], e[\"page\"], e[\"id\"]):e for e in result}\n",
    "    for name, data in dataset_parts.items():\n",
    "        for e2 in data:\n",
    "            e1 = ref_index[e2[\"book\"], e2[\"page\"], e2[\"id\"]]\n",
    "            for field in (\"text_ocr\", \"nested_ner_xml\", \"has_valid_ner_xml\"):\n",
    "                e1[f\"{field}_{name}\"] = e2[field]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = merge_datasets(data_ref, dataset_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8765"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 286,\n",
       " 'box': [127.59990697081633,\n",
       "  319.9430680456292,\n",
       "  385.6102733261905,\n",
       "  38.49245993571395],\n",
       " 'book': 'Bottin1_1820',\n",
       " 'page': 107,\n",
       " 'valid_box': True,\n",
       " 'nested_ner_xml_ref': \"<PER>Dufan et Clémendot</PER>, <ACT>pharmaciens</ACT>, <SPAT><LOC>r. de la\\u2029Chaussée-d'Antin</LOC>, <CARDINAL>34</CARDINAL></SPAT>. <TITRE>(Elig.)</TITRE> 449\",\n",
       " 'text_ocr_ref': \"Dufan et Clémendot, pharmaciens, r. de la\\nChaussée-d'Antin, 34. (Elig.) 449\",\n",
       " 'text_ocr_pero': 'Dufau et Clémendot, pharmaciens, r. de la\\nChäussee-d Antin.\\n\\n. JEII',\n",
       " 'nested_ner_xml_pero': '<PER>Dufau et Clémendot</PER>, <ACT>pharmaciens</ACT>, <SPAT><LOC>r. de la\\u2029Chäussee-d Antin</LOC>.\\u2029<CARDINAL>\\u2029</CARDINAL></SPAT>. <TITRE>JEII</TITRE>',\n",
       " 'has_valid_ner_xml_pero': False,\n",
       " 'text_ocr_tess': \"Dafan et Glémendot ; pharmaciens ; +. de la\\nChäussée-d'Antin . 32. (Elis.) .hl&\",\n",
       " 'nested_ner_xml_tess': '<PER>Dafan et Glémendot</PER> ; <ACT>pharmaciens</ACT> ; <SPAT><LOC>+. de la\\u2029Chäussée-d&apos;Antin</LOC> . <CARDINAL>32</CARDINAL></SPAT>. <TITRE>(Elis.)</TITRE> .hl&amp;',\n",
       " 'has_valid_ner_xml_tess': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check on XML escaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for insolated \"&\" not in XML entity\n",
    "PAT_ERR = r\"&(?!(apos|quot|gt|lt|amp);)\" \n",
    "def check_xml_entities(dataset: list):\n",
    "    for e in dataset:\n",
    "        for key in (\"nested_ner_xml_ref\", \"nested_ner_xml_pero\", \"nested_ner_xml_tess\"):\n",
    "            content = e[key]\n",
    "            # if \"\\\"\" in content:\n",
    "            #     print(\"ERROR: quote in entry:\")\n",
    "            #     print(e)\n",
    "            #     break\n",
    "            if re.match(PAT_ERR, content):\n",
    "                print(\"ERROR: unescaped XML special char in entry:\")\n",
    "                print(e)\n",
    "                break\n",
    "    print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "check_xml_entities(dataset_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"dataset_full.json\"\n",
    "with open(OUTPUT_FILE, mode=\"w\", encoding=\"utf8\") as out_file:\n",
    "    json.dump(dataset_full, out_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
