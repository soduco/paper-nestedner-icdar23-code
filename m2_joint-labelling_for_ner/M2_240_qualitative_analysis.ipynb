{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda9d76b",
   "metadata": {},
   "source": [
    "# 240 : Qualitative analysis using M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f29f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53ce29-cd5f-4295-ac93-2677c2d07034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset_ICDAR\"\n",
    "  OUT_BASE = BASE / \"res_ICDAR/method_2\"\n",
    "else:\n",
    "  BASE = Path().resolve() # Directory of this approach\n",
    "  #Adapt this to your situation\n",
    "  DATASETS = Path('../dataset_ICDAR').resolve() #Where your data are located befor Dataset object creation\n",
    "  OUT_BASE = Path('../res_ICDAR/method_2').resolve() #Where you save the results of this notebook\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2021c2a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037c5c2",
   "metadata": {},
   "source": [
    "Choose a fine-tuned model to perform qualitative analysis. Load models from the HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['m2_joint_label_ref_cmbert_io',\n",
    " 'm2_joint_label_ref_ptrn_cmbert_io',\n",
    " 'm2_joint_label_ref_cmbert_iob2',\n",
    " 'm2_joint_label_ref_ptrn_cmbert_iob2',\n",
    " 'm2_joint_label_ocr_cmbert_io',\n",
    " 'm2_joint_label_ocr_ptrn_cmbert_io',\n",
    " 'm2_joint_label_ocr_cmbert_iob2',\n",
    " 'm2_joint_label_ocr_ptrn_cmbert_iob2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf87a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = widgets.RadioButtons(\n",
    "            options=models,\n",
    "            layout={'width': 'max-content'}\n",
    "        )\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43af0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = model_name.value\n",
    "FORMAT = 'IO'\n",
    "\n",
    "if 'ref' in MODEL:\n",
    "    SET = \"ref\"\n",
    "elif 'ocr' in MODEL:\n",
    "    SET = \"ocr\"\n",
    "\n",
    "if 'ptrn' in MODEL:\n",
    "    MODEL_TYPE = 'pretrained_camembert_ner'\n",
    "else:\n",
    "    MODEL_TYPE = 'camembert_ner'\n",
    "    \n",
    "if 'm2_joint_label_ref_cmbert_io' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ref_cmbert_io'\n",
    "elif 'm2_joint_label_ref_ptrn_cmbert_io' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ref_ptrn_cmbert_io'\n",
    "elif 'm2_joint_label_ref_cmbert_iob2' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ref_cmbert_iob2'\n",
    "elif 'm2_joint_label_ref_ptrn_cmbert_iob2' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ref_ptrn_cmbert_iob2'\n",
    "elif 'm2_joint_label_ocr_cmbert_io' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ocr_cmbert_io'\n",
    "elif 'm2_joint_label_ocr_ptrn_cmbert_io' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ocr_ptrn_cmbert_io'\n",
    "elif 'm2_joint_label_ocr_cmbert_iob2' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ocr_cmbert_iob2'\n",
    "elif 'm2_joint_label_ocr_ptrn_cmbert_iob2' in MODEL:\n",
    "    DATASET = 'm2m3_qualitative_analysis_ocr_ptrn_cmbert_iob2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb597f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299fc2c1",
   "metadata": {},
   "source": [
    "### Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa81965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "from datasets import load_dataset\n",
    "\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "train_dev_test = load_dataset('nlpso/' + DATASET)\n",
    "test = train_dev_test[\"test\"]\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741d14e",
   "metadata": {},
   "source": [
    "### Non-structured entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"{DATASETS}/qualitative_analysis/test_entries_{SET}.txt\"\n",
    "with open(PATH, 'r',encoding='utf8') as ex:\n",
    "    lines = ex.read()\n",
    "    lines = lines.split('\\n')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba547f",
   "metadata": {},
   "source": [
    "## Use model on entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline\n",
    "\n",
    "LIMIT = 100\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlpso/' + MODEL) #Param : tokenizer du modele souhaité\n",
    "model = AutoModelForTokenClassification.from_pretrained('nlpso/' + MODEL) #Modèle choisi\n",
    "\n",
    "#Classification des entités\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=None, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da614f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xmlize_util import get_NER_tags\n",
    "if FORMAT == \"IOB2\":\n",
    "    from camembert_utils.util_IOB2 import word_tokens_from_nested_xml_iob2\n",
    "else:\n",
    "    from camembert_utils.util_IO import word_tokens_from_nested_xml\n",
    "from xmlize_util import get_NER_tags, xmlize_multilevel\n",
    "\n",
    "stats = []\n",
    "k = 0 \n",
    "errors_count = 0\n",
    "errors = []\n",
    "for i in range(len(lines)):\n",
    "    print(lines[i])\n",
    "    res = nlp(lines[i])\n",
    "    preds_tokens, preds_tags = [],[]\n",
    "\n",
    "    for e in res:\n",
    "        preds_tokens.append(e[\"word\"])\n",
    "        preds_tags.append(e['entity'])\n",
    "    levels, num_levels = get_NER_tags(lines[i],res,FORMAT)\n",
    "    xml = xmlize_multilevel(levels,num_levels)\n",
    "\n",
    "    try:\n",
    "        assert len(test[i][\"tokens\"]) == len(preds_tokens)\n",
    "        assert len(test[i][\"ner_tags\"]) == len(preds_tags)\n",
    "        stats.append([k,lines[i],xml,test[i][\"tokens\"],test[i][\"ner_tags\"],preds_tokens,preds_tags])\n",
    "    except:\n",
    "        errors_count += 1\n",
    "        print(test[i][\"tokens\"])\n",
    "        print(preds_tokens)\n",
    "        print(\"NUM \" + str(k))\n",
    "        print(lines[i][:-1])\n",
    "    k += 1\n",
    "    \n",
    "#print(errors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd552df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\"index\",\"entry\",\"entry_xml\",\"spans_gold\",\"tags_gold\",\"spans_preds\",\"tags_preds\"]\n",
    "df = pd.DataFrame(stats,columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd9c68",
   "metadata": {},
   "source": [
    "## F1-Score ranking\n",
    "F1-Score is calculated for each entry using seqeval library :\n",
    "* entities are rebuild using joint-labels with seqeval lib\n",
    "* f1-score is calculted for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f979bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    y_preds = df.iloc[i][\"tags_preds\"]\n",
    "    y_true = df.iloc[i][\"tags_gold\"]\n",
    "    try:\n",
    "        f1 = f1_score([y_true],[y_preds])\n",
    "        scores.append(f1)\n",
    "    except:\n",
    "        count += 1\n",
    "        print(df.iloc[i])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"f1\"] = scores\n",
    "df = df.sort_values(by=['f1']).reset_index()\n",
    "del df[\"level_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75854eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b17082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "\n",
    "df.hist(column='f1',bins=40,sharey=True, sharex=True)\n",
    "pl.suptitle('Entery-scale F1-Score distribution over test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6b85b",
   "metadata": {},
   "source": [
    "### 15-Top worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccccc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,16):\n",
    "    print(f\"INDEX {i}\")\n",
    "    print(df.iloc[i][\"entry\"])\n",
    "    print(df.iloc[i][\"entry_xml\"])\n",
    "    print(f\"F1-Score : {df.iloc[i]['f1']}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b631e",
   "metadata": {},
   "source": [
    "### 15-Top best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc515768",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = df.sort_values(by='f1', ascending=False)\n",
    "for i in range(0,16):\n",
    "    print(rdf.iloc[i][\"entry\"])\n",
    "    print(rdf.iloc[i][\"entry_xml\"])\n",
    "    print(f\"F1-Score : {rdf.iloc[i]['f1']}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1581a2",
   "metadata": {},
   "source": [
    "## Sub-word global analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_preds = []\n",
    "flat_labels = []\n",
    "for i in range(len(df)):\n",
    "    flat_preds += df[\"tags_preds\"][i]\n",
    "    flat_labels += df[\"tags_gold\"][i]\n",
    "flat_preds = pd.Series(flat_preds, name=\"Predictions\")\n",
    "flat_labels = pd.Series(flat_labels, name=\"Gold\")\n",
    "\n",
    "global_confusion = pd.crosstab(flat_labels, flat_preds,normalize='index').multiply(100., axis=1)\n",
    "global_confusion.columns = [\"ACT+O\",\"DESC+O\",\"DESC+ACT\",\"DESC+TITREP\",\"PER+O\",\"PER+TITREH\",\"SPAT+O\",\"SPAT+CARDINAL\",\"SPAT+FT\",\"SPAT+LOC\",\"O+O\"]\n",
    "global_confusion.index = [\"ACT+O\",\"DESC+O\",\"DESC+ACT\",\"DESC+TITREP\",\"PER+O\",\"PER+TITREH\",\"SPAT+O\",\"SPAT+CARDINAL\",\"SPAT+FT\",\"SPAT+LOC\",\"O+O\"]\n",
    "global_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Init figure\n",
    "plt.figure(figsize=(34, 16))\n",
    "\n",
    "#Create heatmap\n",
    "snsfig = sns.heatmap(\n",
    "    global_confusion, \n",
    "    annot = True, #Display labels\n",
    "    cmap=sns.color_palette(\"rocket_r\", as_cmap=True), #Color\n",
    "    fmt=\".1f\",\n",
    "    cbar=False,\n",
    "    annot_kws={\"fontsize\":40}\n",
    ")\n",
    "\n",
    "#Rename label axis and set their style\n",
    "plt.xlabel('Predictions',weight = 'bold',fontsize=35) # x-axis label with fontsize 15\n",
    "plt.ylabel('Gold',weight = 'bold',fontsize=35) # y-axis label with fontsize 15\n",
    "\n",
    "#Set x labels position to top\n",
    "snsfig.xaxis.tick_top()\n",
    "snsfig.xaxis.set_label_position('top')\n",
    "\n",
    "#Rotate y ticks horizontaly\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "#Change ticks size\n",
    "snsfig.set_xticklabels(snsfig.get_xmajorticklabels(), fontsize = 32)\n",
    "snsfig.set_yticklabels(snsfig.get_ymajorticklabels(), fontsize = 32)\n",
    "\n",
    "print(\"Confusion matrix of reference and predicted tokens types.\")\n",
    "print(\"Values are normalized by row (percentage of each reference classe and its resultants predictions)\")\n",
    "print(\"Last row represent percentage of each class in gold.\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Save figure\n",
    "fig = snsfig.get_figure()\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./tokenscaleanalysis-{FORMAT}-{SET}.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9342a",
   "metadata": {},
   "source": [
    "## Entry scale analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987574e1",
   "metadata": {},
   "source": [
    "Please choose one entry giving its index to perform an entry scale analysis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca834a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.iloc[i][\"entry\"])\n",
    "print(df.iloc[i][\"entry_xml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8275b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_preds = df.iloc[i][\"tags_preds\"]\n",
    "y_true = df.iloc[i][\"tags_gold\"]\n",
    "print(classification_report([y_true],[y_preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = pd.Series(df[\"tags_gold\"].iloc[i], name='Gold')\n",
    "y_pred = pd.Series(df[\"tags_preds\"].iloc[i], name='Predictions')\n",
    "entry_confusion = pd.crosstab(y_true, y_pred)\n",
    "entry_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap\n",
    "snsfig = sns.heatmap(\n",
    "    entry_confusion, \n",
    "    annot = True, #Display labels\n",
    "    cmap=sns.color_palette(\"rocket_r\", as_cmap=True), #Color\n",
    "    fmt=\"g\",\n",
    "    cbar=False,\n",
    "    annot_kws={\"fontsize\":30}\n",
    ")\n",
    "\n",
    "#Rename label axis and set their style\n",
    "plt.xlabel('Predictions',weight = 'bold',fontsize=25) # x-axis label with fontsize 15\n",
    "plt.ylabel('Gold',weight = 'bold',fontsize=25) # y-axis label with fontsize 15\n",
    "\n",
    "#Set x labels position to top\n",
    "snsfig.xaxis.tick_top()\n",
    "snsfig.xaxis.set_label_position('top')\n",
    "\n",
    "#Rotate y ticks horizontaly\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "#Change ticks size\n",
    "snsfig.set_xticklabels(snsfig.get_xmajorticklabels(), fontsize = 20)\n",
    "snsfig.set_yticklabels(snsfig.get_ymajorticklabels(), fontsize = 20)\n",
    "\n",
    "print(\"Confusion matrix of reference and predicted tokens types.\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Save figure\n",
    "fig = snsfig.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69962e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
