{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294705ff-9e89-499f-a41f-9494362be5f9",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "source": [
    "# 10 - Flat NER - Experiment #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d1d0e",
   "metadata": {},
   "source": [
    "Fine-tune models with ground-truth datasets.\n",
    "\n",
    "**Outputs :**\n",
    "* `11-flat-ner-ref-camembert_ner`\n",
    "* `12-flat-ner-ref-pretrained_camembert_ner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flD_9oT8LmDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flD_9oT8LmDB",
    "outputId": "63a92e5f-d414-46cc-db86-b46981e42594"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZvwNIzqBwDs",
   "metadata": {
    "id": "cZvwNIzqBwDs",
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "Set the BASE path.\n",
    "If run on Google Colab, will also mout Google Drive to the moutpoint given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LWJVak2mB6bI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWJVak2mB6bI",
    "outputId": "dbb54104-560b-480c-d4b0-74a0787e2024"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset_ICDAR\"\n",
    "  OUT_BASE = BASE / \"res_ICDAR/method_0\"\n",
    "else:\n",
    "  BASE = Path().resolve() # Directory of this approach\n",
    "  #Adapt this to your situation\n",
    "  DATASETS = Path('../dataset_ICDAR').resolve() #Where your data are located befor Dataset object creation\n",
    "  OUT_BASE = Path('../res_ICDAR/method_0').resolve() #Where you save the results of this notebook\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a270f9-5f9e-449e-bbff-69136b383507",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "RUN_CAMEMBERT = True            # Set to false to skip training Camembert\n",
    "RUN_CAMEMBERT_PRETRAINED = False  # Set to false to skip training Camembert pretrained\n",
    "\n",
    "USE_HUGGING_FACE_DATASET = True\n",
    "\n",
    "# Number of times a model will be trained & evaluated on each of the 8 trainsets.\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18178dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RUN_CAMEMBERT != RUN_CAMEMBERT_PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CAMEMBERT:\n",
    "    MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "    MODEL_NAME = 'camembert_ner'\n",
    "    FOLDER = f\"11-flat-ner-ref-{MODEL_NAME}-testest\"\n",
    "    INPUT_DIR = \"nlpso/m0_fine_tuning_ref_cmbert_io\"\n",
    "    \n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "    MODEL_NAME = 'pretrained_camembert_ner'\n",
    "    FOLDER = f\"12-flat-ner-ref-{MODEL_NAME}\"\n",
    "    INPUT_DIR = \"nlpso/m0_fine_tuning_ref_ptrn_cmbert_io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hxHdPTBlCCFO",
   "metadata": {
    "id": "hxHdPTBlCCFO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "TRAINSETS_SIZES = [6084]\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"10-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {
    "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed"
   },
   "source": [
    "## 10 - Train and eval on reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {
    "id": "91140aa5-b377-47c1-bd44-844cd9365ec3"
   },
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4"
   },
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import json\n",
    "from camembert_util import init_model, train_eval_loop, _convert_tokenizer\n",
    "\n",
    "def train_bert(metrics_output_directory,huggingface_dataset=True):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            if huggingface_dataset == True:\n",
    "                datasetdir = INPUT_DIR\n",
    "            else:\n",
    "                datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "            \n",
    "            if huggingface_dataset == True:\n",
    "                train_dev_test = load_dataset(datasetdir)\n",
    "            else:\n",
    "                train_dev_test = load_from_disk(datasetdir)\n",
    "            \n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de0446-e62f-46d5-ae73-34112f3c420d",
   "metadata": {
    "id": "09de0446-e62f-46d5-ae73-34112f3c420d"
   },
   "source": [
    "## 11 - CamemBERT - train & eval on reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05387e39-dd69-491e-9517-57490356e5e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05387e39-dd69-491e-9517-57490356e5e9",
    "outputId": "a894e899-0646-4260-f12f-7468adfbb5b2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    print(MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH)\n",
    "    \n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR,USE_HUGGING_FACE_DATASET)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IO labels\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60",
   "metadata": {
    "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60"
   },
   "source": [
    "## 12 - CamemBERT pretrained - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
    "outputId": "077e0a27-cd2b-41e4-a080-80292418d483"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "    print(MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH)\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR,USE_HUGGING_FACE_DATASET)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning pretrained model for IO labels\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
