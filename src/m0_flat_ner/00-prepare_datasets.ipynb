{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8189029c-0b96-45a0-8d89-6c49ffdda9b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 00 - Flat NER datasets generation\n",
    "\n",
    "Execute this notebook twice (set **MODEL_NAME** with *camember_ner* and for *pretrained_camembert_ner*)\n",
    "\n",
    "**Outputs**\n",
    "- In `01-experiment_1_prepared_ref_dataset_camembert_ner` : train, dev, test for clean data with CamemBERT NER tokenizer\n",
    "- In `01-experiment_1_prepared_ref_dataset_pretrained_camembert_ner` : train, dev, test for clean data with Pretrained CamemBERT NER tokenizer\n",
    "- In `02-experiment_2_prepared_pero_ocr_dataset_camembert_ner` : train, dev & test datasets for noisy OCR data (Pero-OCR) with CamemBERT NER tokenizer\n",
    "- In `02-experiment_2_prepared_pero_ocr_dataset_pretrained_camembert_ner` : train, dev & test datasets for noisy OCR data (Pero-OCR) with Pretrained CamemBERT NER tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52a0b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77ed69-9fa6-4462-9b1b-00ecb3f17392",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff04646-29cc-4cb7-a931-45b18016ed64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lrde/home2/stual/code_ICDAR_review/src/m0_flat_ner', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/lrde/home2/stual/.local/lib/python3.10/site-packages', '/usr/lib/python3.10/site-packages']\n",
      "/lrde/home2/stual/code_ICDAR_review/src/m0_flat_ner\n",
      "/work/stual/dataset_ICDAR\n",
      "/work/stual/res_ICDAR/method_0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset\"\n",
    "else:\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "  DATASETS = Path('/work/stual/dataset_ICDAR').resolve() # ADAPT THIS TO YOUR SITUATION : Your dataset location\n",
    "  RES_PATH_BASE = '/work/stual/res_ICDAR/' # ADAPT THIS TO YOUR SITUATION : folder where you save your results\n",
    "  OUT_BASE = Path(RES_PATH_BASE + '/method_0').resolve() \n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ab2a8-d126-4a36-87c1-5bd934a2f5c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16874c6b-e422-4e07-b31c-856841a71300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GLOBAL CONSTANTS\n",
    "import config\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "config.SPLIT_SEED = 42 # Random seed used in train/dev/test. Do not change it if you want to recreate the paper results.\n",
    "\n",
    "MODEL_NAME = \"pretrained_camembert_ner\" #camembert_ner OR pretrained_camembert_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71010115-8bac-43d9-9638-15f56f029493",
   "metadata": {},
   "source": [
    "# 01. Experiment #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de597797-0541-404e-b721-8667077eb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "GOLD_REF = DATASETS / \"41-ner_ref_from_pero/gold.csv\"\n",
    "assert GOLD_REF.exists()\n",
    "\n",
    "with open(GOLD_REF,'r',encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        l = line.split('\", \"')\n",
    "        res.append([l[0][1:],l[1][:-2]])\n",
    "gold_reference = pd.DataFrame(res,columns=[\"ner_xml\",\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031fb44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_xml</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PER&gt;Dufant (Victor)&lt;/PER&gt;, &lt;ACT&gt;libraire&lt;/ACT...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PER&gt;Dufay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PER&gt;Dulay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;SP...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;/ACT&gt;,...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PER&gt;Dufeu&lt;/PER&gt;, &lt;ACT&gt;charcutier&lt;/ACT&gt;, &lt;SPAT...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440</th>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;géographe&lt;/ACT&gt; , &lt;S...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l'institut&lt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt;, &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;SPAT&gt;&lt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt; , &lt;ACT&gt;carrier&lt;/ACT&gt;, &lt;SPAT...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8445 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ner_xml  \\\n",
       "0     <PER>Dufant (Victor)</PER>, <ACT>libraire</ACT...   \n",
       "1     <PER>Dufay</PER>, <ACT>essayeur du commerce</A...   \n",
       "2     <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <SP...   \n",
       "3     <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...   \n",
       "4     <PER>Dufeu</PER>, <ACT>charcutier</ACT>, <SPAT...   \n",
       "...                                                 ...   \n",
       "8440  <PER>Lamarche</PER>, <ACT>géographe</ACT> , <S...   \n",
       "8441  <PER>Lamarck</PER>, <ACT>membre de l'institut<...   \n",
       "8442  <PER>Lamare</PER>, <ACT>notaire</ACT>, <SPAT><...   \n",
       "8443  <PER>Lamarre</PER> , <ACT>carrier</ACT>, <SPAT...   \n",
       "8444  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                               book  \n",
       "0                      Bottin1_1820  \n",
       "1                      Bottin1_1820  \n",
       "2                      Bottin1_1820  \n",
       "3                      Bottin1_1820  \n",
       "4                      Bottin1_1820  \n",
       "...                             ...  \n",
       "8440  Notables_communaux_seine_1801  \n",
       "8441  Notables_communaux_seine_1801  \n",
       "8442  Notables_communaux_seine_1801  \n",
       "8443  Notables_communaux_seine_1801  \n",
       "8444  Notables_communaux_seine_1801  \n",
       "\n",
       "[8445 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TITRE-H and TITRE-P labels to transformers NER Pipeline\n",
    "for i in range(len(gold_reference)):\n",
    "    if '<TITRE-H>' in gold_reference['ner_xml'][i]:\n",
    "        gold_reference['ner_xml'][i] = gold_reference['ner_xml'][i].replace('TITRE-H','TITREH')\n",
    "    if '<TITRE-P>' in gold_reference['ner_xml'][i]:\n",
    "        gold_reference['ner_xml'][i] = gold_reference['ner_xml'][i].replace('TITRE-P','TITREP')\n",
    "gold_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5bdd42-8847-48e5-833f-8cbb8106e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 14:34:07.256907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 14:34:08.964264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 14:34:08.964375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 14:34:08.964385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6084, 3042, 1521, 760, 380, 190, 95, 47]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset_util import train_dev_test_split, unwrap # Local imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONSTANTS\n",
    "MIN_TRAINSET_SIZE = 30\n",
    "\n",
    " # Split 72/8/20% w. stratified sampling on directories names\n",
    "train, dev, test = train_dev_test_split(gold_reference.to_numpy())\n",
    "\n",
    "# Iteratively split the trainset in half to create smaller trainsets\n",
    "exp1_trainsets = [train]\n",
    "t_len = len(train)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current = exp1_trainsets[-1]\n",
    "        _, groups = unwrap(current)\n",
    "        smaller, rest = train_test_split(\n",
    "            current,\n",
    "            train_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=config.SPLIT_SEED,\n",
    "            stratify=groups,\n",
    "        )\n",
    "        t_len = len(rest)\n",
    "        if t_len < MIN_TRAINSET_SIZE:\n",
    "            break\n",
    "        exp1_trainsets.append(smaller)\n",
    "\n",
    "    except ValueError:\n",
    "        # Stop now if we encounter the error \"The least populated class in y has only 1 member\".\n",
    "        break\n",
    "\n",
    "[len(s) for s in exp1_trainsets] # Should be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f4fd33-72da-4eb8-bec2-c90aa3798c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Dev set should contain 676 examples\n",
    "assert len(dev) == 676\n",
    "\n",
    "# Test set should contain 1685 examples\n",
    "assert len(test) == 1685\n",
    "\n",
    "# Lenghts of exp1_trainsets should be fixed\n",
    "assert sorted([len(s) for s in exp1_trainsets] ) == sorted([6084, 3042, 1521, 760, 380, 190, 95, 47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85046df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>6085</td>\n",
       "      <td>676</td>\n",
       "      <td>1685</td>\n",
       "      <td>8446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>4568</td>\n",
       "      <td>519</td>\n",
       "      <td>1094</td>\n",
       "      <td>6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TITRE</th>\n",
       "      <td>290</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>6871</td>\n",
       "      <td>762</td>\n",
       "      <td>1788</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>5991</td>\n",
       "      <td>678</td>\n",
       "      <td>1751</td>\n",
       "      <td>8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>23860</td>\n",
       "      <td>2684</td>\n",
       "      <td>6408</td>\n",
       "      <td>32952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train   Dev  Test    All\n",
       "Entity type                          \n",
       "PER           6085   676  1685   8446\n",
       "ACT           4568   519  1094   6181\n",
       "TITRE          290    42    76    408\n",
       "LOC           6871   762  1788   9421\n",
       "FT              55     7    14     76\n",
       "CARDINAL      5991   678  1751   8420\n",
       "All          23860  2684  6408  32952"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import createStatsTab\n",
    "\n",
    "createStatsTab(train,dev,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd88d23-c062-4772-b53f-610927523397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58889d4e9154084bb08fc965479ddd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f610dd3bba494ff6a2838e6eb8e3b96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b572ed124be24239bdd3a35db8c5e0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9add43992deb44698c6a76f817810df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7269152bef734ac999222f6504f912ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69deb660cdd04b048883f3f72f59212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4618cf53732b4a23b4e9915910b2adb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8a1cac6b7141aeba973ffd47cd94ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dd9d43d56e45f7a3dc4a20937e3115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f861f91f754b19839fde710ccb6be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d51fc1b5ba42cabb3c3949be7050de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13df4300113425cac849b9912a454db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aed4c92cc34c598822b15d195e0f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0680cd13387a428ba19a31791816fa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d127d7088a4f2eb191f1907cb2e280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df2954050e044f78daa5f7f21e01786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0235f17083346949e726b6650007eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f72d91d0d140938a1f5565c81143bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf5d56fb0334ef087568c7dade7af55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9a5e547eef4d3884c3b32f42b9694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee62e1ff8d54881b78a0c465cdd72e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af65ca979464ab6b2b605a61989c67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e49d9b744da4b36a00000c5116f1953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692e4d4533d4453b9970d7ad2a4065d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save on disk\n",
    "from dataset_util import save_dataset # Local import\n",
    "\n",
    "output_directory = OUT_BASE / f\"01-experiment_1_prepared_ref_dataset_{MODEL_NAME}\"\n",
    "output_directory.mkdir(exist_ok=True, parents=True) # Create if necessary\n",
    "   \n",
    "for train in exp1_trainsets:\n",
    "    datasets = [train, dev, test]\n",
    "    save_dataset(output_directory, datasets, [\"train\",\"dev\",\"test\"], suffix=len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e623237-eb40-4bef-80d2-7a21a334023f",
   "metadata": {},
   "source": [
    "# 02. Experiment #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9e0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "GOLD_REF = DATASETS / \"31-ner_align_pero/gold.csv\"\n",
    "gold_reference = pd.read_csv(GOLD_REF, header=None, names=[\"ner_xml\",\"book\"],skipinitialspace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5cd59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_xml</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>☞ \n",
       " \n",
       "T \n",
       "&lt;PER&gt;Dufant (Victor)&lt;/PER&gt;, &lt;ACT&gt;libraire...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PER&gt;Dutay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PER&gt;Dulay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;SP...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;/ACT&gt;,...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y \n",
       "☞ \n",
       "&lt;PER&gt;Dnten&lt;/PER&gt;,&lt;ACT&gt;charentier&lt;/ACT&gt;, &lt;S...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440</th>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;geographe&lt;/ACT&gt; , &lt;S...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l&amp;apos;inst...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt; , &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;SPAT&gt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;carrier&lt;/ACT&gt;, &lt;SPAT&gt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8445 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ner_xml  \\\n",
       "0     ☞\n",
       "\n",
       "T\n",
       "<PER>Dufant (Victor)</PER>, <ACT>libraire...   \n",
       "1     <PER>Dutay</PER>, <ACT>essayeur du commerce</A...   \n",
       "2     <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <SP...   \n",
       "3     <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...   \n",
       "4     Y\n",
       "☞\n",
       "<PER>Dnten</PER>,<ACT>charentier</ACT>, <S...   \n",
       "...                                                 ...   \n",
       "8440  <PER>Lamarche</PER>, <ACT>geographe</ACT> , <S...   \n",
       "8441  <PER>Lamarck</PER>, <ACT>membre de l&apos;inst...   \n",
       "8442  <PER>Lamare</PER> , <ACT>notaire</ACT>, <SPAT>...   \n",
       "8443  <PER>Lamarre</PER>, <ACT>carrier</ACT>, <SPAT>...   \n",
       "8444  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                               book  \n",
       "0                      Bottin1_1820  \n",
       "1                      Bottin1_1820  \n",
       "2                      Bottin1_1820  \n",
       "3                      Bottin1_1820  \n",
       "4                      Bottin1_1820  \n",
       "...                             ...  \n",
       "8440  Notables_communaux_seine_1801  \n",
       "8441  Notables_communaux_seine_1801  \n",
       "8442  Notables_communaux_seine_1801  \n",
       "8443  Notables_communaux_seine_1801  \n",
       "8444  Notables_communaux_seine_1801  \n",
       "\n",
       "[8445 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TITRE-H and TITRE-P labels to transformers NER Pipeline\n",
    "for i in range(len(gold_reference)):\n",
    "    if '<TITRE-H>' in gold_reference['ner_xml'][i]:\n",
    "        gold_reference['ner_xml'][i] = gold_reference['ner_xml'][i].replace('TITRE-H','TITREH')\n",
    "    if '<TITRE-P>' in gold_reference['ner_xml'][i]:\n",
    "        gold_reference['ner_xml'][i] = gold_reference['ner_xml'][i].replace('TITRE-P','TITREP')\n",
    "gold_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8316172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6084, 3042, 1521, 760, 380, 190, 95, 47]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset_util import train_dev_test_split, unwrap # Local imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONSTANTS\n",
    "MIN_TRAINSET_SIZE = 30\n",
    "\n",
    " # Split 72/8/20% w. stratified sampling on directories names\n",
    "train, dev, test = train_dev_test_split(gold_reference.to_numpy())\n",
    "\n",
    "# Iteratively split the trainset in half to create smaller trainsets\n",
    "exp1_trainsets = [train]\n",
    "t_len = len(train)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current = exp1_trainsets[-1]\n",
    "        _, groups = unwrap(current)\n",
    "        smaller, rest = train_test_split(\n",
    "            current,\n",
    "            train_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=config.SPLIT_SEED,\n",
    "            stratify=groups,\n",
    "        )\n",
    "        t_len = len(rest)\n",
    "        if t_len < MIN_TRAINSET_SIZE:\n",
    "            break\n",
    "        exp1_trainsets.append(smaller)\n",
    "\n",
    "    except ValueError:\n",
    "        # Stop now if we encounter the error \"The least populated class in y has only 1 member\".\n",
    "        break\n",
    "\n",
    "[len(s) for s in exp1_trainsets] # Should be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eedb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Dev set should contain 676 examples\n",
    "assert len(dev) == 676\n",
    "\n",
    "# Test set should contain 1685 examples\n",
    "assert len(test) == 1685\n",
    "\n",
    "# Lenghts of exp1_trainsets should be fixed\n",
    "assert sorted([len(s) for s in exp1_trainsets] ) == sorted([6084, 3042, 1521, 760, 380, 190, 95, 47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b9201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>6085</td>\n",
       "      <td>676</td>\n",
       "      <td>1685</td>\n",
       "      <td>8446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>4568</td>\n",
       "      <td>519</td>\n",
       "      <td>1094</td>\n",
       "      <td>6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TITRE</th>\n",
       "      <td>290</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>6871</td>\n",
       "      <td>762</td>\n",
       "      <td>1788</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>5991</td>\n",
       "      <td>678</td>\n",
       "      <td>1751</td>\n",
       "      <td>8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>23860</td>\n",
       "      <td>2684</td>\n",
       "      <td>6408</td>\n",
       "      <td>32952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train   Dev  Test    All\n",
       "Entity type                          \n",
       "PER           6085   676  1685   8446\n",
       "ACT           4568   519  1094   6181\n",
       "TITRE          290    42    76    408\n",
       "LOC           6871   762  1788   9421\n",
       "FT              55     7    14     76\n",
       "CARDINAL      5991   678  1751   8420\n",
       "All          23860  2684  6408  32952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import createStatsTab\n",
    "\n",
    "createStatsTab(train,dev,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "511f889f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train \u001b[38;5;129;01min\u001b[39;00m exp1_trainsets:\n\u001b[1;32m      8\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m [train, dev, test]\n\u001b[0;32m----> 9\u001b[0m     \u001b[43msave_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stage_DAS/m0_flat_ner/dataset_util.py:57\u001b[0m, in \u001b[0;36msave_dataset\u001b[0;34m(output_dir, datasets, names, suffix)\u001b[0m\n\u001b[1;32m     54\u001b[0m     examples, _ \u001b[38;5;241m=\u001b[39m unwrap(ds)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Huggingface\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     hf_dic[name] \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_huggingface_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m bert_ds \u001b[38;5;241m=\u001b[39m DatasetDict(hf_dic)\n\u001b[1;32m     60\u001b[0m hf_file \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m file_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffix)\n",
      "File \u001b[0;32m~/stage_DAS/m0_flat_ner/camembert_util.py:127\u001b[0m, in \u001b[0;36mcreate_huggingface_dataset\u001b[0;34m(entries)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_huggingface_dataset\u001b[39m(entries):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Creates a Huggingface Dataset from a set of NER-XML entries\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     tokenized_entries \u001b[38;5;241m=\u001b[39m [word_tokens_from_xml(entry) \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries]\n\u001b[1;32m    128\u001b[0m     word_tokens, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtokenized_entries)\n\u001b[1;32m    129\u001b[0m     ds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: word_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels})\n",
      "File \u001b[0;32m~/stage_DAS/m0_flat_ner/camembert_util.py:127\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_huggingface_dataset\u001b[39m(entries):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Creates a Huggingface Dataset from a set of NER-XML entries\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     tokenized_entries \u001b[38;5;241m=\u001b[39m [\u001b[43mword_tokens_from_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries]\n\u001b[1;32m    128\u001b[0m     word_tokens, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtokenized_entries)\n\u001b[1;32m    129\u001b[0m     ds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: word_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels})\n",
      "File \u001b[0;32m~/stage_DAS/m0_flat_ner/camembert_util.py:173\u001b[0m, in \u001b[0;36mword_tokens_from_xml\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m    171\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    172\u001b[0m entry_xml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<x>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</x>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 173\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mparseString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry_xml\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgetElementsByTagName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    175\u001b[0m cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mchildNodes:\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/dom/minidom.py:2000\u001b[0m, in \u001b[0;36mparseString\u001b[0;34m(string, parser)\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expatbuilder\n\u001b[0;32m-> 2000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexpatbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2002\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pulldom\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/dom/expatbuilder.py:925\u001b[0m, in \u001b[0;36mparseString\u001b[0;34m(string, namespaces)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     builder \u001b[38;5;241m=\u001b[39m ExpatBuilder()\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/dom/expatbuilder.py:223\u001b[0m, in \u001b[0;36mExpatBuilder.parseString\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    221\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetParser()\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subset(string)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParseEscape:\n",
      "File \u001b[0;32m/usr/src/debug/python/Python-3.10.8/Modules/pyexpat.c:416\u001b[0m, in \u001b[0;36mStartElement\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/dom/expatbuilder.py:350\u001b[0m, in \u001b[0;36mExpatBuilder.first_element_handler\u001b[0;34m(self, name, attributes)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_end_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetParser()\u001b[38;5;241m.\u001b[39mStartElementHandler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_element_handler\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_element_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/dom/expatbuilder.py:736\u001b[0m, in \u001b[0;36mNamespaces.start_element_handler\u001b[0;34m(self, name, attributes)\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;124;03m\"\"\"Push this namespace declaration on our storage.\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ns_ordered_prefixes\u001b[38;5;241m.\u001b[39mappend((prefix, uri))\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_element_handler\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, attributes):\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[1;32m    738\u001b[0m         uri, localname, prefix, qname \u001b[38;5;241m=\u001b[39m _parse_ns_name(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Save on disk\n",
    "from dataset_util import save_dataset # Local import\n",
    "\n",
    "output_directory = OUT_BASE / f\"02-experiment_2_prepared_pero_ocr_dataset_{MODEL_NAME}\"\n",
    "output_directory.mkdir(exist_ok=True, parents=True) # Create if necessary\n",
    "   \n",
    "for train in exp1_trainsets:\n",
    "    datasets = [train, dev, test]\n",
    "    save_dataset(output_directory, datasets, [\"train\",\"dev\",\"test\"], suffix=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3d4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
