{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294705ff-9e89-499f-a41f-9494362be5f9",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "source": [
    "# 20 - Flat NER - Experiment #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d1d0e",
   "metadata": {},
   "source": [
    "Run Flat NER approach on ground-truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e498466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" #NumÃ©ro GPU\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e9f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flD_9oT8LmDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flD_9oT8LmDB",
    "outputId": "63a92e5f-d414-46cc-db86-b46981e42594"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZvwNIzqBwDs",
   "metadata": {
    "id": "cZvwNIzqBwDs",
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "Set the BASE path.\n",
    "If run on Google Colab, will also mout Google Drive to the moutpoint given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LWJVak2mB6bI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWJVak2mB6bI",
    "outputId": "dbb54104-560b-480c-d4b0-74a0787e2024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lrde/home2/stual/stage_DAS/m0_flat_ner', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages']\n",
      "/lrde/home2/stual/stage_DAS/m0_flat_ner\n",
      "/work/stual/dataset_ICDAR\n",
      "/work/stual/res_ICDAR/method_0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset\"\n",
    "else:\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "  DATASETS = Path('/work/stual/dataset_ICDAR')\n",
    "  OUT_BASE = Path('/work/stual/res_ICDAR/method_0')\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a270f9-5f9e-449e-bbff-69136b383507",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "RUN_CAMEMBERT = False            # Set to false to skip training Camembert\n",
    "RUN_CAMEMBERT_PRETRAINED = True  # Set to false to skip training Camembert pretrained\n",
    "\n",
    "# Number of times a model will be trained & evaluated on each of the 8 trainsets.\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18178dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RUN_CAMEMBERT != RUN_CAMEMBERT_PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaf4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CAMEMBERT:\n",
    "    MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "    MODEL_NAME = 'camembert_ner'\n",
    "    FOLDER = f\"21-flat-ner-ref-{MODEL_NAME}\"\n",
    "    \n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "    MODEL_NAME = 'pretrained_camembert_ner'\n",
    "    FOLDER = f\"22-flat-ner-ref-{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hxHdPTBlCCFO",
   "metadata": {
    "id": "hxHdPTBlCCFO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_0/01-experiment_1_prepared_ref_dataset_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_0/20-experiment_1_metrics'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = OUT_BASE / f\"01-experiment_1_prepared_ref_dataset_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"20-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {
    "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed"
   },
   "source": [
    "## 20 - Train and eval on reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {
    "id": "91140aa5-b377-47c1-bd44-844cd9365ec3"
   },
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 14:21:13.602457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 14:21:16.247886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 14:21:16.247997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 14:21:16.248011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "import json\n",
    "from camembert_util import init_model, train_eval_loop, _convert_tokenizer\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de0446-e62f-46d5-ae73-34112f3c420d",
   "metadata": {
    "id": "09de0446-e62f-46d5-ae73-34112f3c420d"
   },
   "source": [
    "## 21 - CamemBERT - train & eval on reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05387e39-dd69-491e-9517-57490356e5e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05387e39-dd69-491e-9517-57490356e5e9",
    "outputId": "a894e899-0646-4260-f12f-7468adfbb5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning model\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    print(MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH)\n",
    "    \n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning CamemBERT model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60",
   "metadata": {
    "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60"
   },
   "source": [
    "## 22 - CamemBERT pretrained - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
    "outputId": "077e0a27-cd2b-41e4-a080-80292418d483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/stual/res_ICDAR/method_0/20-experiment_1_metrics/22-flat-ner-ref-pretrained_camembert_ner /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 04:21 < 10:11, 5.73 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204963</td>\n",
       "      <td>0.941950</td>\n",
       "      <td>0.961252</td>\n",
       "      <td>0.951503</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>{'precision': 0.9297994269340975, 'recall': 0.9558173784977909, 'f1': 0.9426289034132171, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9155963302752294, 'recall': 0.9614643545279383, 'f1': 0.9379699248120301, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9383033419023136, 'recall': 0.9592641261498029, 'f1': 0.9486679662118258, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9854014598540146, 'recall': 0.995575221238938, 'f1': 0.9904622157006603, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8181818181818182, 'recall': 0.675, 'f1': 0.7397260273972603, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126874</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.968331</td>\n",
       "      <td>0.959041</td>\n",
       "      <td>0.971822</td>\n",
       "      <td>{'precision': 0.9708029197080292, 'recall': 0.979381443298969, 'f1': 0.9750733137829911, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9122486288848263, 'recall': 0.9614643545279383, 'f1': 0.9362101313320825, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9309462915601023, 'recall': 0.9566360052562418, 'f1': 0.9436163318211277, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7804878048780488, 'recall': 0.8, 'f1': 0.7901234567901235, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.091654</td>\n",
       "      <td>0.968136</td>\n",
       "      <td>0.973547</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9852724594992637, 'f1': 0.9859985261606484, 'number': 679}</td>\n",
       "      <td>{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7692307692307693, 'recall': 0.75, 'f1': 0.7594936708860761, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.080330</td>\n",
       "      <td>0.966089</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.971280</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9882179675994109, 'f1': 0.9845928099779898, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9275092936802974, 'recall': 0.9614643545279383, 'f1': 0.9441816461684011, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647058823529412, 'recall': 0.9697766097240473, 'f1': 0.9672346002621232, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8536585365853658, 'recall': 0.875, 'f1': 0.8641975308641976, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.082930</td>\n",
       "      <td>0.964484</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>0.979022</td>\n",
       "      <td>{'precision': 0.9750733137829912, 'recall': 0.979381443298969, 'f1': 0.9772226304188096, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9357277882797732, 'recall': 0.953757225433526, 'f1': 0.9446564885496184, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9572538860103627, 'recall': 0.9710906701708278, 'f1': 0.964122635355512, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.080599</td>\n",
       "      <td>0.971503</td>\n",
       "      <td>0.978018</td>\n",
       "      <td>0.974749</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9852724594992637, 'f1': 0.9838235294117648, 'number': 679}</td>\n",
       "      <td>{'precision': 0.947069943289225, 'recall': 0.9653179190751445, 'f1': 0.9561068702290076, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.073221</td>\n",
       "      <td>0.970806</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.974768</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9882179675994109, 'f1': 0.9860396767083027, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.064855</td>\n",
       "      <td>0.967909</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.972753</td>\n",
       "      <td>0.982870</td>\n",
       "      <td>{'precision': 0.9838945827232797, 'recall': 0.9896907216494846, 'f1': 0.986784140969163, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9382022471910112, 'recall': 0.9653179190751445, 'f1': 0.9515669515669515, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9583333333333334, 'recall': 0.9671484888304862, 'f1': 0.9627207325049051, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.068484</td>\n",
       "      <td>0.970089</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.974407</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9433962264150944, 'recall': 0.9633911368015414, 'f1': 0.9532888465204956, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9738562091503268, 'recall': 0.9789750328515112, 'f1': 0.9764089121887288, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.075196</td>\n",
       "      <td>0.978067</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.979159</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9724047306176085, 'recall': 0.9724047306176085, 'f1': 0.9724047306176085, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.063913</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>0.981371</td>\n",
       "      <td>0.978818</td>\n",
       "      <td>0.983615</td>\n",
       "      <td>{'precision': 0.9853372434017595, 'recall': 0.9896907216494846, 'f1': 0.9875091844232182, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9602272727272727, 'recall': 0.976878612716763, 'f1': 0.9684813753581661, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9711286089238845, 'recall': 0.9724047306176085, 'f1': 0.9717662508207485, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.975213</td>\n",
       "      <td>0.982116</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>0.983615</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9882179675994109, 'f1': 0.9874908020603386, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9600760456273765, 'recall': 0.9730250481695568, 'f1': 0.9665071770334929, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9713168187744459, 'recall': 0.9789750328515112, 'f1': 0.975130890052356, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.976632</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9580952380952381, 'recall': 0.9691714836223507, 'f1': 0.96360153256705, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9750982961992136, 'recall': 0.9776609724047306, 'f1': 0.9763779527559054, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.067353</td>\n",
       "      <td>0.978407</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.978771</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9823269513991163, 'f1': 0.9837758112094395, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9619047619047619, 'recall': 0.9730250481695568, 'f1': 0.9674329501915709, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9789750328515112, 'recall': 0.9789750328515112, 'f1': 0.9789750328515112, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.060476</td>\n",
       "      <td>0.973343</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9490566037735849, 'recall': 0.9691714836223507, 'f1': 0.9590085795996187, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9724770642201835, 'recall': 0.9750328515111695, 'f1': 0.973753280839895, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8372093023255814, 'recall': 0.9, 'f1': 0.8674698795180723, 'number': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/stage_DAS/m0_flat_ner/camembert_util.py:101: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9297994269340975, 'recall': 0.9558173784977909, 'f1': 0.9426289034132171, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9155963302752294, 'recall': 0.9614643545279383, 'f1': 0.9379699248120301, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9383033419023136, 'recall': 0.9592641261498029, 'f1': 0.9486679662118258, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9854014598540146, 'recall': 0.995575221238938, 'f1': 0.9904622157006603, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8181818181818182, 'recall': 0.675, 'f1': 0.7397260273972603, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9708029197080292, 'recall': 0.979381443298969, 'f1': 0.9750733137829911, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9122486288848263, 'recall': 0.9614643545279383, 'f1': 0.9362101313320825, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9309462915601023, 'recall': 0.9566360052562418, 'f1': 0.9436163318211277, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7804878048780488, 'recall': 0.8, 'f1': 0.7901234567901235, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9852724594992637, 'f1': 0.9859985261606484, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7692307692307693, 'recall': 0.75, 'f1': 0.7594936708860761, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9882179675994109, 'f1': 0.9845928099779898, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9275092936802974, 'recall': 0.9614643545279383, 'f1': 0.9441816461684011, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647058823529412, 'recall': 0.9697766097240473, 'f1': 0.9672346002621232, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8536585365853658, 'recall': 0.875, 'f1': 0.8641975308641976, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750733137829912, 'recall': 0.979381443298969, 'f1': 0.9772226304188096, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9357277882797732, 'recall': 0.953757225433526, 'f1': 0.9446564885496184, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9572538860103627, 'recall': 0.9710906701708278, 'f1': 0.964122635355512, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9852724594992637, 'f1': 0.9838235294117648, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.947069943289225, 'recall': 0.9653179190751445, 'f1': 0.9561068702290076, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9882179675994109, 'f1': 0.9860396767083027, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838945827232797, 'recall': 0.9896907216494846, 'f1': 0.986784140969163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382022471910112, 'recall': 0.9653179190751445, 'f1': 0.9515669515669515, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9583333333333334, 'recall': 0.9671484888304862, 'f1': 0.9627207325049051, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9433962264150944, 'recall': 0.9633911368015414, 'f1': 0.9532888465204956, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9738562091503268, 'recall': 0.9789750328515112, 'f1': 0.9764089121887288, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724047306176085, 'recall': 0.9724047306176085, 'f1': 0.9724047306176085, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853372434017595, 'recall': 0.9896907216494846, 'f1': 0.9875091844232182, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9602272727272727, 'recall': 0.976878612716763, 'f1': 0.9684813753581661, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9711286089238845, 'recall': 0.9724047306176085, 'f1': 0.9717662508207485, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9882179675994109, 'f1': 0.9874908020603386, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9600760456273765, 'recall': 0.9730250481695568, 'f1': 0.9665071770334929, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9713168187744459, 'recall': 0.9789750328515112, 'f1': 0.975130890052356, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9580952380952381, 'recall': 0.9691714836223507, 'f1': 0.96360153256705, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750982961992136, 'recall': 0.9776609724047306, 'f1': 0.9763779527559054, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9823269513991163, 'f1': 0.9837758112094395, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619047619047619, 'recall': 0.9730250481695568, 'f1': 0.9674329501915709, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9789750328515112, 'recall': 0.9789750328515112, 'f1': 0.9789750328515112, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9490566037735849, 'recall': 0.9691714836223507, 'f1': 0.9590085795996187, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724770642201835, 'recall': 0.9750328515111695, 'f1': 0.973753280839895, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8372093023255814, 'recall': 0.9, 'f1': 0.8674698795180723, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000 (score: 0.9791589132861928).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9775811209439528, 'recall': 0.9827995255041518, 'f1': 0.9801833776989057, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9207207207207208, 'recall': 0.9341864716636198, 'f1': 0.927404718693285, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705228031145717, 'recall': 0.9764969222160045, 'f1': 0.9735006973500697, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.996011396011396, 'recall': 0.9982866933181039, 'f1': 0.9971477467199088, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8666666666666667, 'recall': 0.8552631578947368, 'f1': 0.8609271523178809, 'number': 76}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724047306176085, 'recall': 0.9724047306176085, 'f1': 0.9724047306176085, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 04:12 < 09:50, 5.93 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.205769</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.959762</td>\n",
       "      <td>0.954428</td>\n",
       "      <td>0.967105</td>\n",
       "      <td>{'precision': 0.9532163742690059, 'recall': 0.9602356406480118, 'f1': 0.9567131327953045, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9122486288848263, 'recall': 0.9614643545279383, 'f1': 0.9362101313320825, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9382239382239382, 'recall': 0.9579500657030223, 'f1': 0.9479843953185956, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.84, 'recall': 0.525, 'f1': 0.6461538461538462, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127639</td>\n",
       "      <td>0.951318</td>\n",
       "      <td>0.968331</td>\n",
       "      <td>0.959749</td>\n",
       "      <td>0.975174</td>\n",
       "      <td>{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}</td>\n",
       "      <td>{'precision': 0.907103825136612, 'recall': 0.9595375722543352, 'f1': 0.9325842696629214, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9320512820512821, 'recall': 0.9553219448094612, 'f1': 0.9435431537962362, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7619047619047619, 'recall': 0.8, 'f1': 0.7804878048780488, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.964101</td>\n",
       "      <td>0.970566</td>\n",
       "      <td>0.967323</td>\n",
       "      <td>0.978277</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9454887218045113, 'recall': 0.9691714836223507, 'f1': 0.9571836346336823, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9440832249674902, 'recall': 0.9540078843626807, 'f1': 0.9490196078431372, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.85, 'f1': 0.85, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.079418</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>0.974292</td>\n",
       "      <td>0.969776</td>\n",
       "      <td>0.980884</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9325842696629213, 'recall': 0.9595375722543352, 'f1': 0.9458689458689458, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9619921363040629, 'recall': 0.9645203679369251, 'f1': 0.963254593175853, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7708333333333334, 'recall': 0.925, 'f1': 0.840909090909091, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.082158</td>\n",
       "      <td>0.967098</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.970867</td>\n",
       "      <td>0.978774</td>\n",
       "      <td>{'precision': 0.9780380673499268, 'recall': 0.9837997054491899, 'f1': 0.9809104258443465, 'number': 679}</td>\n",
       "      <td>{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8974358974358975, 'recall': 0.875, 'f1': 0.8860759493670887, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.074687</td>\n",
       "      <td>0.971122</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.974188</td>\n",
       "      <td>0.980636</td>\n",
       "      <td>{'precision': 0.986784140969163, 'recall': 0.9896907216494846, 'f1': 0.9882352941176471, 'number': 679}</td>\n",
       "      <td>{'precision': 0.946969696969697, 'recall': 0.9633911368015414, 'f1': 0.9551098376313275, 'number': 519}</td>\n",
       "      <td>{'precision': 0.961038961038961, 'recall': 0.9724047306176085, 'f1': 0.9666884389288047, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>0.972542</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9837997054491899, 'f1': 0.9845246868091377, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.96484375, 'recall': 0.973718791064389, 'f1': 0.9692609548724657, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.062878</td>\n",
       "      <td>0.973033</td>\n",
       "      <td>0.981371</td>\n",
       "      <td>0.977184</td>\n",
       "      <td>0.984359</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9437148217636022, 'recall': 0.9691714836223507, 'f1': 0.9562737642585553, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.068927</td>\n",
       "      <td>0.971165</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>0.982125</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9596879063719116, 'recall': 0.9697766097240473, 'f1': 0.9647058823529412, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.978099</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.979918</td>\n",
       "      <td>0.984980</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9618320610687023, 'recall': 0.9710982658959537, 'f1': 0.9664429530201342, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9751633986928104, 'recall': 0.9802890932982917, 'f1': 0.9777195281782437, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.057395</td>\n",
       "      <td>0.977712</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9617590822179732, 'recall': 0.9691714836223507, 'f1': 0.9654510556621881, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9699346405228758, 'recall': 0.9750328515111695, 'f1': 0.9724770642201835, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.078277</td>\n",
       "      <td>0.974045</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.976398</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9524714828897338, 'recall': 0.9653179190751445, 'f1': 0.9588516746411484, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9699738903394256, 'recall': 0.9763469119579501, 'f1': 0.9731499672560576, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.975673</td>\n",
       "      <td>0.984732</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}</td>\n",
       "      <td>{'precision': 0.96, 'recall': 0.9710982658959537, 'f1': 0.9655172413793104, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9661458333333334, 'recall': 0.9750328515111695, 'f1': 0.9705689993459777, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.42857142857142855, 'f1': 0.375, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.063343</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.983987</td>\n",
       "      <td>{'precision': 0.9822485207100592, 'recall': 0.9779086892488954, 'f1': 0.9800738007380073, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9582542694497154, 'recall': 0.9730250481695568, 'f1': 0.9655831739961759, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9673629242819843, 'recall': 0.973718791064389, 'f1': 0.9705304518664047, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.75, 'f1': 0.8108108108108107, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.058073</td>\n",
       "      <td>0.970838</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.975338</td>\n",
       "      <td>0.983987</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.9941089837997055, 'f1': 0.9926470588235295, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9532163742690059, 'recall': 0.9602356406480118, 'f1': 0.9567131327953045, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9122486288848263, 'recall': 0.9614643545279383, 'f1': 0.9362101313320825, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382239382239382, 'recall': 0.9579500657030223, 'f1': 0.9479843953185956, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.84, 'recall': 0.525, 'f1': 0.6461538461538462, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.907103825136612, 'recall': 0.9595375722543352, 'f1': 0.9325842696629214, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9320512820512821, 'recall': 0.9553219448094612, 'f1': 0.9435431537962362, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7619047619047619, 'recall': 0.8, 'f1': 0.7804878048780488, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9454887218045113, 'recall': 0.9691714836223507, 'f1': 0.9571836346336823, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9440832249674902, 'recall': 0.9540078843626807, 'f1': 0.9490196078431372, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.85, 'f1': 0.85, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9325842696629213, 'recall': 0.9595375722543352, 'f1': 0.9458689458689458, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619921363040629, 'recall': 0.9645203679369251, 'f1': 0.963254593175853, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7708333333333334, 'recall': 0.925, 'f1': 0.840909090909091, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780380673499268, 'recall': 0.9837997054491899, 'f1': 0.9809104258443465, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8974358974358975, 'recall': 0.875, 'f1': 0.8860759493670887, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986784140969163, 'recall': 0.9896907216494846, 'f1': 0.9882352941176471, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.946969696969697, 'recall': 0.9633911368015414, 'f1': 0.9551098376313275, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.961038961038961, 'recall': 0.9724047306176085, 'f1': 0.9666884389288047, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9837997054491899, 'f1': 0.9845246868091377, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96484375, 'recall': 0.973718791064389, 'f1': 0.9692609548724657, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8461538461538461, 'recall': 0.825, 'f1': 0.8354430379746836, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9437148217636022, 'recall': 0.9691714836223507, 'f1': 0.9562737642585553, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9596879063719116, 'recall': 0.9697766097240473, 'f1': 0.9647058823529412, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9618320610687023, 'recall': 0.9710982658959537, 'f1': 0.9664429530201342, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9751633986928104, 'recall': 0.9802890932982917, 'f1': 0.9777195281782437, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9617590822179732, 'recall': 0.9691714836223507, 'f1': 0.9654510556621881, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9699346405228758, 'recall': 0.9750328515111695, 'f1': 0.9724770642201835, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9524714828897338, 'recall': 0.9653179190751445, 'f1': 0.9588516746411484, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9699738903394256, 'recall': 0.9763469119579501, 'f1': 0.9731499672560576, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96, 'recall': 0.9710982658959537, 'f1': 0.9655172413793104, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661458333333334, 'recall': 0.9750328515111695, 'f1': 0.9705689993459777, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.42857142857142855, 'f1': 0.375, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8780487804878049, 'recall': 0.9, 'f1': 0.888888888888889, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9822485207100592, 'recall': 0.9779086892488954, 'f1': 0.9800738007380073, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9582542694497154, 'recall': 0.9730250481695568, 'f1': 0.9655831739961759, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9673629242819843, 'recall': 0.973718791064389, 'f1': 0.9705304518664047, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.75, 'f1': 0.8108108108108107, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.9941089837997055, 'f1': 0.9926470588235295, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8809523809523809, 'recall': 0.925, 'f1': 0.9024390243902439, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000 (score: 0.9799181851989588).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9741176470588235, 'recall': 0.9822064056939501, 'f1': 0.9781453041937389, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9101527403414196, 'recall': 0.9259597806215722, 'f1': 0.9179882193022202, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9645821804095185, 'recall': 0.9753777280358142, 'f1': 0.9699499165275458, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9977194982896237, 'recall': 0.9994288977727013, 'f1': 0.9985734664764623, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.7894736842105263, 'f1': 0.8108108108108109, 'number': 76}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9618320610687023, 'recall': 0.9710982658959537, 'f1': 0.9664429530201342, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9751633986928104, 'recall': 0.9802890932982917, 'f1': 0.9777195281782437, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/5000 03:20 < 10:35, 5.98 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206848</td>\n",
       "      <td>0.939439</td>\n",
       "      <td>0.947839</td>\n",
       "      <td>0.943620</td>\n",
       "      <td>0.964250</td>\n",
       "      <td>{'precision': 0.9301310043668122, 'recall': 0.9410898379970545, 'f1': 0.9355783308931186, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9064220183486239, 'recall': 0.9518304431599229, 'f1': 0.9285714285714286, 'number': 519}</td>\n",
       "      <td>{'precision': 0.934010152284264, 'recall': 0.9671484888304862, 'f1': 0.9502905100064557, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9811046511627907, 'recall': 0.995575221238938, 'f1': 0.9882869692532942, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.122205</td>\n",
       "      <td>0.954763</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.960948</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9237918215613383, 'recall': 0.9576107899807321, 'f1': 0.9403973509933775, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9371794871794872, 'recall': 0.9605781865965834, 'f1': 0.9487345879299156, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.775, 'recall': 0.775, 'f1': 0.775, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.090055</td>\n",
       "      <td>0.968900</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.971959</td>\n",
       "      <td>0.980636</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.084723</td>\n",
       "      <td>0.967897</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.978898</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9711664482306684, 'recall': 0.973718791064389, 'f1': 0.9724409448818898, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8604651162790697, 'recall': 0.925, 'f1': 0.891566265060241, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.079523</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9882179675994109, 'f1': 0.9845928099779898, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9601518026565465, 'recall': 0.9749518304431599, 'f1': 0.9674952198852773, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.071382</td>\n",
       "      <td>0.972542</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.982249</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9837997054491899, 'f1': 0.9845246868091377, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9685452162516383, 'recall': 0.9710906701708278, 'f1': 0.9698162729658792, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882697947214076, 'recall': 0.9941002949852508, 'f1': 0.9911764705882352, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7906976744186046, 'recall': 0.85, 'f1': 0.8192771084337349, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.067085</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.978629</td>\n",
       "      <td>0.985228</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9564393939393939, 'recall': 0.9730250481695568, 'f1': 0.9646609360076409, 'number': 519}</td>\n",
       "      <td>{'precision': 0.970013037809648, 'recall': 0.9776609724047306, 'f1': 0.9738219895287958, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9230769230769231, 'recall': 0.9, 'f1': 0.9113924050632911, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.066567</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.978018</td>\n",
       "      <td>0.973845</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>{'precision': 0.9853587115666179, 'recall': 0.9911634756995582, 'f1': 0.9882525697503671, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9622395833333334, 'recall': 0.9710906701708278, 'f1': 0.9666448659254414, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8048780487804879, 'recall': 0.825, 'f1': 0.8148148148148149, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>0.972284</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.976252</td>\n",
       "      <td>0.982746</td>\n",
       "      <td>{'precision': 0.9896907216494846, 'recall': 0.9896907216494846, 'f1': 0.9896907216494846, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9509433962264151, 'recall': 0.9710982658959537, 'f1': 0.9609151572926596, 'number': 519}</td>\n",
       "      <td>{'precision': 0.96484375, 'recall': 0.973718791064389, 'f1': 0.9692609548724657, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8372093023255814, 'recall': 0.9, 'f1': 0.8674698795180723, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.067575</td>\n",
       "      <td>0.971852</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.974740</td>\n",
       "      <td>0.981256</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9926362297496318, 'f1': 0.9919058130978661, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9672346002621232, 'recall': 0.9697766097240473, 'f1': 0.968503937007874, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.069606</td>\n",
       "      <td>0.972150</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.973777</td>\n",
       "      <td>0.981877</td>\n",
       "      <td>{'precision': 0.9881831610044313, 'recall': 0.9852724594992637, 'f1': 0.9867256637168141, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9655172413793104, 'recall': 0.9710982658959537, 'f1': 0.968299711815562, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9595300261096605, 'recall': 0.9658344283837057, 'f1': 0.962671905697446, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7674418604651163, 'recall': 0.825, 'f1': 0.7951807228915662, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.067246</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.977349</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9528301886792453, 'recall': 0.9730250481695568, 'f1': 0.9628217349857006, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9686274509803922, 'recall': 0.973718791064389, 'f1': 0.9711664482306683, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8536585365853658, 'recall': 0.875, 'f1': 0.8641975308641976, 'number': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9301310043668122, 'recall': 0.9410898379970545, 'f1': 0.9355783308931186, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9064220183486239, 'recall': 0.9518304431599229, 'f1': 0.9285714285714286, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.934010152284264, 'recall': 0.9671484888304862, 'f1': 0.9502905100064557, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9811046511627907, 'recall': 0.995575221238938, 'f1': 0.9882869692532942, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9237918215613383, 'recall': 0.9576107899807321, 'f1': 0.9403973509933775, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9371794871794872, 'recall': 0.9605781865965834, 'f1': 0.9487345879299156, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.775, 'f1': 0.775, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9711664482306684, 'recall': 0.973718791064389, 'f1': 0.9724409448818898, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8604651162790697, 'recall': 0.925, 'f1': 0.891566265060241, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9882179675994109, 'f1': 0.9845928099779898, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601518026565465, 'recall': 0.9749518304431599, 'f1': 0.9674952198852773, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9837997054491899, 'f1': 0.9845246868091377, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685452162516383, 'recall': 0.9710906701708278, 'f1': 0.9698162729658792, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9882697947214076, 'recall': 0.9941002949852508, 'f1': 0.9911764705882352, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7906976744186046, 'recall': 0.85, 'f1': 0.8192771084337349, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9564393939393939, 'recall': 0.9730250481695568, 'f1': 0.9646609360076409, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.970013037809648, 'recall': 0.9776609724047306, 'f1': 0.9738219895287958, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9230769230769231, 'recall': 0.9, 'f1': 0.9113924050632911, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853587115666179, 'recall': 0.9911634756995582, 'f1': 0.9882525697503671, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622395833333334, 'recall': 0.9710906701708278, 'f1': 0.9666448659254414, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8048780487804879, 'recall': 0.825, 'f1': 0.8148148148148149, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896907216494846, 'recall': 0.9896907216494846, 'f1': 0.9896907216494846, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9509433962264151, 'recall': 0.9710982658959537, 'f1': 0.9609151572926596, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.96484375, 'recall': 0.973718791064389, 'f1': 0.9692609548724657, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8372093023255814, 'recall': 0.9, 'f1': 0.8674698795180723, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9926362297496318, 'f1': 0.9919058130978661, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9672346002621232, 'recall': 0.9697766097240473, 'f1': 0.968503937007874, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.875, 'f1': 0.875, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881831610044313, 'recall': 0.9852724594992637, 'f1': 0.9867256637168141, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9655172413793104, 'recall': 0.9710982658959537, 'f1': 0.968299711815562, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9595300261096605, 'recall': 0.9658344283837057, 'f1': 0.962671905697446, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7674418604651163, 'recall': 0.825, 'f1': 0.7951807228915662, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9911634756995582, 'f1': 0.9904341427520236, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9528301886792453, 'recall': 0.9730250481695568, 'f1': 0.9628217349857006, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686274509803922, 'recall': 0.973718791064389, 'f1': 0.9711664482306683, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8536585365853658, 'recall': 0.875, 'f1': 0.8641975308641976, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700 (score: 0.9786285077123211).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9700352526439483, 'recall': 0.9792408066429419, 'f1': 0.9746162927981109, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9072907290729073, 'recall': 0.9213893967093236, 'f1': 0.9142857142857143, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.968421052631579, 'recall': 0.9781757134862898, 'f1': 0.9732739420935412, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9954337899543378, 'recall': 0.9960022844089091, 'f1': 0.995717956037682, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.2857142857142857, 'f1': 0.38095238095238093, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8125, 'recall': 0.6842105263157895, 'f1': 0.742857142857143, 'number': 76}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9564393939393939, 'recall': 0.9730250481695568, 'f1': 0.9646609360076409, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.970013037809648, 'recall': 0.9776609724047306, 'f1': 0.9738219895287958, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9230769230769231, 'recall': 0.9, 'f1': 0.9113924050632911, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/5000 04:22 < 09:17, 6.09 it/s, Epoch 4/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195575</td>\n",
       "      <td>0.951345</td>\n",
       "      <td>0.961624</td>\n",
       "      <td>0.956457</td>\n",
       "      <td>0.967478</td>\n",
       "      <td>{'precision': 0.9429824561403509, 'recall': 0.9499263622974963, 'f1': 0.946441672780631, 'number': 679}</td>\n",
       "      <td>{'precision': 0.924953095684803, 'recall': 0.9499036608863198, 'f1': 0.9372623574144486, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9447300771208226, 'recall': 0.9658344283837057, 'f1': 0.9551656920077972, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8918918918918919, 'recall': 0.825, 'f1': 0.8571428571428571, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127699</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.967586</td>\n",
       "      <td>0.960074</td>\n",
       "      <td>0.972195</td>\n",
       "      <td>{'precision': 0.9778761061946902, 'recall': 0.9764359351988218, 'f1': 0.9771554900515844, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9658344283837057, 'f1': 0.9514563106796117, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7142857142857143, 'recall': 0.75, 'f1': 0.7317073170731706, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093763</td>\n",
       "      <td>0.967371</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9430740037950665, 'recall': 0.9576107899807321, 'f1': 0.9502868068833653, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9570871261378413, 'recall': 0.9671484888304862, 'f1': 0.9620915032679739, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8292682926829268, 'recall': 0.85, 'f1': 0.8395061728395061, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.084287</td>\n",
       "      <td>0.966396</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.970697</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>{'precision': 0.9896907216494846, 'recall': 0.9896907216494846, 'f1': 0.9896907216494846, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9197761194029851, 'recall': 0.9499036608863198, 'f1': 0.9345971563981044, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.077302</td>\n",
       "      <td>0.963249</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.969843</td>\n",
       "      <td>0.978898</td>\n",
       "      <td>{'precision': 0.975254730713246, 'recall': 0.9867452135493373, 'f1': 0.9809663250366032, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9434447300771208, 'recall': 0.9645203679369251, 'f1': 0.9538661468486029, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8636363636363636, 'recall': 0.95, 'f1': 0.9047619047619048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.971471</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.982870</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.066134</td>\n",
       "      <td>0.973284</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.975274</td>\n",
       "      <td>0.984235</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9698952879581152, 'recall': 0.973718791064389, 'f1': 0.9718032786885246, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9230769230769231, 'recall': 0.9, 'f1': 0.9113924050632911, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.067265</td>\n",
       "      <td>0.967825</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.971418</td>\n",
       "      <td>0.981256</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8717948717948718, 'recall': 0.85, 'f1': 0.8607594936708861, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.976433</td>\n",
       "      <td>0.982746</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9623376623376624, 'recall': 0.973718791064389, 'f1': 0.9679947746570869, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.071779</td>\n",
       "      <td>0.974796</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.977332</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9882179675994109, 'f1': 0.9874908020603386, 'number': 679}</td>\n",
       "      <td>{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9750656167979003, 'recall': 0.9763469119579501, 'f1': 0.9757058437294812, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.061052</td>\n",
       "      <td>0.975528</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.977885</td>\n",
       "      <td>0.983987</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9712041884816754, 'recall': 0.9750328515111695, 'f1': 0.9731147540983607, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.972613</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.975863</td>\n",
       "      <td>0.982622</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9634941329856584, 'recall': 0.9710906701708278, 'f1': 0.9672774869109947, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.064738</td>\n",
       "      <td>0.971143</td>\n",
       "      <td>0.978018</td>\n",
       "      <td>0.974568</td>\n",
       "      <td>0.983366</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.875, 'f1': 0.8536585365853658, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.079960</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9487666034155597, 'recall': 0.9633911368015414, 'f1': 0.9560229445506693, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.918918918918919, 'recall': 0.85, 'f1': 0.8831168831168831, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.976606</td>\n",
       "      <td>0.981629</td>\n",
       "      <td>{'precision': 0.9853801169590644, 'recall': 0.9926362297496318, 'f1': 0.9889948642699926, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9563567362428842, 'recall': 0.9710982658959537, 'f1': 0.9636711281070746, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647519582245431, 'recall': 0.9710906701708278, 'f1': 0.9679109364767517, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.971587</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>0.982870</td>\n",
       "      <td>{'precision': 0.9839650145772595, 'recall': 0.9941089837997055, 'f1': 0.9890109890109892, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9686684073107049, 'recall': 0.9750328515111695, 'f1': 0.9718402095612311, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.42857142857142855, 'f1': 0.39999999999999997, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9429824561403509, 'recall': 0.9499263622974963, 'f1': 0.946441672780631, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924953095684803, 'recall': 0.9499036608863198, 'f1': 0.9372623574144486, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9447300771208226, 'recall': 0.9658344283837057, 'f1': 0.9551656920077972, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8918918918918919, 'recall': 0.825, 'f1': 0.8571428571428571, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778761061946902, 'recall': 0.9764359351988218, 'f1': 0.9771554900515844, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9658344283837057, 'f1': 0.9514563106796117, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7142857142857143, 'recall': 0.75, 'f1': 0.7317073170731706, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9430740037950665, 'recall': 0.9576107899807321, 'f1': 0.9502868068833653, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9570871261378413, 'recall': 0.9671484888304862, 'f1': 0.9620915032679739, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8292682926829268, 'recall': 0.85, 'f1': 0.8395061728395061, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896907216494846, 'recall': 0.9896907216494846, 'f1': 0.9896907216494846, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9197761194029851, 'recall': 0.9499036608863198, 'f1': 0.9345971563981044, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975254730713246, 'recall': 0.9867452135493373, 'f1': 0.9809663250366032, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9434447300771208, 'recall': 0.9645203679369251, 'f1': 0.9538661468486029, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8636363636363636, 'recall': 0.95, 'f1': 0.9047619047619048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9698952879581152, 'recall': 0.973718791064389, 'f1': 0.9718032786885246, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9230769230769231, 'recall': 0.9, 'f1': 0.9113924050632911, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8717948717948718, 'recall': 0.85, 'f1': 0.8607594936708861, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9623376623376624, 'recall': 0.973718791064389, 'f1': 0.9679947746570869, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9882179675994109, 'f1': 0.9874908020603386, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750656167979003, 'recall': 0.9763469119579501, 'f1': 0.9757058437294812, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9712041884816754, 'recall': 0.9750328515111695, 'f1': 0.9731147540983607, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9911634756995582, 'f1': 0.9911634756995582, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9634941329856584, 'recall': 0.9710906701708278, 'f1': 0.9672774869109947, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.875, 'f1': 0.8536585365853658, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9487666034155597, 'recall': 0.9633911368015414, 'f1': 0.9560229445506693, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9634464751958225, 'recall': 0.9697766097240473, 'f1': 0.9666011787819255, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.918918918918919, 'recall': 0.85, 'f1': 0.8831168831168831, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853801169590644, 'recall': 0.9926362297496318, 'f1': 0.9889948642699926, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9563567362428842, 'recall': 0.9710982658959537, 'f1': 0.9636711281070746, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647519582245431, 'recall': 0.9710906701708278, 'f1': 0.9679109364767517, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9839650145772595, 'recall': 0.9941089837997055, 'f1': 0.9890109890109892, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686684073107049, 'recall': 0.9750328515111695, 'f1': 0.9718402095612311, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.42857142857142855, 'f1': 0.39999999999999997, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100 (score: 0.9778851514588367).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9595545134818289, 'recall': 0.9709371293001187, 'f1': 0.9652122641509434, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9005424954792043, 'recall': 0.9104204753199269, 'f1': 0.9054545454545454, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9716035634743875, 'recall': 0.9764969222160045, 'f1': 0.9740440971253139, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9971493728620296, 'recall': 0.9988577955454027, 'f1': 0.9980028530670471, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5384615384615384, 'recall': 0.5, 'f1': 0.5185185185185186, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7866666666666666, 'recall': 0.7763157894736842, 'f1': 0.7814569536423841, 'number': 76}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9926362297496318, 'f1': 0.9926362297496318, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9712041884816754, 'recall': 0.9750328515111695, 'f1': 0.9731147540983607, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 04:01 < 09:23, 6.21 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209653</td>\n",
       "      <td>0.934438</td>\n",
       "      <td>0.945231</td>\n",
       "      <td>0.939804</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>{'precision': 0.9254385964912281, 'recall': 0.9322533136966127, 'f1': 0.9288334556126192, 'number': 679}</td>\n",
       "      <td>{'precision': 0.8864864864864865, 'recall': 0.9479768786127167, 'f1': 0.9162011173184358, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9310344827586207, 'recall': 0.9579500657030223, 'f1': 0.944300518134715, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.2, 'f1': 0.32000000000000006, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>0.947465</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>0.954125</td>\n",
       "      <td>0.976663</td>\n",
       "      <td>{'precision': 0.9576642335766423, 'recall': 0.9661266568483063, 'f1': 0.9618768328445747, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9345794392523364, 'recall': 0.9633911368015414, 'f1': 0.9487666034155597, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9332477535301669, 'recall': 0.9553219448094612, 'f1': 0.9441558441558441, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.525, 'recall': 0.525, 'f1': 0.525, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093548</td>\n",
       "      <td>0.970971</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.971514</td>\n",
       "      <td>0.980015</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9764359351988218, 'f1': 0.9778761061946903, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}</td>\n",
       "      <td>{'precision': 0.973718791064389, 'recall': 0.973718791064389, 'f1': 0.973718791064389, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.75, 'f1': 0.7999999999999999, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.083349</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.971768</td>\n",
       "      <td>0.978401</td>\n",
       "      <td>{'precision': 0.986784140969163, 'recall': 0.9896907216494846, 'f1': 0.9882352941176471, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9358490566037736, 'recall': 0.9556840077071291, 'f1': 0.9456625357483317, 'number': 519}</td>\n",
       "      <td>{'precision': 0.968421052631579, 'recall': 0.9671484888304862, 'f1': 0.9677843523997371, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7906976744186046, 'recall': 0.85, 'f1': 0.8192771084337349, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.082293</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>0.969449</td>\n",
       "      <td>0.966029</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9494163424124513, 'recall': 0.961892247043364, 'f1': 0.9556135770234986, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9896602658788775, 'recall': 0.9882005899705014, 'f1': 0.9889298892988929, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.85, 'f1': 0.85, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.072968</td>\n",
       "      <td>0.969316</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9633507853403142, 'recall': 0.9671484888304862, 'f1': 0.9652459016393442, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.064974</td>\n",
       "      <td>0.974397</td>\n",
       "      <td>0.978390</td>\n",
       "      <td>0.976390</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9617590822179732, 'recall': 0.9691714836223507, 'f1': 0.9654510556621881, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647979139504563, 'recall': 0.9724047306176085, 'f1': 0.968586387434555, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.971090</td>\n",
       "      <td>0.976155</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.060429</td>\n",
       "      <td>0.974007</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.975637</td>\n",
       "      <td>0.984235</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9852724594992637, 'f1': 0.9852724594992637, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9599236641221374, 'recall': 0.9691714836223507, 'f1': 0.9645254074784276, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.065796</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.978621</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9547169811320755, 'recall': 0.9749518304431599, 'f1': 0.9647283126787417, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9724409448818898, 'recall': 0.973718791064389, 'f1': 0.9730794484569928, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.064012</td>\n",
       "      <td>0.975148</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.977323</td>\n",
       "      <td>0.982622</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9926362297496318, 'f1': 0.9919058130978661, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9685863874345549, 'recall': 0.9724047306176085, 'f1': 0.9704918032786886, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.972542</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9483747609942639, 'recall': 0.9556840077071291, 'f1': 0.9520153550863724, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9660130718954248, 'recall': 0.9710906701708278, 'f1': 0.9685452162516384, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.061499</td>\n",
       "      <td>0.972613</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.975863</td>\n",
       "      <td>0.983491</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.066505</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.976960</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9528301886792453, 'recall': 0.9730250481695568, 'f1': 0.9628217349857006, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9673202614379085, 'recall': 0.9724047306176085, 'f1': 0.9698558322411535, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.981256</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}</td>\n",
       "      <td>{'precision': 0.950381679389313, 'recall': 0.9595375722543352, 'f1': 0.9549376797698945, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9572538860103627, 'recall': 0.9710906701708278, 'f1': 0.964122635355512, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9254385964912281, 'recall': 0.9322533136966127, 'f1': 0.9288334556126192, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8864864864864865, 'recall': 0.9479768786127167, 'f1': 0.9162011173184358, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9310344827586207, 'recall': 0.9579500657030223, 'f1': 0.944300518134715, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.2, 'f1': 0.32000000000000006, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9576642335766423, 'recall': 0.9661266568483063, 'f1': 0.9618768328445747, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9345794392523364, 'recall': 0.9633911368015414, 'f1': 0.9487666034155597, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9332477535301669, 'recall': 0.9553219448094612, 'f1': 0.9441558441558441, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.525, 'recall': 0.525, 'f1': 0.525, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9764359351988218, 'f1': 0.9778761061946903, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.973718791064389, 'recall': 0.973718791064389, 'f1': 0.973718791064389, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.75, 'f1': 0.7999999999999999, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986784140969163, 'recall': 0.9896907216494846, 'f1': 0.9882352941176471, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9358490566037736, 'recall': 0.9556840077071291, 'f1': 0.9456625357483317, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.968421052631579, 'recall': 0.9671484888304862, 'f1': 0.9677843523997371, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7906976744186046, 'recall': 0.85, 'f1': 0.8192771084337349, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9494163424124513, 'recall': 0.961892247043364, 'f1': 0.9556135770234986, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896602658788775, 'recall': 0.9882005899705014, 'f1': 0.9889298892988929, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.85, 'f1': 0.85, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633507853403142, 'recall': 0.9671484888304862, 'f1': 0.9652459016393442, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9, 'f1': 0.8780487804878048, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9617590822179732, 'recall': 0.9691714836223507, 'f1': 0.9654510556621881, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647979139504563, 'recall': 0.9724047306176085, 'f1': 0.968586387434555, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9867452135493373, 'f1': 0.9867452135493373, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9852724594992637, 'f1': 0.9852724594992637, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9599236641221374, 'recall': 0.9691714836223507, 'f1': 0.9645254074784276, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9547169811320755, 'recall': 0.9749518304431599, 'f1': 0.9647283126787417, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724409448818898, 'recall': 0.973718791064389, 'f1': 0.9730794484569928, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9926362297496318, 'f1': 0.9919058130978661, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685863874345549, 'recall': 0.9724047306176085, 'f1': 0.9704918032786886, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9483747609942639, 'recall': 0.9556840077071291, 'f1': 0.9520153550863724, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9660130718954248, 'recall': 0.9710906701708278, 'f1': 0.9685452162516384, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9882179675994109, 'f1': 0.986764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9528301886792453, 'recall': 0.9730250481695568, 'f1': 0.9628217349857006, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9673202614379085, 'recall': 0.9724047306176085, 'f1': 0.9698558322411535, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.9, 'f1': 0.9, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9896907216494846, 'f1': 0.9889624724061811, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.950381679389313, 'recall': 0.9595375722543352, 'f1': 0.9549376797698945, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9572538860103627, 'recall': 0.9710906701708278, 'f1': 0.964122635355512, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9024390243902439, 'recall': 0.925, 'f1': 0.9135802469135802, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1000 (score: 0.9786205614426474).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/22-flat-ner-ref-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9864146485528648, 'recall': 0.9905100830367735, 'f1': 0.9884581237052383, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9066079295154185, 'recall': 0.9405850091407678, 'f1': 0.9232839838492597, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661487236403996, 'recall': 0.974258533855624, 'f1': 0.9701866815268878, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9965733866362079, 'recall': 0.9965733866362079, 'f1': 0.9965733866362079, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5555555555555556, 'recall': 0.35714285714285715, 'f1': 0.43478260869565216, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7901234567901234, 'recall': 0.8421052631578947, 'f1': 0.8152866242038217, 'number': 76}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9882179675994109, 'f1': 0.9882179675994109, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9547169811320755, 'recall': 0.9749518304431599, 'f1': 0.9647283126787417, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724409448818898, 'recall': 0.973718791064389, 'f1': 0.9730794484569928, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.925, 'recall': 0.925, 'f1': 0.925, 'number': 40}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:04:14.299347\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "    print(MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH)\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning Pretrained CamemBERT model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
