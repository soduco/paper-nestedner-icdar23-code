{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294705ff-9e89-499f-a41f-9494362be5f9",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "source": [
    "# 40 - Experiment #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e498466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" #Numéro GPU\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e9f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flD_9oT8LmDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flD_9oT8LmDB",
    "outputId": "63a92e5f-d414-46cc-db86-b46981e42594"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZvwNIzqBwDs",
   "metadata": {
    "id": "cZvwNIzqBwDs",
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "Set the BASE path.\n",
    "If run on Google Colab, will also mout Google Drive to the moutpoint given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LWJVak2mB6bI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWJVak2mB6bI",
    "outputId": "dbb54104-560b-480c-d4b0-74a0787e2024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lrde/home2/stual/stage_DAS/m0_flat_ner', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages']\n",
      "/lrde/home2/stual/stage_DAS/m0_flat_ner\n",
      "/work/stual/dataset_ICDAR\n",
      "/work/stual/res_ICDAR/method_0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset\"\n",
    "else:\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "  DATASETS = Path('/work/stual/dataset_ICDAR')\n",
    "  OUT_BASE = Path('/work/stual/res_ICDAR/method_0')\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a270f9-5f9e-449e-bbff-69136b383507",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "RUN_CAMEMBERT = False             # Set to false to skip training Camembert\n",
    "RUN_CAMEMBERT_PRETRAINED = True  # Set to false to skip training Camembert pretrained\n",
    "\n",
    "# Number of times a model will be trained & evaluated on each of the 8 trainsets.\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03c89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RUN_CAMEMBERT != RUN_CAMEMBERT_PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a4112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CAMEMBERT:\n",
    "    MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "    MODEL_NAME = 'camembert_ner'\n",
    "    FOLDER = f\"41-flat-ner-pero-ocr-{MODEL_NAME}\"\n",
    "    \n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "    MODEL_NAME = 'pretrained_camembert_ner'\n",
    "    FOLDER = f\"42-flat-ner-pero-ocr-{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hxHdPTBlCCFO",
   "metadata": {
    "id": "hxHdPTBlCCFO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_0/02-experiment_2_prepared_pero_ocr_dataset_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_0/40-experiment_2_metrics'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = OUT_BASE / f\"02-experiment_2_prepared_pero_ocr_dataset_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"40-experiment_2_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {
    "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed"
   },
   "source": [
    "## 22 - CamemBERT - Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {
    "id": "91140aa5-b377-47c1-bd44-844cd9365ec3"
   },
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100, #Une éval toutes les 100 itérations ????\n",
    "    \"max_steps\": 5000,# Nombre maximal d'itérations\n",
    "    \"learning_rate\": 1e-4,#Vitesse d'apprentissage\n",
    "    \"per_device_train_batch_size\": 16,#Batch size train\n",
    "    \"per_device_eval_batch_size\": 16,#Batch size évaluation\n",
    "    \"weight_decay\": 1e-5,#Méthode de dégradation des pondérations (limiter le sur apprentissage)\n",
    "    \"load_best_model_at_end\": True,#Charger le meilleur modèle à la fin de l'entrainement\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",#Métrique utilisée pour le choix du meilleur modèle F1-SCore\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100, # Make Early callback bug ?\n",
    "    \"save_total_limit\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:27:25.669379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 15:27:27.572513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:27:27.572628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:27:27.572642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "import json\n",
    "from camembert_util import init_model, train_eval_loop, _convert_tokenizer\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de0446-e62f-46d5-ae73-34112f3c420d",
   "metadata": {
    "id": "09de0446-e62f-46d5-ae73-34112f3c420d"
   },
   "source": [
    "## 41 - CamemBERT - train & eval on Pero OCR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05387e39-dd69-491e-9517-57490356e5e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05387e39-dd69-491e-9517-57490356e5e9",
    "outputId": "a894e899-0646-4260-f12f-7468adfbb5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning model for IO labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    print(MODEL_METRICS_DIR,MODEL_OUTPUT_MODEL_PATH)\n",
    "    \n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IO labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60",
   "metadata": {
    "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60"
   },
   "source": [
    "## 42 - CamemBERT pretrained - train & eval on Pero OCR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
    "outputId": "077e0a27-cd2b-41e4-a080-80292418d483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/stual/res_ICDAR/method_0/40-experiment_2_metrics/42-flat-ner-pero-ocr-pretrained_camembert_ner /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/5000 06:49 < 06:49, 6.10 it/s, Epoch 6/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229753</td>\n",
       "      <td>0.930147</td>\n",
       "      <td>0.942272</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.955454</td>\n",
       "      <td>{'precision': 0.927536231884058, 'recall': 0.9425625920471281, 'f1': 0.9349890430971513, 'number': 679}</td>\n",
       "      <td>{'precision': 0.8898916967509025, 'recall': 0.9499036608863198, 'f1': 0.9189189189189189, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9363636363636364, 'recall': 0.9474375821287779, 'f1': 0.9418680600914435, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9612068965517241, 'recall': 0.9867256637168141, 'f1': 0.9737991266375545, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7, 'recall': 0.17073170731707318, 'f1': 0.2745098039215686, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145264</td>\n",
       "      <td>0.946304</td>\n",
       "      <td>0.958287</td>\n",
       "      <td>0.952258</td>\n",
       "      <td>0.965705</td>\n",
       "      <td>{'precision': 0.966374269005848, 'recall': 0.9734904270986745, 'f1': 0.9699192956713133, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9109461966604824, 'recall': 0.9460500963391136, 'f1': 0.9281663516068053, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9380645161290323, 'recall': 0.9553219448094612, 'f1': 0.9466145833333334, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9766081871345029, 'recall': 0.9852507374631269, 'f1': 0.9809104258443465, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7027027027027027, 'recall': 0.6341463414634146, 'f1': 0.6666666666666667, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114246</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.962384</td>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>{'precision': 0.9605839416058394, 'recall': 0.9690721649484536, 'f1': 0.9648093841642228, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9395085066162571, 'recall': 0.9576107899807321, 'f1': 0.9484732824427481, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9530638852672751, 'recall': 0.9605781865965834, 'f1': 0.956806282722513, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7297297297297297, 'recall': 0.6585365853658537, 'f1': 0.6923076923076923, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.097431</td>\n",
       "      <td>0.956474</td>\n",
       "      <td>0.965736</td>\n",
       "      <td>0.961082</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>{'precision': 0.973568281938326, 'recall': 0.9764359351988218, 'f1': 0.9750000000000001, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9322033898305084, 'recall': 0.953757225433526, 'f1': 0.9428571428571428, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9421593830334191, 'recall': 0.9632063074901446, 'f1': 0.9525666016894087, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.108134</td>\n",
       "      <td>0.950862</td>\n",
       "      <td>0.965736</td>\n",
       "      <td>0.958241</td>\n",
       "      <td>0.970261</td>\n",
       "      <td>{'precision': 0.9608127721335269, 'recall': 0.9749631811487481, 'f1': 0.9678362573099416, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9292364990689013, 'recall': 0.9614643545279383, 'f1': 0.9450757575757575, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9432989690721649, 'recall': 0.961892247043364, 'f1': 0.9525048796356539, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9794721407624634, 'recall': 0.9852507374631269, 'f1': 0.9823529411764708, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7837837837837838, 'recall': 0.7073170731707317, 'f1': 0.7435897435897435, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.091022</td>\n",
       "      <td>0.956795</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.960875</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>{'precision': 0.9735294117647059, 'recall': 0.9749631811487481, 'f1': 0.9742457689477557, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9358490566037736, 'recall': 0.9556840077071291, 'f1': 0.9456625357483317, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9483204134366925, 'recall': 0.9645203679369251, 'f1': 0.9563517915309447, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7027027027027027, 'recall': 0.6341463414634146, 'f1': 0.6666666666666667, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.963388</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.966784</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>{'precision': 0.9736070381231672, 'recall': 0.9779086892488954, 'f1': 0.9757531227038941, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9571428571428572, 'recall': 0.9684625492772667, 'f1': 0.9627694317439582, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.7560975609756098, 'f1': 0.7948717948717948, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.079648</td>\n",
       "      <td>0.964431</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.966939</td>\n",
       "      <td>0.976968</td>\n",
       "      <td>{'precision': 0.975, 'recall': 0.9764359351988218, 'f1': 0.9757174392935982, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9455909943714822, 'recall': 0.9710982658959537, 'f1': 0.9581749049429659, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9607843137254902, 'recall': 0.9658344283837057, 'f1': 0.9633027522935781, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9852507374631269, 'f1': 0.9830757910228108, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.079853</td>\n",
       "      <td>0.964497</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.967898</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9560723514211886, 'recall': 0.9724047306176085, 'f1': 0.964169381107492, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9852507374631269, 'f1': 0.9859778597785978, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>{'precision': 0.9750733137829912, 'recall': 0.979381443298969, 'f1': 0.9772226304188096, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9490566037735849, 'recall': 0.9691714836223507, 'f1': 0.9590085795996187, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9646133682830931, 'recall': 0.9671484888304862, 'f1': 0.9658792650918635, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.075752</td>\n",
       "      <td>0.968136</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9867452135493373, 'f1': 0.9845701689933872, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9487666034155597, 'recall': 0.9633911368015414, 'f1': 0.9560229445506693, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609882964889467, 'recall': 0.9710906701708278, 'f1': 0.9660130718954247, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.970665</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9852724594992637, 'f1': 0.9838235294117648, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9660130718954248, 'recall': 0.9710906701708278, 'f1': 0.9685452162516384, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9852507374631269, 'f1': 0.9830757910228108, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.075434</td>\n",
       "      <td>0.964945</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7380952380952381, 'recall': 0.7560975609756098, 'f1': 0.746987951807229, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.072886</td>\n",
       "      <td>0.969259</td>\n",
       "      <td>0.974674</td>\n",
       "      <td>0.971959</td>\n",
       "      <td>0.982663</td>\n",
       "      <td>{'precision': 0.9794419970631424, 'recall': 0.9823269513991163, 'f1': 0.9808823529411764, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9454887218045113, 'recall': 0.9691714836223507, 'f1': 0.9571836346336823, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647519582245431, 'recall': 0.9710906701708278, 'f1': 0.9679109364767517, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9210526315789473, 'recall': 0.8536585365853658, 'f1': 0.8860759493670887, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.965262</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.969022</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9867452135493373, 'f1': 0.9838472834067548, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9418386491557224, 'recall': 0.9672447013487476, 'f1': 0.9543726235741444, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.967122</td>\n",
       "      <td>0.975047</td>\n",
       "      <td>0.971068</td>\n",
       "      <td>0.982916</td>\n",
       "      <td>{'precision': 0.9809384164222874, 'recall': 0.9852724594992637, 'f1': 0.9831006612784718, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9491525423728814, 'recall': 0.9710982658959537, 'f1': 0.96, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.080552</td>\n",
       "      <td>0.970337</td>\n",
       "      <td>0.974674</td>\n",
       "      <td>0.972501</td>\n",
       "      <td>0.982789</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9637404580152672, 'recall': 0.9730250481695568, 'f1': 0.9683604985618408, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8536585365853658, 'recall': 0.8536585365853658, 'f1': 0.8536585365853658, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.075418</td>\n",
       "      <td>0.967407</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.970102</td>\n",
       "      <td>0.981777</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9852724594992637, 'f1': 0.9845474613686533, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9608355091383812, 'recall': 0.9671484888304862, 'f1': 0.9639816633922725, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.8780487804878049, 'f1': 0.888888888888889, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>0.975047</td>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.983295</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9473684210526315, 'recall': 0.9710982658959537, 'f1': 0.9590865842055185, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.9210526315789473, 'recall': 0.8536585365853658, 'f1': 0.8860759493670887, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.080203</td>\n",
       "      <td>0.969675</td>\n",
       "      <td>0.976536</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}</td>\n",
       "      <td>{'precision': 0.960377358490566, 'recall': 0.9807321772639692, 'f1': 0.9704480457578646, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.093690</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.966284</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9333333333333333, 'recall': 0.9710982658959537, 'f1': 0.9518413597733711, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9581699346405229, 'recall': 0.9632063074901446, 'f1': 0.9606815203145479, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9794721407624634, 'recall': 0.9852507374631269, 'f1': 0.9823529411764708, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.091036</td>\n",
       "      <td>0.966396</td>\n",
       "      <td>0.974674</td>\n",
       "      <td>0.970517</td>\n",
       "      <td>0.981271</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9420560747663551, 'recall': 0.9710982658959537, 'f1': 0.9563567362428842, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.093755</td>\n",
       "      <td>0.967086</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.970495</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9455909943714822, 'recall': 0.9710982658959537, 'f1': 0.9581749049429659, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9558441558441558, 'recall': 0.9671484888304862, 'f1': 0.9614630960156761, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.965581</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.968628</td>\n",
       "      <td>0.980891</td>\n",
       "      <td>{'precision': 0.9779411764705882, 'recall': 0.979381443298969, 'f1': 0.9786607799852832, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9511278195488722, 'recall': 0.9749518304431599, 'f1': 0.9628924833491912, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9543080939947781, 'recall': 0.9605781865965834, 'f1': 0.9574328749181402, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.825, 'recall': 0.8048780487804879, 'f1': 0.8148148148148149, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.090373</td>\n",
       "      <td>0.968507</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.971025</td>\n",
       "      <td>0.983042</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9476635514018692, 'recall': 0.976878612716763, 'f1': 0.9620493358633776, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9620915032679739, 'recall': 0.9671484888304862, 'f1': 0.9646133682830931, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9866863905325444, 'recall': 0.9837758112094396, 'f1': 0.9852289512555391, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.825, 'recall': 0.8048780487804879, 'f1': 0.8148148148148149, 'number': 41}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/stage_DAS/m0_flat_ner/camembert_util.py:101: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.927536231884058, 'recall': 0.9425625920471281, 'f1': 0.9349890430971513, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8898916967509025, 'recall': 0.9499036608863198, 'f1': 0.9189189189189189, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9363636363636364, 'recall': 0.9474375821287779, 'f1': 0.9418680600914435, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9612068965517241, 'recall': 0.9867256637168141, 'f1': 0.9737991266375545, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7, 'recall': 0.17073170731707318, 'f1': 0.2745098039215686, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.966374269005848, 'recall': 0.9734904270986745, 'f1': 0.9699192956713133, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9109461966604824, 'recall': 0.9460500963391136, 'f1': 0.9281663516068053, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9380645161290323, 'recall': 0.9553219448094612, 'f1': 0.9466145833333334, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9766081871345029, 'recall': 0.9852507374631269, 'f1': 0.9809104258443465, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7027027027027027, 'recall': 0.6341463414634146, 'f1': 0.6666666666666667, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9605839416058394, 'recall': 0.9690721649484536, 'f1': 0.9648093841642228, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9395085066162571, 'recall': 0.9576107899807321, 'f1': 0.9484732824427481, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530638852672751, 'recall': 0.9605781865965834, 'f1': 0.956806282722513, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7297297297297297, 'recall': 0.6585365853658537, 'f1': 0.6923076923076923, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.973568281938326, 'recall': 0.9764359351988218, 'f1': 0.9750000000000001, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9322033898305084, 'recall': 0.953757225433526, 'f1': 0.9428571428571428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9421593830334191, 'recall': 0.9632063074901446, 'f1': 0.9525666016894087, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608127721335269, 'recall': 0.9749631811487481, 'f1': 0.9678362573099416, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9292364990689013, 'recall': 0.9614643545279383, 'f1': 0.9450757575757575, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9432989690721649, 'recall': 0.961892247043364, 'f1': 0.9525048796356539, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794721407624634, 'recall': 0.9852507374631269, 'f1': 0.9823529411764708, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7837837837837838, 'recall': 0.7073170731707317, 'f1': 0.7435897435897435, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9735294117647059, 'recall': 0.9749631811487481, 'f1': 0.9742457689477557, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9358490566037736, 'recall': 0.9556840077071291, 'f1': 0.9456625357483317, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9483204134366925, 'recall': 0.9645203679369251, 'f1': 0.9563517915309447, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7027027027027027, 'recall': 0.6341463414634146, 'f1': 0.6666666666666667, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736070381231672, 'recall': 0.9779086892488954, 'f1': 0.9757531227038941, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9571428571428572, 'recall': 0.9684625492772667, 'f1': 0.9627694317439582, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.7560975609756098, 'f1': 0.7948717948717948, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975, 'recall': 0.9764359351988218, 'f1': 0.9757174392935982, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9455909943714822, 'recall': 0.9710982658959537, 'f1': 0.9581749049429659, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9607843137254902, 'recall': 0.9658344283837057, 'f1': 0.9633027522935781, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9852507374631269, 'f1': 0.9830757910228108, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9560723514211886, 'recall': 0.9724047306176085, 'f1': 0.964169381107492, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9852507374631269, 'f1': 0.9859778597785978, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750733137829912, 'recall': 0.979381443298969, 'f1': 0.9772226304188096, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9490566037735849, 'recall': 0.9691714836223507, 'f1': 0.9590085795996187, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9646133682830931, 'recall': 0.9671484888304862, 'f1': 0.9658792650918635, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9867452135493373, 'f1': 0.9845701689933872, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9487666034155597, 'recall': 0.9633911368015414, 'f1': 0.9560229445506693, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609882964889467, 'recall': 0.9710906701708278, 'f1': 0.9660130718954247, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.7317073170731707, 'f1': 0.7792207792207793, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9852724594992637, 'f1': 0.9838235294117648, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9660130718954248, 'recall': 0.9710906701708278, 'f1': 0.9685452162516384, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9852507374631269, 'f1': 0.9830757910228108, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9472693032015066, 'recall': 0.9691714836223507, 'f1': 0.9580952380952381, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7380952380952381, 'recall': 0.7560975609756098, 'f1': 0.746987951807229, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794419970631424, 'recall': 0.9823269513991163, 'f1': 0.9808823529411764, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9454887218045113, 'recall': 0.9691714836223507, 'f1': 0.9571836346336823, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647519582245431, 'recall': 0.9710906701708278, 'f1': 0.9679109364767517, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9210526315789473, 'recall': 0.8536585365853658, 'f1': 0.8860759493670887, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9867452135493373, 'f1': 0.9838472834067548, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9418386491557224, 'recall': 0.9672447013487476, 'f1': 0.9543726235741444, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809384164222874, 'recall': 0.9852724594992637, 'f1': 0.9831006612784718, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9491525423728814, 'recall': 0.9710982658959537, 'f1': 0.96, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9637404580152672, 'recall': 0.9730250481695568, 'f1': 0.9683604985618408, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8536585365853658, 'recall': 0.8536585365853658, 'f1': 0.8536585365853658, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9852724594992637, 'f1': 0.9845474613686533, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608355091383812, 'recall': 0.9671484888304862, 'f1': 0.9639816633922725, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.8780487804878049, 'f1': 0.888888888888889, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9473684210526315, 'recall': 0.9710982658959537, 'f1': 0.9590865842055185, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9210526315789473, 'recall': 0.8536585365853658, 'f1': 0.8860759493670887, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.960377358490566, 'recall': 0.9807321772639692, 'f1': 0.9704480457578646, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9333333333333333, 'recall': 0.9710982658959537, 'f1': 0.9518413597733711, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581699346405229, 'recall': 0.9632063074901446, 'f1': 0.9606815203145479, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794721407624634, 'recall': 0.9852507374631269, 'f1': 0.9823529411764708, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9420560747663551, 'recall': 0.9710982658959537, 'f1': 0.9563567362428842, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9455909943714822, 'recall': 0.9710982658959537, 'f1': 0.9581749049429659, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9558441558441558, 'recall': 0.9671484888304862, 'f1': 0.9614630960156761, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779411764705882, 'recall': 0.979381443298969, 'f1': 0.9786607799852832, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9511278195488722, 'recall': 0.9749518304431599, 'f1': 0.9628924833491912, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9543080939947781, 'recall': 0.9605781865965834, 'f1': 0.9574328749181402, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.825, 'recall': 0.8048780487804879, 'f1': 0.8148148148148149, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9476635514018692, 'recall': 0.976878612716763, 'f1': 0.9620493358633776, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620915032679739, 'recall': 0.9671484888304862, 'f1': 0.9646133682830931, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9866863905325444, 'recall': 0.9837758112094396, 'f1': 0.9852289512555391, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.825, 'recall': 0.8048780487804879, 'f1': 0.8148148148148149, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000 (score: 0.9730933382816849).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9594356261022927, 'recall': 0.9679715302491103, 'f1': 0.9636846767050488, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8733850129198967, 'recall': 0.926873857404022, 'f1': 0.8993348115299336, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398786541643684, 'recall': 0.9535534415221041, 'f1': 0.9466666666666667, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986796785304248, 'recall': 0.981724728726442, 'f1': 0.9842542227311767, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5333333333333333, 'recall': 0.5714285714285714, 'f1': 0.5517241379310344, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7375, 'recall': 0.7866666666666666, 'f1': 0.7612903225806452, 'number': 75}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.960377358490566, 'recall': 0.9807321772639692, 'f1': 0.9704480457578646, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 04:05 < 09:33, 6.10 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232911</td>\n",
       "      <td>0.937058</td>\n",
       "      <td>0.937058</td>\n",
       "      <td>0.937058</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>{'precision': 0.9368575624082232, 'recall': 0.9396170839469808, 'f1': 0.9382352941176471, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9023941068139963, 'recall': 0.9441233140655106, 'f1': 0.9227871939736346, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9362808842652796, 'recall': 0.9461235216819974, 'f1': 0.9411764705882354, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9653179190751445, 'recall': 0.9852507374631269, 'f1': 0.9751824817518248, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.950466</td>\n",
       "      <td>0.948346</td>\n",
       "      <td>0.969628</td>\n",
       "      <td>{'precision': 0.9587628865979382, 'recall': 0.9587628865979382, 'f1': 0.9587628865979382, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9202226345083488, 'recall': 0.9556840077071291, 'f1': 0.9376181474480151, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9311688311688312, 'recall': 0.9421813403416557, 'f1': 0.9366427171783148, 'number': 761}</td>\n",
       "      <td>{'precision': 0.985207100591716, 'recall': 0.9823008849557522, 'f1': 0.983751846381093, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.5365853658536586, 'f1': 0.5945945945945946, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113670</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.962011</td>\n",
       "      <td>0.959866</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>{'precision': 0.966275659824047, 'recall': 0.9705449189985272, 'f1': 0.9684055841293165, 'number': 679}</td>\n",
       "      <td>{'precision': 0.94106463878327, 'recall': 0.953757225433526, 'f1': 0.9473684210526315, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9529411764705882, 'recall': 0.9579500657030223, 'f1': 0.9554390563564876, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9852507374631269, 'f1': 0.9852507374631269, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.7317073170731707, 'f1': 0.7407407407407408, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.102116</td>\n",
       "      <td>0.957211</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.961824</td>\n",
       "      <td>0.972539</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9199255121042831, 'recall': 0.9518304431599229, 'f1': 0.9356060606060607, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9494818652849741, 'recall': 0.9632063074901446, 'f1': 0.9562948467058056, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7692307692307693, 'recall': 0.7317073170731707, 'f1': 0.7499999999999999, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.099562</td>\n",
       "      <td>0.956153</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>{'precision': 0.9736456808199122, 'recall': 0.979381443298969, 'f1': 0.9765051395007343, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9309701492537313, 'recall': 0.9614643545279383, 'f1': 0.9459715639810427, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9493506493506494, 'recall': 0.9605781865965834, 'f1': 0.9549314173742652, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6590909090909091, 'recall': 0.7073170731707317, 'f1': 0.6823529411764706, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.082562</td>\n",
       "      <td>0.957840</td>\n",
       "      <td>0.964618</td>\n",
       "      <td>0.961217</td>\n",
       "      <td>0.975449</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594240837696335, 'recall': 0.9632063074901446, 'f1': 0.961311475409836, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5869565217391305, 'recall': 0.6585365853658537, 'f1': 0.6206896551724138, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.074909</td>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.967514</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9720588235294118, 'recall': 0.9734904270986745, 'f1': 0.9727740986019131, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9633986928104575, 'recall': 0.9684625492772667, 'f1': 0.9659239842726082, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7727272727272727, 'recall': 0.8292682926829268, 'f1': 0.7999999999999999, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.077936</td>\n",
       "      <td>0.961126</td>\n",
       "      <td>0.966853</td>\n",
       "      <td>0.963981</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6904761904761905, 'recall': 0.7073170731707317, 'f1': 0.6987951807228916, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.078974</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.966580</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>{'precision': 0.9706314243759178, 'recall': 0.9734904270986745, 'f1': 0.9720588235294119, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9453860640301318, 'recall': 0.9672447013487476, 'f1': 0.9561904761904761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9571428571428572, 'recall': 0.9684625492772667, 'f1': 0.9627694317439582, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9910979228486647, 'recall': 0.9852507374631269, 'f1': 0.9881656804733727, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7857142857142857, 'recall': 0.8048780487804879, 'f1': 0.7951807228915663, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.074114</td>\n",
       "      <td>0.968148</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.970845</td>\n",
       "      <td>0.981397</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9509433962264151, 'recall': 0.9710982658959537, 'f1': 0.9609151572926596, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609882964889467, 'recall': 0.9710906701708278, 'f1': 0.9660130718954247, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>0.968460</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.970260</td>\n",
       "      <td>0.980258</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9491525423728814, 'recall': 0.9710982658959537, 'f1': 0.96, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9556135770234987, 'recall': 0.961892247043364, 'f1': 0.9587426326129667, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9881831610044313, 'recall': 0.9867256637168141, 'f1': 0.9874538745387453, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.082064</td>\n",
       "      <td>0.959274</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.962124</td>\n",
       "      <td>0.977474</td>\n",
       "      <td>{'precision': 0.9765051395007343, 'recall': 0.979381443298969, 'f1': 0.9779411764705883, 'number': 679}</td>\n",
       "      <td>{'precision': 0.926829268292683, 'recall': 0.9518304431599229, 'f1': 0.9391634980988594, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9568627450980393, 'recall': 0.961892247043364, 'f1': 0.9593709043250329, 'number': 761}</td>\n",
       "      <td>{'precision': 0.982274741506647, 'recall': 0.9808259587020649, 'f1': 0.981549815498155, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.7804878048780488, 'f1': 0.7901234567901235, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.078544</td>\n",
       "      <td>0.962717</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>0.980385</td>\n",
       "      <td>{'precision': 0.9736070381231672, 'recall': 0.9779086892488954, 'f1': 0.9757531227038941, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9583875162548765, 'recall': 0.9684625492772667, 'f1': 0.9633986928104575, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7560975609756098, 'recall': 0.7560975609756098, 'f1': 0.7560975609756099, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>0.981144</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9506641366223909, 'recall': 0.9653179190751445, 'f1': 0.9579349904397705, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9595827900912647, 'recall': 0.9671484888304862, 'f1': 0.9633507853403143, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.075332</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.967371</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9534282018111255, 'recall': 0.9684625492772667, 'f1': 0.9608865710560626, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8461538461538461, 'recall': 0.8048780487804879, 'f1': 0.8250000000000001, 'number': 41}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9368575624082232, 'recall': 0.9396170839469808, 'f1': 0.9382352941176471, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9023941068139963, 'recall': 0.9441233140655106, 'f1': 0.9227871939736346, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9362808842652796, 'recall': 0.9461235216819974, 'f1': 0.9411764705882354, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9653179190751445, 'recall': 0.9852507374631269, 'f1': 0.9751824817518248, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9587628865979382, 'recall': 0.9587628865979382, 'f1': 0.9587628865979382, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9202226345083488, 'recall': 0.9556840077071291, 'f1': 0.9376181474480151, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9311688311688312, 'recall': 0.9421813403416557, 'f1': 0.9366427171783148, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.985207100591716, 'recall': 0.9823008849557522, 'f1': 0.983751846381093, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5365853658536586, 'f1': 0.5945945945945946, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.966275659824047, 'recall': 0.9705449189985272, 'f1': 0.9684055841293165, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.94106463878327, 'recall': 0.953757225433526, 'f1': 0.9473684210526315, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529411764705882, 'recall': 0.9579500657030223, 'f1': 0.9554390563564876, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9852507374631269, 'f1': 0.9852507374631269, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.7317073170731707, 'f1': 0.7407407407407408, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9199255121042831, 'recall': 0.9518304431599229, 'f1': 0.9356060606060607, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9494818652849741, 'recall': 0.9632063074901446, 'f1': 0.9562948467058056, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7692307692307693, 'recall': 0.7317073170731707, 'f1': 0.7499999999999999, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736456808199122, 'recall': 0.979381443298969, 'f1': 0.9765051395007343, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9309701492537313, 'recall': 0.9614643545279383, 'f1': 0.9459715639810427, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9493506493506494, 'recall': 0.9605781865965834, 'f1': 0.9549314173742652, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6590909090909091, 'recall': 0.7073170731707317, 'f1': 0.6823529411764706, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594240837696335, 'recall': 0.9632063074901446, 'f1': 0.961311475409836, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5869565217391305, 'recall': 0.6585365853658537, 'f1': 0.6206896551724138, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720588235294118, 'recall': 0.9734904270986745, 'f1': 0.9727740986019131, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633986928104575, 'recall': 0.9684625492772667, 'f1': 0.9659239842726082, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7727272727272727, 'recall': 0.8292682926829268, 'f1': 0.7999999999999999, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6904761904761905, 'recall': 0.7073170731707317, 'f1': 0.6987951807228916, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9706314243759178, 'recall': 0.9734904270986745, 'f1': 0.9720588235294119, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9453860640301318, 'recall': 0.9672447013487476, 'f1': 0.9561904761904761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9571428571428572, 'recall': 0.9684625492772667, 'f1': 0.9627694317439582, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9910979228486647, 'recall': 0.9852507374631269, 'f1': 0.9881656804733727, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7857142857142857, 'recall': 0.8048780487804879, 'f1': 0.7951807228915663, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9509433962264151, 'recall': 0.9710982658959537, 'f1': 0.9609151572926596, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609882964889467, 'recall': 0.9710906701708278, 'f1': 0.9660130718954247, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9491525423728814, 'recall': 0.9710982658959537, 'f1': 0.96, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9556135770234987, 'recall': 0.961892247043364, 'f1': 0.9587426326129667, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881831610044313, 'recall': 0.9867256637168141, 'f1': 0.9874538745387453, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9765051395007343, 'recall': 0.979381443298969, 'f1': 0.9779411764705883, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.926829268292683, 'recall': 0.9518304431599229, 'f1': 0.9391634980988594, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9568627450980393, 'recall': 0.961892247043364, 'f1': 0.9593709043250329, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.982274741506647, 'recall': 0.9808259587020649, 'f1': 0.981549815498155, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.7804878048780488, 'f1': 0.7901234567901235, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736070381231672, 'recall': 0.9779086892488954, 'f1': 0.9757531227038941, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9583875162548765, 'recall': 0.9684625492772667, 'f1': 0.9633986928104575, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7560975609756098, 'recall': 0.7560975609756098, 'f1': 0.7560975609756099, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9867452135493373, 'f1': 0.986019131714496, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9506641366223909, 'recall': 0.9653179190751445, 'f1': 0.9579349904397705, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9595827900912647, 'recall': 0.9671484888304862, 'f1': 0.9633507853403143, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9837997054491899, 'f1': 0.9837997054491899, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9534282018111255, 'recall': 0.9684625492772667, 'f1': 0.9608865710560626, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8461538461538461, 'recall': 0.8048780487804879, 'f1': 0.8250000000000001, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000 (score: 0.9708449396471681).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9605882352941176, 'recall': 0.968564650059312, 'f1': 0.9645599527466037, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8877005347593583, 'recall': 0.9104204753199269, 'f1': 0.8989169675090253, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9404630650496141, 'recall': 0.9546726357022943, 'f1': 0.9475145792835323, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9889918887601391, 'recall': 0.9748715019988577, 'f1': 0.9818809318377911, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5833333333333334, 'recall': 0.5, 'f1': 0.5384615384615384, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.68, 'f1': 0.7132867132867132, 'number': 75}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9867452135493373, 'f1': 0.9852941176470588, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9509433962264151, 'recall': 0.9710982658959537, 'f1': 0.9609151572926596, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609882964889467, 'recall': 0.9710906701708278, 'f1': 0.9660130718954247, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 800/5000 02:07 < 11:09, 6.28 it/s, Epoch 2/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239299</td>\n",
       "      <td>0.921829</td>\n",
       "      <td>0.931099</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.952923</td>\n",
       "      <td>{'precision': 0.9014285714285715, 'recall': 0.9293078055964654, 'f1': 0.9151559100797679, 'number': 679}</td>\n",
       "      <td>{'precision': 0.8903107861060329, 'recall': 0.9383429672447013, 'f1': 0.9136960600375233, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9143222506393862, 'recall': 0.9395532194480947, 'f1': 0.9267660401814647, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9765739385065886, 'recall': 0.9837758112094396, 'f1': 0.9801616458486407, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147522</td>\n",
       "      <td>0.943771</td>\n",
       "      <td>0.956425</td>\n",
       "      <td>0.950055</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>{'precision': 0.9560761346998536, 'recall': 0.9617083946980854, 'f1': 0.958883994126285, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9193245778611632, 'recall': 0.9441233140655106, 'f1': 0.9315589353612168, 'number': 519}</td>\n",
       "      <td>{'precision': 0.928843710292249, 'recall': 0.9605781865965834, 'f1': 0.9444444444444444, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6486486486486487, 'recall': 0.5853658536585366, 'f1': 0.6153846153846153, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.105101</td>\n",
       "      <td>0.961809</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.963954</td>\n",
       "      <td>0.977474</td>\n",
       "      <td>{'precision': 0.9692532942898975, 'recall': 0.9749631811487481, 'f1': 0.9720998531571218, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9530638852672751, 'recall': 0.9605781865965834, 'f1': 0.956806282722513, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8421052631578947, 'recall': 0.7804878048780488, 'f1': 0.810126582278481, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>0.957549</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.961809</td>\n",
       "      <td>0.973931</td>\n",
       "      <td>{'precision': 0.9620991253644315, 'recall': 0.9720176730486009, 'f1': 0.967032967032967, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9305816135084428, 'recall': 0.9556840077071291, 'f1': 0.9429657794676807, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9620418848167539, 'recall': 0.9658344283837057, 'f1': 0.9639344262295081, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7560975609756098, 'recall': 0.7560975609756098, 'f1': 0.7560975609756099, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.099731</td>\n",
       "      <td>0.959630</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.962303</td>\n",
       "      <td>0.973804</td>\n",
       "      <td>{'precision': 0.9648609077598829, 'recall': 0.9705449189985272, 'f1': 0.9676945668135096, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}</td>\n",
       "      <td>{'precision': 0.953125, 'recall': 0.961892247043364, 'f1': 0.9574885546108568, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7837837837837838, 'recall': 0.7073170731707317, 'f1': 0.7435897435897435, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.101717</td>\n",
       "      <td>0.957502</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.961232</td>\n",
       "      <td>0.974690</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9632063074901446, 'recall': 0.9632063074901446, 'f1': 0.9632063074901446, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5609756097560976, 'f1': 0.5287356321839081, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.085785</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.962702</td>\n",
       "      <td>0.975449</td>\n",
       "      <td>{'precision': 0.9691176470588235, 'recall': 0.9705449189985272, 'f1': 0.9698307579102281, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.6829268292682927, 'f1': 0.674698795180723, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.090064</td>\n",
       "      <td>0.958287</td>\n",
       "      <td>0.966853</td>\n",
       "      <td>0.962551</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>{'precision': 0.975, 'recall': 0.9764359351988218, 'f1': 0.9757174392935982, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9370988446726572, 'recall': 0.9592641261498029, 'f1': 0.9480519480519481, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8484848484848485, 'recall': 0.6829268292682927, 'f1': 0.7567567567567567, 'number': 41}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9014285714285715, 'recall': 0.9293078055964654, 'f1': 0.9151559100797679, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8903107861060329, 'recall': 0.9383429672447013, 'f1': 0.9136960600375233, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9143222506393862, 'recall': 0.9395532194480947, 'f1': 0.9267660401814647, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9765739385065886, 'recall': 0.9837758112094396, 'f1': 0.9801616458486407, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9560761346998536, 'recall': 0.9617083946980854, 'f1': 0.958883994126285, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9193245778611632, 'recall': 0.9441233140655106, 'f1': 0.9315589353612168, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.928843710292249, 'recall': 0.9605781865965834, 'f1': 0.9444444444444444, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6486486486486487, 'recall': 0.5853658536585366, 'f1': 0.6153846153846153, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9692532942898975, 'recall': 0.9749631811487481, 'f1': 0.9720998531571218, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530638852672751, 'recall': 0.9605781865965834, 'f1': 0.956806282722513, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8421052631578947, 'recall': 0.7804878048780488, 'f1': 0.810126582278481, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620991253644315, 'recall': 0.9720176730486009, 'f1': 0.967032967032967, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9305816135084428, 'recall': 0.9556840077071291, 'f1': 0.9429657794676807, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620418848167539, 'recall': 0.9658344283837057, 'f1': 0.9639344262295081, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7560975609756098, 'recall': 0.7560975609756098, 'f1': 0.7560975609756099, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9648609077598829, 'recall': 0.9705449189985272, 'f1': 0.9676945668135096, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953125, 'recall': 0.961892247043364, 'f1': 0.9574885546108568, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7837837837837838, 'recall': 0.7073170731707317, 'f1': 0.7435897435897435, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9749631811487481, 'f1': 0.9735294117647058, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9632063074901446, 'recall': 0.9632063074901446, 'f1': 0.9632063074901446, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5609756097560976, 'f1': 0.5287356321839081, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9691176470588235, 'recall': 0.9705449189985272, 'f1': 0.9698307579102281, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.6829268292682927, 'f1': 0.674698795180723, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975, 'recall': 0.9764359351988218, 'f1': 0.9757174392935982, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9370988446726572, 'recall': 0.9592641261498029, 'f1': 0.9480519480519481, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8484848484848485, 'recall': 0.6829268292682927, 'f1': 0.7567567567567567, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300 (score: 0.9639539204756596).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9650680876258141, 'recall': 0.966785290628707, 'f1': 0.965925925925926, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.87677304964539, 'recall': 0.9040219378427788, 'f1': 0.8901890189018902, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.950974930362117, 'recall': 0.9552322327923894, 'f1': 0.9530988274706867, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9844200807847663, 'recall': 0.9743003997715591, 'f1': 0.9793340987370838, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6363636363636364, 'recall': 0.5, 'f1': 0.56, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.696969696969697, 'recall': 0.6133333333333333, 'f1': 0.652482269503546, 'number': 75}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9692532942898975, 'recall': 0.9749631811487481, 'f1': 0.9720998531571218, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530638852672751, 'recall': 0.9605781865965834, 'f1': 0.956806282722513, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8421052631578947, 'recall': 0.7804878048780488, 'f1': 0.810126582278481, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/5000 04:11 < 08:55, 6.35 it/s, Epoch 4/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223499</td>\n",
       "      <td>0.928389</td>\n",
       "      <td>0.946369</td>\n",
       "      <td>0.937293</td>\n",
       "      <td>0.960896</td>\n",
       "      <td>{'precision': 0.9290882778581766, 'recall': 0.9455081001472754, 'f1': 0.9372262773722628, 'number': 679}</td>\n",
       "      <td>{'precision': 0.8988970588235294, 'recall': 0.9421965317919075, 'f1': 0.9200376293508938, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9220945083014048, 'recall': 0.9487516425755584, 'f1': 0.9352331606217616, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9751461988304093, 'recall': 0.9837758112094396, 'f1': 0.9794419970631425, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.5121951219512195, 'f1': 0.5526315789473684, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145393</td>\n",
       "      <td>0.939728</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>0.945986</td>\n",
       "      <td>0.968616</td>\n",
       "      <td>{'precision': 0.9632352941176471, 'recall': 0.9646539027982327, 'f1': 0.963944076526858, 'number': 679}</td>\n",
       "      <td>{'precision': 0.911275415896488, 'recall': 0.9499036608863198, 'f1': 0.9301886792452829, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9255455712451861, 'recall': 0.9474375821287779, 'f1': 0.9363636363636364, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9780701754385965, 'recall': 0.9867256637168141, 'f1': 0.9823788546255506, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5135135135135135, 'recall': 0.4634146341463415, 'f1': 0.48717948717948717, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109998</td>\n",
       "      <td>0.951031</td>\n",
       "      <td>0.962011</td>\n",
       "      <td>0.956490</td>\n",
       "      <td>0.974437</td>\n",
       "      <td>{'precision': 0.9691629955947136, 'recall': 0.9720176730486009, 'f1': 0.9705882352941176, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9320754716981132, 'recall': 0.9518304431599229, 'f1': 0.9418493803622497, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9382239382239382, 'recall': 0.9579500657030223, 'f1': 0.9479843953185956, 'number': 761}</td>\n",
       "      <td>{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7073170731707317, 'recall': 0.7073170731707317, 'f1': 0.7073170731707317, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109345</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.960894</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0.969754</td>\n",
       "      <td>{'precision': 0.9400855920114123, 'recall': 0.9705449189985272, 'f1': 0.955072463768116, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9048507462686567, 'recall': 0.9344894026974951, 'f1': 0.919431279620853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9557291666666666, 'recall': 0.9645203679369251, 'f1': 0.9601046435578809, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7692307692307693, 'recall': 0.7317073170731707, 'f1': 0.7499999999999999, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.108614</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.956052</td>\n",
       "      <td>0.950213</td>\n",
       "      <td>0.967603</td>\n",
       "      <td>{'precision': 0.9522431259044862, 'recall': 0.9690721649484536, 'f1': 0.9605839416058394, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9065420560747663, 'recall': 0.9344894026974951, 'f1': 0.9203036053130929, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9366925064599483, 'recall': 0.9526938239159002, 'f1': 0.9446254071661239, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.6829268292682927, 'f1': 0.736842105263158, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>0.925575</td>\n",
       "      <td>0.944879</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.970008</td>\n",
       "      <td>{'precision': 0.9283667621776505, 'recall': 0.9543446244477173, 'f1': 0.9411764705882353, 'number': 679}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9248554913294798, 'f1': 0.9031044214487299, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9152759948652118, 'recall': 0.9369250985545335, 'f1': 0.925974025974026, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6578947368421053, 'recall': 0.6097560975609756, 'f1': 0.6329113924050632, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.087736</td>\n",
       "      <td>0.962208</td>\n",
       "      <td>0.967225</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.978107</td>\n",
       "      <td>{'precision': 0.9778434268833087, 'recall': 0.9749631811487481, 'f1': 0.9764011799410028, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9421593830334191, 'recall': 0.9632063074901446, 'f1': 0.9525666016894087, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.7560975609756098, 'f1': 0.7948717948717948, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.083413</td>\n",
       "      <td>0.960148</td>\n",
       "      <td>0.969088</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>{'precision': 0.9735294117647059, 'recall': 0.9749631811487481, 'f1': 0.9742457689477557, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9148148148148149, 'recall': 0.9518304431599229, 'f1': 0.9329556185080266, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9661898569570871, 'recall': 0.9763469119579501, 'f1': 0.9712418300653595, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8285714285714286, 'recall': 0.7073170731707317, 'f1': 0.7631578947368421, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.960458</td>\n",
       "      <td>0.967970</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>{'precision': 0.973568281938326, 'recall': 0.9764359351988218, 'f1': 0.9750000000000001, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9483204134366925, 'recall': 0.9645203679369251, 'f1': 0.9563517915309447, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823529411764705, 'recall': 0.9852507374631269, 'f1': 0.9837997054491899, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.7560975609756098, 'f1': 0.8051948051948052, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.073182</td>\n",
       "      <td>0.964549</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.968663</td>\n",
       "      <td>0.979879</td>\n",
       "      <td>{'precision': 0.9749631811487481, 'recall': 0.9749631811487481, 'f1': 0.9749631811487481, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9440298507462687, 'recall': 0.9749518304431599, 'f1': 0.9592417061611375, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6904761904761905, 'recall': 0.7073170731707317, 'f1': 0.6987951807228916, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>0.969955</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.971938</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.093846</td>\n",
       "      <td>0.966234</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.968030</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>{'precision': 0.9764705882352941, 'recall': 0.9779086892488954, 'f1': 0.9771891096394407, 'number': 679}</td>\n",
       "      <td>{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9607329842931938, 'recall': 0.9645203679369251, 'f1': 0.9626229508196721, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.075444</td>\n",
       "      <td>0.958349</td>\n",
       "      <td>0.968343</td>\n",
       "      <td>0.963320</td>\n",
       "      <td>0.980764</td>\n",
       "      <td>{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9304511278195489, 'recall': 0.953757225433526, 'f1': 0.9419600380589914, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9569190600522193, 'recall': 0.9632063074901446, 'f1': 0.9600523903077931, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8048780487804879, 'recall': 0.8048780487804879, 'f1': 0.8048780487804877, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>0.965121</td>\n",
       "      <td>0.968715</td>\n",
       "      <td>0.966914</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9750367107195301, 'recall': 0.9779086892488954, 'f1': 0.9764705882352941, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9529411764705882, 'recall': 0.9579500657030223, 'f1': 0.9554390563564876, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.082043</td>\n",
       "      <td>0.964523</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.968280</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9474671669793621, 'recall': 0.9730250481695568, 'f1': 0.9600760456273764, 'number': 519}</td>\n",
       "      <td>{'precision': 0.953125, 'recall': 0.961892247043364, 'f1': 0.9574885546108568, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.813953488372093, 'recall': 0.8536585365853658, 'f1': 0.8333333333333333, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.076856</td>\n",
       "      <td>0.966617</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.968593</td>\n",
       "      <td>0.982030</td>\n",
       "      <td>{'precision': 0.9793510324483776, 'recall': 0.9779086892488954, 'f1': 0.978629329403095, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9477611940298507, 'recall': 0.9788053949903661, 'f1': 0.9630331753554502, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9646133682830931, 'recall': 0.9671484888304862, 'f1': 0.9658792650918635, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9778434268833087, 'recall': 0.976401179941003, 'f1': 0.9771217712177122, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8918918918918919, 'recall': 0.8048780487804879, 'f1': 0.8461538461538461, 'number': 41}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9290882778581766, 'recall': 0.9455081001472754, 'f1': 0.9372262773722628, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8988970588235294, 'recall': 0.9421965317919075, 'f1': 0.9200376293508938, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9220945083014048, 'recall': 0.9487516425755584, 'f1': 0.9352331606217616, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9751461988304093, 'recall': 0.9837758112094396, 'f1': 0.9794419970631425, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.5121951219512195, 'f1': 0.5526315789473684, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9632352941176471, 'recall': 0.9646539027982327, 'f1': 0.963944076526858, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.911275415896488, 'recall': 0.9499036608863198, 'f1': 0.9301886792452829, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9255455712451861, 'recall': 0.9474375821287779, 'f1': 0.9363636363636364, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780701754385965, 'recall': 0.9867256637168141, 'f1': 0.9823788546255506, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5135135135135135, 'recall': 0.4634146341463415, 'f1': 0.48717948717948717, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9691629955947136, 'recall': 0.9720176730486009, 'f1': 0.9705882352941176, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9320754716981132, 'recall': 0.9518304431599229, 'f1': 0.9418493803622497, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382239382239382, 'recall': 0.9579500657030223, 'f1': 0.9479843953185956, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7073170731707317, 'recall': 0.7073170731707317, 'f1': 0.7073170731707317, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400855920114123, 'recall': 0.9705449189985272, 'f1': 0.955072463768116, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9048507462686567, 'recall': 0.9344894026974951, 'f1': 0.919431279620853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557291666666666, 'recall': 0.9645203679369251, 'f1': 0.9601046435578809, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7692307692307693, 'recall': 0.7317073170731707, 'f1': 0.7499999999999999, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9522431259044862, 'recall': 0.9690721649484536, 'f1': 0.9605839416058394, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9065420560747663, 'recall': 0.9344894026974951, 'f1': 0.9203036053130929, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9366925064599483, 'recall': 0.9526938239159002, 'f1': 0.9446254071661239, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.6829268292682927, 'f1': 0.736842105263158, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9283667621776505, 'recall': 0.9543446244477173, 'f1': 0.9411764705882353, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9248554913294798, 'f1': 0.9031044214487299, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9152759948652118, 'recall': 0.9369250985545335, 'f1': 0.925974025974026, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6578947368421053, 'recall': 0.6097560975609756, 'f1': 0.6329113924050632, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778434268833087, 'recall': 0.9749631811487481, 'f1': 0.9764011799410028, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9421593830334191, 'recall': 0.9632063074901446, 'f1': 0.9525666016894087, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.7560975609756098, 'f1': 0.7948717948717948, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9735294117647059, 'recall': 0.9749631811487481, 'f1': 0.9742457689477557, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9148148148148149, 'recall': 0.9518304431599229, 'f1': 0.9329556185080266, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661898569570871, 'recall': 0.9763469119579501, 'f1': 0.9712418300653595, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8285714285714286, 'recall': 0.7073170731707317, 'f1': 0.7631578947368421, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.973568281938326, 'recall': 0.9764359351988218, 'f1': 0.9750000000000001, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9483204134366925, 'recall': 0.9645203679369251, 'f1': 0.9563517915309447, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823529411764705, 'recall': 0.9852507374631269, 'f1': 0.9837997054491899, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.7560975609756098, 'f1': 0.8051948051948052, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9749631811487481, 'recall': 0.9749631811487481, 'f1': 0.9749631811487481, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9440298507462687, 'recall': 0.9749518304431599, 'f1': 0.9592417061611375, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6904761904761905, 'recall': 0.7073170731707317, 'f1': 0.6987951807228916, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764705882352941, 'recall': 0.9779086892488954, 'f1': 0.9771891096394407, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9607329842931938, 'recall': 0.9645203679369251, 'f1': 0.9626229508196721, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9723032069970845, 'recall': 0.9823269513991163, 'f1': 0.9772893772893771, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9304511278195489, 'recall': 0.953757225433526, 'f1': 0.9419600380589914, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569190600522193, 'recall': 0.9632063074901446, 'f1': 0.9600523903077931, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8048780487804879, 'recall': 0.8048780487804879, 'f1': 0.8048780487804877, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750367107195301, 'recall': 0.9779086892488954, 'f1': 0.9764705882352941, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529411764705882, 'recall': 0.9579500657030223, 'f1': 0.9554390563564876, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9474671669793621, 'recall': 0.9730250481695568, 'f1': 0.9600760456273764, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953125, 'recall': 0.961892247043364, 'f1': 0.9574885546108568, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.813953488372093, 'recall': 0.8536585365853658, 'f1': 0.8333333333333333, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793510324483776, 'recall': 0.9779086892488954, 'f1': 0.978629329403095, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9477611940298507, 'recall': 0.9788053949903661, 'f1': 0.9630331753554502, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9646133682830931, 'recall': 0.9671484888304862, 'f1': 0.9658792650918635, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778434268833087, 'recall': 0.976401179941003, 'f1': 0.9771217712177122, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8918918918918919, 'recall': 0.8048780487804879, 'f1': 0.8461538461538461, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100 (score: 0.9719383014309607).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9479227618490346, 'recall': 0.9608540925266904, 'f1': 0.9543446244477173, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8887900355871886, 'recall': 0.9131627056672761, 'f1': 0.9008115419296663, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943801652892562, 'recall': 0.9585898153329603, 'f1': 0.9511382565241533, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867358708189158, 'recall': 0.9771559109080525, 'f1': 0.9819225251076039, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.42857142857142855, 'f1': 0.4137931034482759, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.6533333333333333, 'f1': 0.7101449275362319, 'number': 75}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9823269513991163, 'f1': 0.9823269513991163, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635416666666666, 'recall': 0.9724047306176085, 'f1': 0.9679529103989536, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-PER\",\n",
      "    \"2\": \"I-TITRE\",\n",
      "    \"3\": \"I-ACT\",\n",
      "    \"4\": \"I-LOC\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 3,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 6,\n",
      "    \"I-LOC\": 4,\n",
      "    \"I-PER\": 1,\n",
      "    \"I-TITRE\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110036743\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1900' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1900/5000 05:00 < 08:10, 6.32 it/s, Epoch 4/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.225553</td>\n",
       "      <td>0.931668</td>\n",
       "      <td>0.944507</td>\n",
       "      <td>0.938043</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>{'precision': 0.9273255813953488, 'recall': 0.9396170839469808, 'f1': 0.9334308705193856, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9044117647058824, 'recall': 0.9479768786127167, 'f1': 0.9256820319849483, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9328165374677002, 'recall': 0.9487516425755584, 'f1': 0.9407166123778501, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9695652173913043, 'recall': 0.9867256637168141, 'f1': 0.9780701754385964, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5769230769230769, 'recall': 0.36585365853658536, 'f1': 0.44776119402985076, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147380</td>\n",
       "      <td>0.944465</td>\n",
       "      <td>0.956425</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.968109</td>\n",
       "      <td>{'precision': 0.9619883040935673, 'recall': 0.9690721649484536, 'f1': 0.9655172413793105, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9305816135084428, 'recall': 0.9556840077071291, 'f1': 0.9429657794676807, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9281129653401797, 'recall': 0.9500657030223391, 'f1': 0.938961038961039, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9766081871345029, 'recall': 0.9852507374631269, 'f1': 0.9809104258443465, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5897435897435898, 'recall': 0.5609756097560976, 'f1': 0.575, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106408</td>\n",
       "      <td>0.961338</td>\n",
       "      <td>0.963128</td>\n",
       "      <td>0.962233</td>\n",
       "      <td>0.975829</td>\n",
       "      <td>{'precision': 0.961764705882353, 'recall': 0.9631811487481591, 'f1': 0.9624724061810155, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9504761904761905, 'recall': 0.9614643545279383, 'f1': 0.9559386973180076, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9620418848167539, 'recall': 0.9658344283837057, 'f1': 0.9639344262295081, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7647058823529411, 'recall': 0.6341463414634146, 'f1': 0.6933333333333332, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.103088</td>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.965736</td>\n",
       "      <td>0.961795</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9216417910447762, 'recall': 0.9518304431599229, 'f1': 0.9364928909952606, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9504563233376793, 'recall': 0.9579500657030223, 'f1': 0.9541884816753926, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.101610</td>\n",
       "      <td>0.952889</td>\n",
       "      <td>0.964246</td>\n",
       "      <td>0.958534</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>{'precision': 0.9622093023255814, 'recall': 0.9749631811487481, 'f1': 0.9685442574981712, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9526515151515151, 'recall': 0.9691714836223507, 'f1': 0.9608404966571156, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9345314505776636, 'recall': 0.9566360052562418, 'f1': 0.9454545454545454, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.6153846153846154, 'recall': 0.5853658536585366, 'f1': 0.6, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.087140</td>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.967598</td>\n",
       "      <td>0.965440</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>{'precision': 0.9721407624633431, 'recall': 0.9764359351988218, 'f1': 0.9742836149889786, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9506641366223909, 'recall': 0.9653179190751445, 'f1': 0.9579349904397705, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9619422572178478, 'recall': 0.9632063074901446, 'f1': 0.9625738673670386, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7317073170731707, 'recall': 0.7317073170731707, 'f1': 0.7317073170731707, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.081226</td>\n",
       "      <td>0.958287</td>\n",
       "      <td>0.966853</td>\n",
       "      <td>0.962551</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>{'precision': 0.964963503649635, 'recall': 0.9734904270986745, 'f1': 0.969208211143695, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9544270833333334, 'recall': 0.9632063074901446, 'f1': 0.9587965990843689, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7804878048780488, 'recall': 0.7804878048780488, 'f1': 0.7804878048780488, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.078977</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.966580</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>{'precision': 0.9677891654465594, 'recall': 0.9734904270986745, 'f1': 0.9706314243759177, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.7804878048780488, 'f1': 0.8311688311688312, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.080380</td>\n",
       "      <td>0.967286</td>\n",
       "      <td>0.969088</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9852507374631269, 'f1': 0.9859778597785978, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.073892</td>\n",
       "      <td>0.968101</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.970080</td>\n",
       "      <td>0.982536</td>\n",
       "      <td>{'precision': 0.9794419970631424, 'recall': 0.9823269513991163, 'f1': 0.9808823529411764, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9638783269961977, 'recall': 0.976878612716763, 'f1': 0.970334928229665, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9595300261096605, 'recall': 0.9658344283837057, 'f1': 0.962671905697446, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.074234</td>\n",
       "      <td>0.967395</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.969911</td>\n",
       "      <td>0.980891</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9619422572178478, 'recall': 0.9632063074901446, 'f1': 0.9625738673670386, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.8536585365853658, 'f1': 0.8433734939759037, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.080984</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.967670</td>\n",
       "      <td>0.980385</td>\n",
       "      <td>{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8048780487804879, 'recall': 0.8048780487804879, 'f1': 0.8048780487804877, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.968715</td>\n",
       "      <td>0.965479</td>\n",
       "      <td>0.981650</td>\n",
       "      <td>{'precision': 0.9765395894428153, 'recall': 0.9808541973490427, 'f1': 0.9786921381337251, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9569752281616688, 'recall': 0.9645203679369251, 'f1': 0.9607329842931938, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9837758112094396, 'f1': 0.9830508474576272, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7317073170731707, 'recall': 0.7317073170731707, 'f1': 0.7317073170731707, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>0.970293</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.971737</td>\n",
       "      <td>0.983295</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}</td>\n",
       "      <td>{'precision': 0.96, 'recall': 0.9710982658959537, 'f1': 0.9655172413793104, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9646596858638743, 'recall': 0.9684625492772667, 'f1': 0.9665573770491803, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.078145</td>\n",
       "      <td>0.964101</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.967143</td>\n",
       "      <td>0.979499</td>\n",
       "      <td>{'precision': 0.9794117647058823, 'recall': 0.9808541973490427, 'f1': 0.9801324503311258, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9581699346405229, 'recall': 0.9632063074901446, 'f1': 0.9606815203145479, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.7857142857142857, 'recall': 0.8048780487804879, 'f1': 0.7951807228915663, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.079189</td>\n",
       "      <td>0.965185</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.967874</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>{'precision': 0.9750367107195301, 'recall': 0.9779086892488954, 'f1': 0.9764705882352941, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.082305</td>\n",
       "      <td>0.969191</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.970812</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>{'precision': 0.9765395894428153, 'recall': 0.9808541973490427, 'f1': 0.9786921381337251, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.966284</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.968796</td>\n",
       "      <td>0.982916</td>\n",
       "      <td>{'precision': 0.9691629955947136, 'recall': 0.9720176730486009, 'f1': 0.9705882352941176, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9619771863117871, 'recall': 0.9749518304431599, 'f1': 0.968421052631579, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9583875162548765, 'recall': 0.9684625492772667, 'f1': 0.9633986928104575, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.7804878048780488, 'f1': 0.7901234567901235, 'number': 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.969225</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.971386</td>\n",
       "      <td>0.983042</td>\n",
       "      <td>{'precision': 0.9808259587020649, 'recall': 0.979381443298969, 'f1': 0.9801031687546058, 'number': 679}</td>\n",
       "      <td>{'precision': 0.9619771863117871, 'recall': 0.9749518304431599, 'f1': 0.968421052631579, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}</td>\n",
       "      <td>{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9273255813953488, 'recall': 0.9396170839469808, 'f1': 0.9334308705193856, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9044117647058824, 'recall': 0.9479768786127167, 'f1': 0.9256820319849483, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9328165374677002, 'recall': 0.9487516425755584, 'f1': 0.9407166123778501, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9695652173913043, 'recall': 0.9867256637168141, 'f1': 0.9780701754385964, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5769230769230769, 'recall': 0.36585365853658536, 'f1': 0.44776119402985076, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619883040935673, 'recall': 0.9690721649484536, 'f1': 0.9655172413793105, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9305816135084428, 'recall': 0.9556840077071291, 'f1': 0.9429657794676807, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9281129653401797, 'recall': 0.9500657030223391, 'f1': 0.938961038961039, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9766081871345029, 'recall': 0.9852507374631269, 'f1': 0.9809104258443465, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5897435897435898, 'recall': 0.5609756097560976, 'f1': 0.575, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.961764705882353, 'recall': 0.9631811487481591, 'f1': 0.9624724061810155, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9504761904761905, 'recall': 0.9614643545279383, 'f1': 0.9559386973180076, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620418848167539, 'recall': 0.9658344283837057, 'f1': 0.9639344262295081, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7647058823529411, 'recall': 0.6341463414634146, 'f1': 0.6933333333333332, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9216417910447762, 'recall': 0.9518304431599229, 'f1': 0.9364928909952606, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9504563233376793, 'recall': 0.9579500657030223, 'f1': 0.9541884816753926, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9852507374631269, 'f1': 0.9845246868091377, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.7560975609756098, 'f1': 0.7654320987654322, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622093023255814, 'recall': 0.9749631811487481, 'f1': 0.9685442574981712, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9526515151515151, 'recall': 0.9691714836223507, 'f1': 0.9608404966571156, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9345314505776636, 'recall': 0.9566360052562418, 'f1': 0.9454545454545454, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6153846153846154, 'recall': 0.5853658536585366, 'f1': 0.6, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9721407624633431, 'recall': 0.9764359351988218, 'f1': 0.9742836149889786, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9506641366223909, 'recall': 0.9653179190751445, 'f1': 0.9579349904397705, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619422572178478, 'recall': 0.9632063074901446, 'f1': 0.9625738673670386, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7317073170731707, 'recall': 0.7317073170731707, 'f1': 0.7317073170731707, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.964963503649635, 'recall': 0.9734904270986745, 'f1': 0.969208211143695, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544270833333334, 'recall': 0.9632063074901446, 'f1': 0.9587965990843689, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7804878048780488, 'recall': 0.7804878048780488, 'f1': 0.7804878048780488, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9677891654465594, 'recall': 0.9734904270986745, 'f1': 0.9706314243759177, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.7804878048780488, 'f1': 0.8311688311688312, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808823529411764, 'recall': 0.9823269513991163, 'f1': 0.9816041206769683, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9852507374631269, 'f1': 0.9859778597785978, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.868421052631579, 'recall': 0.8048780487804879, 'f1': 0.8354430379746836, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794419970631424, 'recall': 0.9823269513991163, 'f1': 0.9808823529411764, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9638783269961977, 'recall': 0.976878612716763, 'f1': 0.970334928229665, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9595300261096605, 'recall': 0.9658344283837057, 'f1': 0.962671905697446, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7894736842105263, 'recall': 0.7317073170731707, 'f1': 0.7594936708860759, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9837997054491899, 'f1': 0.9823529411764705, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619422572178478, 'recall': 0.9632063074901446, 'f1': 0.9625738673670386, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882179675994109, 'recall': 0.9896755162241888, 'f1': 0.9889462048636699, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.8536585365853658, 'f1': 0.8433734939759037, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779735682819384, 'recall': 0.9808541973490427, 'f1': 0.9794117647058823, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8048780487804879, 'recall': 0.8048780487804879, 'f1': 0.8048780487804877, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9765395894428153, 'recall': 0.9808541973490427, 'f1': 0.9786921381337251, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569752281616688, 'recall': 0.9645203679369251, 'f1': 0.9607329842931938, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9837758112094396, 'f1': 0.9830508474576272, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7317073170731707, 'recall': 0.7317073170731707, 'f1': 0.7317073170731707, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96, 'recall': 0.9710982658959537, 'f1': 0.9655172413793104, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9646596858638743, 'recall': 0.9684625492772667, 'f1': 0.9665573770491803, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794117647058823, 'recall': 0.9808541973490427, 'f1': 0.9801324503311258, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581699346405229, 'recall': 0.9632063074901446, 'f1': 0.9606815203145479, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7857142857142857, 'recall': 0.8048780487804879, 'f1': 0.7951807228915663, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750367107195301, 'recall': 0.9779086892488954, 'f1': 0.9764705882352941, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8292682926829268, 'recall': 0.8292682926829268, 'f1': 0.8292682926829268, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9765395894428153, 'recall': 0.9808541973490427, 'f1': 0.9786921381337251, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8947368421052632, 'recall': 0.8292682926829268, 'f1': 0.860759493670886, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9691629955947136, 'recall': 0.9720176730486009, 'f1': 0.9705882352941176, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619771863117871, 'recall': 0.9749518304431599, 'f1': 0.968421052631579, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9583875162548765, 'recall': 0.9684625492772667, 'f1': 0.9633986928104575, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.7804878048780488, 'f1': 0.7901234567901235, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808259587020649, 'recall': 0.979381443298969, 'f1': 0.9801031687546058, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9619771863117871, 'recall': 0.9749518304431599, 'f1': 0.968421052631579, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1800] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1400 (score: 0.9717367050948308).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_0/tmp/42-flat-ner-pero-ocr-pretrained_camembert_ner/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9512338425381903, 'recall': 0.9602609727164887, 'f1': 0.9557260920897284, 'number': 1686}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8793256433007985, 'recall': 0.9058500914076782, 'f1': 0.8923908149482215, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9484764542936288, 'recall': 0.9580302182428652, 'f1': 0.9532293986636972, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9783228750713063, 'recall': 0.9794403198172473, 'f1': 0.9788812785388128, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.6428571428571429, 'f1': 0.6923076923076924, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8153846153846154, 'recall': 0.7066666666666667, 'f1': 0.757142857142857, 'number': 75}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.9808541973490427, 'f1': 0.9808541973490427, 'number': 679}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96, 'recall': 0.9710982658959537, 'f1': 0.9655172413793104, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9646596858638743, 'recall': 0.9684625492772667, 'f1': 0.9665573770491803, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.85, 'recall': 0.8292682926829268, 'f1': 0.8395061728395061, 'number': 41}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:04:37.755047\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT_PRETRAINED:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "    print(MODEL_METRICS_DIR,MODEL_OUTPUT_MODEL_PATH)\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IO labels\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
