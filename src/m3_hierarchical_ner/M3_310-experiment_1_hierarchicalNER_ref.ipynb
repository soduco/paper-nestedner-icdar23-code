{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294705ff-9e89-499f-a41f-9494362be5f9",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "source": [
    "# 310 - Experiment #1 - Hierarchical NER with reference dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536176a",
   "metadata": {},
   "source": [
    "Requirements : \n",
    "* Create datasets in `m2_joint-labelling_for_ner` : `M2_200-prepare_datasets_joint_labelling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e498466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #Numéro GPU\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e9f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flD_9oT8LmDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flD_9oT8LmDB",
    "outputId": "63a92e5f-d414-46cc-db86-b46981e42594"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZvwNIzqBwDs",
   "metadata": {
    "id": "cZvwNIzqBwDs",
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "Set the BASE path.\n",
    "If run on Google Colab, will also mout Google Drive to the moutpoint given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LWJVak2mB6bI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWJVak2mB6bI",
    "outputId": "dbb54104-560b-480c-d4b0-74a0787e2024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lrde/home2/stual/stage_DAS/m3_hierarchical_ner', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages']\n",
      "/lrde/home2/stual/stage_DAS/m3_hierarchical_ner\n",
      "/work/stual/dataset_ICDAR\n",
      "/work/stual/res_ICDAR/method_3\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset\"\n",
    "else:\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "  DATASETS = Path('/work/stual/dataset_ICDAR')\n",
    "  DATA_BASE = Path('/work/stual/res_ICDAR/method_2')\n",
    "  OUT_BASE = Path('/work/stual/res_ICDAR/method_3')\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hxHdPTBlCCFO",
   "metadata": {
    "id": "hxHdPTBlCCFO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d554600",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CAMEMBERT_IO = True\n",
    "RUN_CAMEMBERT_IOB2 = False\n",
    "#Can't run together because of convert_tokenizer_\n",
    "RUN_PTRN_CAMEMBERT_IO = False\n",
    "RUN_PTRN_CAMEMBERT_IOB2 = False\n",
    "\n",
    "# Number of times a model will be trained & evaluated on each a dataset\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {
    "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed"
   },
   "source": [
    "## CamemBERT - Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {
    "id": "91140aa5-b377-47c1-bd44-844cd9365ec3"
   },
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defda8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "\n",
    "#Print examples from datasets\n",
    "def loadExample(INPUT_DIR,set_length:int,i:int,subset:str):\n",
    "    set_ = load_from_disk(INPUT_DIR / f\"huggingface_{set_length}\")\n",
    "    data = {\"tokens\": set_[subset][i][\"tokens\"],\n",
    "            \"labels\": set_[subset][i][\"ner_tags\"]}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacc1d2",
   "metadata": {},
   "source": [
    "## Hierarchical NER : Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76a0e1",
   "metadata": {},
   "source": [
    "### Tree with IO Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc90872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             EN                                                                                        \n",
      " ┌──────────────┬───────────────────────┬────────────────────┼────────────────────────────────────────┬───────────────────────────────────────────┐      \n",
      " O            I-PER                   I-ACT                I-DESC                                   I-SPAT                                     I-TITRE \n",
      " │      ┌───────┴──────────┐            │        ┌───────────┼───────────────┐            ┌───────────┼───────────────┬───────────────┐           │      \n",
      "O+O  I-PER+O         I-PER+i_TITREH  I-ACT+O  I-DESC+O  I-DESC+i_ACT  I-DESC+i_TITREP  I-SPAT+O  I-SPAT+i_LOC  I-SPAT+i_CARDINA  I-SPAT+i_FT  I-TITRE+O\n",
      "                                                                                                                      L                                \n",
      "\n",
      "(-100.0\n",
      "  (1.0 1.0)\n",
      "  (1.0 1.0 1.0)\n",
      "  (1.0 1.0)\n",
      "  (1.0 1.0 1.0 1.0)\n",
      "  (1.0 1.0 1.0 1.0 1.0)\n",
      "  (1.0 1.0))\n"
     ]
    }
   ],
   "source": [
    "from hierarchicalNER.trees import Ltree, Wtree\n",
    "Ltree.pretty_print(unicodelines=True, nodedist=2)\n",
    "print(Wtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c78841",
   "metadata": {},
   "source": [
    "### Tree with IOB2 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0689a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                              EN                                                                                                                                                                                                                                               \n",
      " ┌───────────────────────────────────────┬───────────────────────────────────────────────────────────┬─────────────────────────────────────────────────────────────────────┬──────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────┐                  \n",
      " O                                      PER                                                         ACT                                                                   DESC                                                                                                                                                                   SPAT                                                                                                       TITRE              \n",
      " │                ┌──────────────────────┴─────────────────┐                                         │                             ┌───────────────────────────────────────┼──────────────────────────────────────────────────┐                                          ┌───────────────────────────────────────┬────────────────────────────────┴─────────────────┬─────────────────────────────────────────────────┐                                       │                  \n",
      "O+O             PER+O                                  PER+TITREH                                  ACT+O                         DESC+O                                 DESC+ACT                                         DESC+TITREP                                   SPAT+O                                 SPAT+LOC                                        SPAT+CARDINAL                                        SPAT+FT                                 TITRE+O             \n",
      " │       ┌────────┴────────┐             ┌─────────────────┼─────────────────┐              ┌────────┴────────┐          ┌─────────┴─────────┐             ┌───────────────┼───────────────┐                ┌─────────────────┼─────────────────┐              ┌─────────┴─────────┐             ┌───────────────┼───────────────┐                ┌─────────────────┼─────────────────┐                ┌──────────────┼──────────────┐             ┌──────────┴──────────┐       \n",
      "O+O  I-b_PER+O         I-i_PER+O  I-b_PER+b_TITREH  I-i_PER+b_TITREH  I-i_PER+i_TITREH  I-b_ACT+O         I-i_ACT+O  I-b_DESC+O          I-i_DESC+O  I-b_DESC+b_ACT  I-i_DESC+b_ACT  I-i_DESC+i_ACT  I-b_DESC+b_TITRE  I-i_DESC+b_TITRE  I-i_DESC+i_TITRE  I-b_SPAT+O          I-i_SPAT+O  I-b_SPAT+b_LOC  I-i_SPAT+b_LOC  I-i_SPAT+i_LOC  I-b_SPAT+b_CARDI  I-i_SPAT+b_CARDI  I-i_SPAT+i_CARDI  I-b_SPAT+b_FT  I-i_SPAT+b_FT  I-i_SPAT+i_FT  I-b_TITRE+O           I-i_TITRE+O\n",
      "                                                                                                                                                                                                            P                 P                 P                                                                                                NAL               NAL               NAL                                                                                       \n",
      "\n",
      "(-100.0\n",
      "  (1.0 (1.0 1.0))\n",
      "  (1.0 (1.0 1.0 1.0) (1.0 1.0 1.0 1.0))\n",
      "  (1.0 (1.0 1.0 1.0))\n",
      "  (1.0 (1.0 1.0 1.0) (1.0 1.0 1.0 1.0) (1.0 1.0 1.0 1.0))\n",
      "  (1.0\n",
      "    (1.0 1.0 1.0)\n",
      "    (1.0 1.0 1.0 1.0)\n",
      "    (1.0 1.0 1.0 1.0)\n",
      "    (1.0 1.0 1.0 1.0))\n",
      "  (1.0 (1.0 1.0 1.0)))\n"
     ]
    }
   ],
   "source": [
    "from hierarchicalNER.trees import Ltree_iob2, Wtree_iob2\n",
    "Ltree_iob2.pretty_print(unicodelines=True, nodedist=2)\n",
    "print(Wtree_iob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9c889",
   "metadata": {},
   "source": [
    "## 311 - Train & eval : IO Ref dataset with CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e2004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"camembert_ner\"\n",
    "MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "LABEL = \"io\"\n",
    "FOLDER = \"311-camembert-ner-hierarchical-loss-io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882da225",
   "metadata": {},
   "source": [
    "### 311.1 Load IO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_1_prepared_dataset_ref_io_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-310-experiment_1_metrics'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_1_prepared_dataset_ref_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-310-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6040ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens             labels\n",
      "0  Duffau-Pauillac            I-PER+O\n",
      "1                (            I-PER+O\n",
      "2              Chs            I-PER+O\n",
      "3                )            I-PER+O\n",
      "4                ,                O+O\n",
      "5          Enghien       I-SPAT+i_LOC\n",
      "6                ,           I-SPAT+O\n",
      "7               16  I-SPAT+i_CARDINAL\n",
      "8                .                O+O\n",
      "9                *                O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4aa5b",
   "metadata": {},
   "source": [
    "### 311.2 Fine-tuning with IO labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 15:53:17.082002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 15:53:18.991198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 15:53:18.991311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 15:53:18.991322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree positions of all the leaves{'O+O': (0, 0), 'I-PER+O': (1, 0), 'I-PER+i_TITREH': (1, 1), 'I-ACT+O': (2, 0), 'I-DESC+O': (3, 0), 'I-DESC+i_ACT': (3, 1), 'I-DESC+i_TITREP': (3, 2), 'I-SPAT+O': (4, 0), 'I-SPAT+i_LOC': (4, 1), 'I-SPAT+i_CARDINAL': (4, 2), 'I-SPAT+i_FT': (4, 3), 'I-TITRE+O': (5, 0)} #1\n",
      "Num of classes : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "import json\n",
    "from hierarchicalNER.util_IO import init_model, train_eval_loop\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "            \n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6131ba8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05387e39-dd69-491e-9517-57490356e5e9",
    "outputId": "a894e899-0646-4260-f12f-7468adfbb5b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([12, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([12]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110040588\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1400' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1400/5000 08:59 < 23:09, 2.59 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341509</td>\n",
       "      <td>0.938622</td>\n",
       "      <td>0.938894</td>\n",
       "      <td>0.938758</td>\n",
       "      <td>0.940045</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>0.935433</td>\n",
       "      <td>0.920217</td>\n",
       "      <td>0.945010</td>\n",
       "      <td>0.964997</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.950964</td>\n",
       "      <td>0.972195</td>\n",
       "      <td>0.930803</td>\n",
       "      <td>0.936270</td>\n",
       "      <td>0.933529</td>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.930018</td>\n",
       "      <td>0.940760</td>\n",
       "      <td>0.935358</td>\n",
       "      <td>0.953327</td>\n",
       "      <td>{'precision': 0.9219653179190751, 'recall': 0.9437869822485208, 'f1': 0.932748538011696, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8462897526501767, 'recall': 0.9229287090558767, 'f1': 0.8829493087557604, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8462897526501767, 'recall': 0.952286282306163, 'f1': 0.8961646398503273, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9366197183098591, 'recall': 0.9582132564841499, 'f1': 0.9472934472934472, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9445876288659794, 'recall': 0.9632063074901446, 'f1': 0.9538061158100194, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219527</td>\n",
       "      <td>0.946870</td>\n",
       "      <td>0.954822</td>\n",
       "      <td>0.950829</td>\n",
       "      <td>0.949479</td>\n",
       "      <td>0.934805</td>\n",
       "      <td>0.955906</td>\n",
       "      <td>0.945237</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.956405</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.953527</td>\n",
       "      <td>0.974553</td>\n",
       "      <td>0.944170</td>\n",
       "      <td>0.953598</td>\n",
       "      <td>0.948860</td>\n",
       "      <td>0.964499</td>\n",
       "      <td>0.945321</td>\n",
       "      <td>0.959762</td>\n",
       "      <td>0.952487</td>\n",
       "      <td>0.962761</td>\n",
       "      <td>{'precision': 0.9604105571847508, 'recall': 0.9689349112426036, 'f1': 0.9646539027982327, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8987341772151899, 'recall': 0.9576107899807321, 'f1': 0.9272388059701492, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8987341772151899, 'recall': 0.9880715705765407, 'f1': 0.9412878787878788, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7916666666666666, 'recall': 0.5757575757575758, 'f1': 0.6666666666666667, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9449152542372882, 'recall': 0.9639769452449568, 'f1': 0.9543509272467903, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9325699745547074, 'recall': 0.9632063074901446, 'f1': 0.9476405946994182, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.176005</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.961772</td>\n",
       "      <td>0.960382</td>\n",
       "      <td>0.960899</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.945066</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.965703</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>0.976663</td>\n",
       "      <td>0.949752</td>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.952255</td>\n",
       "      <td>0.970767</td>\n",
       "      <td>0.962880</td>\n",
       "      <td>0.966468</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>{'precision': 0.9693430656934306, 'recall': 0.9822485207100592, 'f1': 0.9757531227038942, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9288461538461539, 'recall': 0.930635838150289, 'f1': 0.9297401347449471, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9288461538461539, 'recall': 0.9602385685884692, 'f1': 0.9442815249266862, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.21875, 'recall': 0.23333333333333334, 'f1': 0.22580645161290322, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9456366237482118, 'recall': 0.952449567723343, 'f1': 0.9490308686288585, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9504563233376793, 'recall': 0.9579500657030223, 'f1': 0.9541884816753926, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155756</td>\n",
       "      <td>0.950458</td>\n",
       "      <td>0.961193</td>\n",
       "      <td>0.955796</td>\n",
       "      <td>0.961395</td>\n",
       "      <td>0.924949</td>\n",
       "      <td>0.957480</td>\n",
       "      <td>0.940934</td>\n",
       "      <td>0.965864</td>\n",
       "      <td>0.965147</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.942263</td>\n",
       "      <td>0.958590</td>\n",
       "      <td>0.950357</td>\n",
       "      <td>0.972505</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.968703</td>\n",
       "      <td>0.963677</td>\n",
       "      <td>0.975174</td>\n",
       "      <td>{'precision': 0.9621542940320232, 'recall': 0.977810650887574, 'f1': 0.9699192956713133, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9102803738317757, 'recall': 0.9383429672447013, 'f1': 0.9240986717267552, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9102803738317757, 'recall': 0.9681908548707754, 'f1': 0.9383429672447013, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.1111111111111111, 'recall': 0.13333333333333333, 'f1': 0.1212121212121212, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2, 'f1': 0.25, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.968299711815562, 'f1': 0.9545454545454546, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9507772020725389, 'recall': 0.9645203679369251, 'f1': 0.9575994781474234, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.140020</td>\n",
       "      <td>0.956013</td>\n",
       "      <td>0.969302</td>\n",
       "      <td>0.962611</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.952455</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.959896</td>\n",
       "      <td>0.970209</td>\n",
       "      <td>0.958940</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.962126</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.955298</td>\n",
       "      <td>0.966520</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.974677</td>\n",
       "      <td>0.963401</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.967155</td>\n",
       "      <td>0.976539</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.5, 'f1': 0.4444444444444445, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4090909090909091, 'recall': 0.6, 'f1': 0.4864864864864865, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2, 'f1': 0.33333333333333337, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9458064516129032, 'recall': 0.9632063074901446, 'f1': 0.9544270833333334, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.141222</td>\n",
       "      <td>0.956359</td>\n",
       "      <td>0.964668</td>\n",
       "      <td>0.960496</td>\n",
       "      <td>0.964623</td>\n",
       "      <td>0.940031</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.951245</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.965124</td>\n",
       "      <td>0.959333</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>0.950901</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.956039</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.959041</td>\n",
       "      <td>0.968331</td>\n",
       "      <td>0.963663</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>{'precision': 0.9651162790697675, 'recall': 0.9822485207100592, 'f1': 0.9736070381231672, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9136960600375235, 'recall': 0.9383429672447013, 'f1': 0.9258555133079848, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9136960600375235, 'recall': 0.9681908548707754, 'f1': 0.9401544401544402, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3225806451612903, 'recall': 0.3333333333333333, 'f1': 0.32786885245901637, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.9696969696969697, 'f1': 0.8767123287671234, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}</td>\n",
       "      <td>{'precision': 0.951885565669701, 'recall': 0.961892247043364, 'f1': 0.9568627450980393, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.968433</td>\n",
       "      <td>0.957069</td>\n",
       "      <td>0.965864</td>\n",
       "      <td>0.924395</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.954485</td>\n",
       "      <td>0.964667</td>\n",
       "      <td>0.959549</td>\n",
       "      <td>0.980263</td>\n",
       "      <td>0.937429</td>\n",
       "      <td>0.963583</td>\n",
       "      <td>0.950326</td>\n",
       "      <td>0.975174</td>\n",
       "      <td>0.961950</td>\n",
       "      <td>0.970194</td>\n",
       "      <td>0.966055</td>\n",
       "      <td>0.977905</td>\n",
       "      <td>{'precision': 0.9620991253644315, 'recall': 0.9763313609467456, 'f1': 0.9691629955947137, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8805704099821747, 'recall': 0.9518304431599229, 'f1': 0.9148148148148147, 'number': 519}</td>\n",
       "      <td>{'precision': 0.914018691588785, 'recall': 0.9721669980119284, 'f1': 0.9421965317919075, 'number': 503}</td>\n",
       "      <td>{'precision': 0.19230769230769232, 'recall': 0.3125, 'f1': 0.2380952380952381, 'number': 16}</td>\n",
       "      <td>{'precision': 0.23809523809523808, 'recall': 0.5, 'f1': 0.3225806451612903, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9571428571428572, 'recall': 0.9654178674351584, 'f1': 0.9612625538020085, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9507133592736705, 'recall': 0.9632063074901446, 'f1': 0.9569190600522193, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.153113</td>\n",
       "      <td>0.949457</td>\n",
       "      <td>0.962931</td>\n",
       "      <td>0.956147</td>\n",
       "      <td>0.948982</td>\n",
       "      <td>0.944788</td>\n",
       "      <td>0.961155</td>\n",
       "      <td>0.952901</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>0.950098</td>\n",
       "      <td>0.964667</td>\n",
       "      <td>0.957327</td>\n",
       "      <td>0.969215</td>\n",
       "      <td>0.947125</td>\n",
       "      <td>0.962702</td>\n",
       "      <td>0.954850</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.959570</td>\n",
       "      <td>0.963860</td>\n",
       "      <td>0.961710</td>\n",
       "      <td>0.969588</td>\n",
       "      <td>{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8983050847457628, 'recall': 0.9190751445086706, 'f1': 0.9085714285714287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9553752535496958, 'recall': 0.9363817097415507, 'f1': 0.9457831325301206, 'number': 503}</td>\n",
       "      <td>{'precision': 0.15789473684210525, 'recall': 0.375, 'f1': 0.22222222222222218, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3235294117647059, 'recall': 0.7333333333333333, 'f1': 0.4489795918367347, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.118252</td>\n",
       "      <td>0.961869</td>\n",
       "      <td>0.971619</td>\n",
       "      <td>0.966719</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>0.959813</td>\n",
       "      <td>0.973064</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.962815</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.969457</td>\n",
       "      <td>0.961130</td>\n",
       "      <td>0.976229</td>\n",
       "      <td>0.967134</td>\n",
       "      <td>0.975782</td>\n",
       "      <td>0.971439</td>\n",
       "      <td>0.983739</td>\n",
       "      <td>{'precision': 0.9737609329446064, 'recall': 0.9881656804733728, 'f1': 0.9809104258443466, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9243542435424354, 'recall': 0.9653179190751445, 'f1': 0.9443920829406222, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9482758620689655, 'recall': 0.9840954274353877, 'f1': 0.9658536585365853, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.375, 'f1': 0.33333333333333326, 'number': 16}</td>\n",
       "      <td>{'precision': 0.37777777777777777, 'recall': 0.5666666666666667, 'f1': 0.4533333333333333, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2727272727272727, 'recall': 0.6, 'f1': 0.37499999999999994, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9599427753934192, 'recall': 0.9668587896253602, 'f1': 0.9633883704235463, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9606815203145478, 'recall': 0.9632063074901446, 'f1': 0.9619422572178477, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.107071</td>\n",
       "      <td>0.958845</td>\n",
       "      <td>0.971619</td>\n",
       "      <td>0.965190</td>\n",
       "      <td>0.963381</td>\n",
       "      <td>0.942915</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.956814</td>\n",
       "      <td>0.967229</td>\n",
       "      <td>0.959763</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.964854</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.970631</td>\n",
       "      <td>0.960337</td>\n",
       "      <td>0.970643</td>\n",
       "      <td>0.966014</td>\n",
       "      <td>0.974292</td>\n",
       "      <td>0.970135</td>\n",
       "      <td>0.982125</td>\n",
       "      <td>{'precision': 0.9652173913043478, 'recall': 0.985207100591716, 'f1': 0.9751098096632504, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9222222222222223, 'recall': 0.9595375722543352, 'f1': 0.9405099150141643, 'number': 519}</td>\n",
       "      <td>{'precision': 0.953125, 'recall': 0.9701789264413518, 'f1': 0.961576354679803, 'number': 503}</td>\n",
       "      <td>{'precision': 0.35714285714285715, 'recall': 0.625, 'f1': 0.45454545454545453, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3620689655172414, 'recall': 0.7, 'f1': 0.47727272727272735, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9615384615384616, 'recall': 0.9726224783861671, 'f1': 0.9670487106017192, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9646596858638743, 'recall': 0.9684625492772667, 'f1': 0.9665573770491803, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.126915</td>\n",
       "      <td>0.952043</td>\n",
       "      <td>0.971619</td>\n",
       "      <td>0.961731</td>\n",
       "      <td>0.957423</td>\n",
       "      <td>0.958982</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.964239</td>\n",
       "      <td>0.962761</td>\n",
       "      <td>0.948366</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.971326</td>\n",
       "      <td>0.954282</td>\n",
       "      <td>0.968576</td>\n",
       "      <td>0.961376</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.962049</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>0.967395</td>\n",
       "      <td>0.977905</td>\n",
       "      <td>{'precision': 0.9750733137829912, 'recall': 0.9837278106508875, 'f1': 0.979381443298969, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9256505576208178, 'recall': 0.9595375722543352, 'f1': 0.9422894985808893, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9682539682539683, 'recall': 0.9701789264413518, 'f1': 0.9692154915590864, 'number': 503}</td>\n",
       "      <td>{'precision': 0.29411764705882354, 'recall': 0.625, 'f1': 0.4, 'number': 16}</td>\n",
       "      <td>{'precision': 0.45652173913043476, 'recall': 0.7, 'f1': 0.5526315789473684, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9697406340057637, 'recall': 0.9697406340057637, 'f1': 0.9697406340057637, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9482535575679172, 'recall': 0.9632063074901446, 'f1': 0.9556714471968709, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.141646</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.962676</td>\n",
       "      <td>0.956678</td>\n",
       "      <td>0.947831</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.955480</td>\n",
       "      <td>0.960899</td>\n",
       "      <td>0.954098</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.961983</td>\n",
       "      <td>0.970209</td>\n",
       "      <td>0.950592</td>\n",
       "      <td>0.966226</td>\n",
       "      <td>0.958345</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.964906</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>0.969022</td>\n",
       "      <td>0.980139</td>\n",
       "      <td>{'precision': 0.9722222222222222, 'recall': 0.9837278106508875, 'f1': 0.9779411764705883, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9565217391304348, 'recall': 0.9622266401590457, 'f1': 0.9593657086223983, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3142857142857143, 'recall': 0.6875, 'f1': 0.43137254901960786, 'number': 16}</td>\n",
       "      <td>{'precision': 0.39215686274509803, 'recall': 0.6666666666666666, 'f1': 0.4938271604938271, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.958273381294964, 'recall': 0.9596541786743515, 'f1': 0.958963282937365, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.116222</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.965865</td>\n",
       "      <td>0.974926</td>\n",
       "      <td>0.941026</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.952010</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.963552</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.966434</td>\n",
       "      <td>0.986966</td>\n",
       "      <td>0.950853</td>\n",
       "      <td>0.965932</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.982187</td>\n",
       "      <td>0.960633</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>0.966679</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>{'precision': 0.967930029154519, 'recall': 0.9822485207100592, 'f1': 0.9750367107195302, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9277566539923955, 'recall': 0.9701789264413518, 'f1': 0.9484936831875608, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6428571428571429, 'recall': 0.5625, 'f1': 0.6000000000000001, 'number': 16}</td>\n",
       "      <td>{'precision': 0.43243243243243246, 'recall': 0.5333333333333333, 'f1': 0.47761194029850745, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9514978601997147, 'recall': 0.9610951008645533, 'f1': 0.9562724014336917, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9569752281616688, 'recall': 0.9645203679369251, 'f1': 0.9607329842931938, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.149141</td>\n",
       "      <td>0.956410</td>\n",
       "      <td>0.972198</td>\n",
       "      <td>0.964240</td>\n",
       "      <td>0.959161</td>\n",
       "      <td>0.949432</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.957585</td>\n",
       "      <td>0.962761</td>\n",
       "      <td>0.954098</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.961983</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.951487</td>\n",
       "      <td>0.967695</td>\n",
       "      <td>0.959522</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.966421</td>\n",
       "      <td>0.975782</td>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.979022</td>\n",
       "      <td>{'precision': 0.9780380673499268, 'recall': 0.9881656804733728, 'f1': 0.9830757910228108, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9097605893186004, 'recall': 0.9518304431599229, 'f1': 0.9303201506591338, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9529411764705882, 'recall': 0.9662027833001988, 'f1': 0.9595261599210266, 'number': 503}</td>\n",
       "      <td>{'precision': 0.24242424242424243, 'recall': 0.5, 'f1': 0.326530612244898, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9597701149425287, 'recall': 0.962536023054755, 'f1': 0.9611510791366907, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9633507853403142, 'recall': 0.9671484888304862, 'f1': 0.9652459016393442, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/stage_DAS/m3_hierarchical_ner/hierarchicalNER/util_IO.py:175: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9219653179190751, 'recall': 0.9437869822485208, 'f1': 0.932748538011696, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8462897526501767, 'recall': 0.9229287090558767, 'f1': 0.8829493087557604, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8462897526501767, 'recall': 0.952286282306163, 'f1': 0.8961646398503273, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9366197183098591, 'recall': 0.9582132564841499, 'f1': 0.9472934472934472, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9445876288659794, 'recall': 0.9632063074901446, 'f1': 0.9538061158100194, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9604105571847508, 'recall': 0.9689349112426036, 'f1': 0.9646539027982327, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8987341772151899, 'recall': 0.9576107899807321, 'f1': 0.9272388059701492, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8987341772151899, 'recall': 0.9880715705765407, 'f1': 0.9412878787878788, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7916666666666666, 'recall': 0.5757575757575758, 'f1': 0.6666666666666667, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9449152542372882, 'recall': 0.9639769452449568, 'f1': 0.9543509272467903, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9325699745547074, 'recall': 0.9632063074901446, 'f1': 0.9476405946994182, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9693430656934306, 'recall': 0.9822485207100592, 'f1': 0.9757531227038942, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9288461538461539, 'recall': 0.930635838150289, 'f1': 0.9297401347449471, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9288461538461539, 'recall': 0.9602385685884692, 'f1': 0.9442815249266862, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.21875, 'recall': 0.23333333333333334, 'f1': 0.22580645161290322, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456366237482118, 'recall': 0.952449567723343, 'f1': 0.9490308686288585, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9504563233376793, 'recall': 0.9579500657030223, 'f1': 0.9541884816753926, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621542940320232, 'recall': 0.977810650887574, 'f1': 0.9699192956713133, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9102803738317757, 'recall': 0.9383429672447013, 'f1': 0.9240986717267552, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9102803738317757, 'recall': 0.9681908548707754, 'f1': 0.9383429672447013, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.1111111111111111, 'recall': 0.13333333333333333, 'f1': 0.1212121212121212, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2, 'f1': 0.25, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.968299711815562, 'f1': 0.9545454545454546, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507772020725389, 'recall': 0.9645203679369251, 'f1': 0.9575994781474234, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.5, 'f1': 0.4444444444444445, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4090909090909091, 'recall': 0.6, 'f1': 0.4864864864864865, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2, 'f1': 0.33333333333333337, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9458064516129032, 'recall': 0.9632063074901446, 'f1': 0.9544270833333334, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9651162790697675, 'recall': 0.9822485207100592, 'f1': 0.9736070381231672, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9136960600375235, 'recall': 0.9383429672447013, 'f1': 0.9258555133079848, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9136960600375235, 'recall': 0.9681908548707754, 'f1': 0.9401544401544402, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3225806451612903, 'recall': 0.3333333333333333, 'f1': 0.32786885245901637, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.9696969696969697, 'f1': 0.8767123287671234, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.951885565669701, 'recall': 0.961892247043364, 'f1': 0.9568627450980393, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620991253644315, 'recall': 0.9763313609467456, 'f1': 0.9691629955947137, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8805704099821747, 'recall': 0.9518304431599229, 'f1': 0.9148148148148147, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.914018691588785, 'recall': 0.9721669980119284, 'f1': 0.9421965317919075, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.19230769230769232, 'recall': 0.3125, 'f1': 0.2380952380952381, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23809523809523808, 'recall': 0.5, 'f1': 0.3225806451612903, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9571428571428572, 'recall': 0.9654178674351584, 'f1': 0.9612625538020085, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507133592736705, 'recall': 0.9632063074901446, 'f1': 0.9569190600522193, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8983050847457628, 'recall': 0.9190751445086706, 'f1': 0.9085714285714287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9553752535496958, 'recall': 0.9363817097415507, 'f1': 0.9457831325301206, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.15789473684210525, 'recall': 0.375, 'f1': 0.22222222222222218, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3235294117647059, 'recall': 0.7333333333333333, 'f1': 0.4489795918367347, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9568062827225131, 'recall': 0.9605781865965834, 'f1': 0.958688524590164, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9737609329446064, 'recall': 0.9881656804733728, 'f1': 0.9809104258443466, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9243542435424354, 'recall': 0.9653179190751445, 'f1': 0.9443920829406222, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482758620689655, 'recall': 0.9840954274353877, 'f1': 0.9658536585365853, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.375, 'f1': 0.33333333333333326, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37777777777777777, 'recall': 0.5666666666666667, 'f1': 0.4533333333333333, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2727272727272727, 'recall': 0.6, 'f1': 0.37499999999999994, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9599427753934192, 'recall': 0.9668587896253602, 'f1': 0.9633883704235463, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9606815203145478, 'recall': 0.9632063074901446, 'f1': 0.9619422572178477, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9652173913043478, 'recall': 0.985207100591716, 'f1': 0.9751098096632504, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9222222222222223, 'recall': 0.9595375722543352, 'f1': 0.9405099150141643, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953125, 'recall': 0.9701789264413518, 'f1': 0.961576354679803, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35714285714285715, 'recall': 0.625, 'f1': 0.45454545454545453, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3620689655172414, 'recall': 0.7, 'f1': 0.47727272727272735, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9615384615384616, 'recall': 0.9726224783861671, 'f1': 0.9670487106017192, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9646596858638743, 'recall': 0.9684625492772667, 'f1': 0.9665573770491803, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750733137829912, 'recall': 0.9837278106508875, 'f1': 0.979381443298969, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9256505576208178, 'recall': 0.9595375722543352, 'f1': 0.9422894985808893, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9682539682539683, 'recall': 0.9701789264413518, 'f1': 0.9692154915590864, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.29411764705882354, 'recall': 0.625, 'f1': 0.4, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45652173913043476, 'recall': 0.7, 'f1': 0.5526315789473684, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9697406340057637, 'recall': 0.9697406340057637, 'f1': 0.9697406340057637, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482535575679172, 'recall': 0.9632063074901446, 'f1': 0.9556714471968709, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9722222222222222, 'recall': 0.9837278106508875, 'f1': 0.9779411764705883, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9565217391304348, 'recall': 0.9622266401590457, 'f1': 0.9593657086223983, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3142857142857143, 'recall': 0.6875, 'f1': 0.43137254901960786, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.39215686274509803, 'recall': 0.6666666666666666, 'f1': 0.4938271604938271, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.958273381294964, 'recall': 0.9596541786743515, 'f1': 0.958963282937365, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557867360208062, 'recall': 0.9658344283837057, 'f1': 0.9607843137254902, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.967930029154519, 'recall': 0.9822485207100592, 'f1': 0.9750367107195302, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9277566539923955, 'recall': 0.9701789264413518, 'f1': 0.9484936831875608, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6428571428571429, 'recall': 0.5625, 'f1': 0.6000000000000001, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.43243243243243246, 'recall': 0.5333333333333333, 'f1': 0.47761194029850745, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9514978601997147, 'recall': 0.9610951008645533, 'f1': 0.9562724014336917, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569752281616688, 'recall': 0.9645203679369251, 'f1': 0.9607329842931938, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780380673499268, 'recall': 0.9881656804733728, 'f1': 0.9830757910228108, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9097605893186004, 'recall': 0.9518304431599229, 'f1': 0.9303201506591338, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529411764705882, 'recall': 0.9662027833001988, 'f1': 0.9595261599210266, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.24242424242424243, 'recall': 0.5, 'f1': 0.326530612244898, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9597701149425287, 'recall': 0.962536023054755, 'f1': 0.9611510791366907, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633507853403142, 'recall': 0.9671484888304862, 'f1': 0.9652459016393442, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900 (score: 0.9667194928684627).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9788484136310224, 'recall': 0.9887240356083086, 'f1': 0.9837614408030706, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8704974271012007, 'recall': 0.9277879341864717, 'f1': 0.8982300884955753, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9159741458910434, 'recall': 0.962172647914646, 'f1': 0.9385052034058656, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.27710843373493976, 'recall': 0.36507936507936506, 'f1': 0.31506849315068497, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3217391304347826, 'recall': 0.46835443037974683, 'f1': 0.38144329896907214, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9761904761904762, 'recall': 0.9534883720930233, 'f1': 0.9647058823529412, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.59375, 'recall': 0.5757575757575758, 'f1': 0.5846153846153846, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9587803500846979, 'recall': 0.9719519175729823, 'f1': 0.9653212052302445, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9760312151616499, 'recall': 0.9798545047565753, 'f1': 0.9779391231499581, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9971461187214612, 'recall': 0.9977155910908052, 'f1': 0.9974307736226091, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9737609329446064, 'recall': 0.9881656804733728, 'f1': 0.9809104258443466, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9243542435424354, 'recall': 0.9653179190751445, 'f1': 0.9443920829406222, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482758620689655, 'recall': 0.9840954274353877, 'f1': 0.9658536585365853, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.375, 'f1': 0.33333333333333326, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37777777777777777, 'recall': 0.5666666666666667, 'f1': 0.4533333333333333, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2727272727272727, 'recall': 0.6, 'f1': 0.37499999999999994, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9599427753934192, 'recall': 0.9668587896253602, 'f1': 0.9633883704235463, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9606815203145478, 'recall': 0.9632063074901446, 'f1': 0.9619422572178477, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-PER+O\",\n",
      "    \"2\": \"I-PER+i_TITREH\",\n",
      "    \"3\": \"I-ACT+O\",\n",
      "    \"4\": \"I-DESC+O\",\n",
      "    \"5\": \"I-DESC+i_ACT\",\n",
      "    \"6\": \"I-DESC+i_TITREP\",\n",
      "    \"7\": \"I-SPAT+O\",\n",
      "    \"8\": \"I-SPAT+i_LOC\",\n",
      "    \"9\": \"I-SPAT+i_CARDINAL\",\n",
      "    \"10\": \"I-SPAT+i_FT\",\n",
      "    \"11\": \"I-TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT+O\": 3,\n",
      "    \"I-DESC+O\": 4,\n",
      "    \"I-DESC+i_ACT\": 5,\n",
      "    \"I-DESC+i_TITREP\": 6,\n",
      "    \"I-PER+O\": 1,\n",
      "    \"I-PER+i_TITREH\": 2,\n",
      "    \"I-SPAT+O\": 7,\n",
      "    \"I-SPAT+i_CARDINAL\": 9,\n",
      "    \"I-SPAT+i_FT\": 10,\n",
      "    \"I-SPAT+i_LOC\": 8,\n",
      "    \"I-TITRE+O\": 11,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([12, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([12]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110040588\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2300' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2300/5000 12:47 < 15:01, 3.00 it/s, Epoch 6/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.364013</td>\n",
       "      <td>0.929683</td>\n",
       "      <td>0.934260</td>\n",
       "      <td>0.931966</td>\n",
       "      <td>0.937190</td>\n",
       "      <td>0.905247</td>\n",
       "      <td>0.932808</td>\n",
       "      <td>0.918821</td>\n",
       "      <td>0.943893</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.945344</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>0.927342</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.930328</td>\n",
       "      <td>0.957485</td>\n",
       "      <td>0.925571</td>\n",
       "      <td>0.935917</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>{'precision': 0.9221902017291066, 'recall': 0.9467455621301775, 'f1': 0.9343065693430657, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8705035971223022, 'recall': 0.9325626204238922, 'f1': 0.9004651162790699, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8705035971223022, 'recall': 0.9622266401590457, 'f1': 0.9140698772426817, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9158485273492286, 'recall': 0.9409221902017291, 'f1': 0.9282160625444207, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9286624203821656, 'recall': 0.9579500657030223, 'f1': 0.943078913324709, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256892</td>\n",
       "      <td>0.946605</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.945644</td>\n",
       "      <td>0.943272</td>\n",
       "      <td>0.930185</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.940566</td>\n",
       "      <td>0.950223</td>\n",
       "      <td>0.966919</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>0.950864</td>\n",
       "      <td>0.970829</td>\n",
       "      <td>0.945866</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>0.945032</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.942772</td>\n",
       "      <td>0.945231</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.955437</td>\n",
       "      <td>{'precision': 0.95900439238653, 'recall': 0.9689349112426036, 'f1': 0.9639440765268579, 'number': 676}</td>\n",
       "      <td>{'precision': 0.881508078994614, 'recall': 0.9460500963391136, 'f1': 0.9126394052044609, 'number': 519}</td>\n",
       "      <td>{'precision': 0.881508078994614, 'recall': 0.9761431411530815, 'f1': 0.9264150943396227, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.06060606060606061, 'f1': 0.1142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9473684210526315, 'recall': 0.9596541786743515, 'f1': 0.9534717251252683, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9467532467532468, 'recall': 0.9579500657030223, 'f1': 0.9523187459177009, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213411</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.953606</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>0.936280</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>0.946248</td>\n",
       "      <td>0.959161</td>\n",
       "      <td>0.960189</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>0.954393</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.953010</td>\n",
       "      <td>0.949802</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.953601</td>\n",
       "      <td>0.957154</td>\n",
       "      <td>0.955374</td>\n",
       "      <td>0.967229</td>\n",
       "      <td>{'precision': 0.9562043795620438, 'recall': 0.9689349112426036, 'f1': 0.9625275532696547, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9226415094339623, 'recall': 0.9421965317919075, 'f1': 0.9323164918970448, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9226415094339623, 'recall': 0.9721669980119284, 'f1': 0.9467570183930301, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.23076923076923078, 'recall': 0.2, 'f1': 0.21428571428571427, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7241379310344828, 'recall': 0.6363636363636364, 'f1': 0.6774193548387097, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9531914893617022, 'recall': 0.968299711815562, 'f1': 0.9606862044317369, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9441558441558442, 'recall': 0.9553219448094612, 'f1': 0.9497060744611365, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168057</td>\n",
       "      <td>0.949587</td>\n",
       "      <td>0.965537</td>\n",
       "      <td>0.957496</td>\n",
       "      <td>0.954816</td>\n",
       "      <td>0.929045</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.960030</td>\n",
       "      <td>0.965264</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.964298</td>\n",
       "      <td>0.978153</td>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.958884</td>\n",
       "      <td>0.951756</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>0.959440</td>\n",
       "      <td>0.969449</td>\n",
       "      <td>0.964418</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>{'precision': 0.973568281938326, 'recall': 0.9807692307692307, 'f1': 0.9771554900515844, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9133709981167608, 'recall': 0.9344894026974951, 'f1': 0.9238095238095239, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9132075471698113, 'recall': 0.9622266401590457, 'f1': 0.9370764762826718, 'number': 503}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}</td>\n",
       "      <td>{'precision': 0.1702127659574468, 'recall': 0.26666666666666666, 'f1': 0.20779220779220778, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}</td>\n",
       "      <td>{'precision': 0.948644793152639, 'recall': 0.9582132564841499, 'f1': 0.9534050179211468, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9520725388601037, 'recall': 0.9658344283837057, 'f1': 0.9589041095890412, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.157808</td>\n",
       "      <td>0.952491</td>\n",
       "      <td>0.958008</td>\n",
       "      <td>0.955241</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.936214</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.945700</td>\n",
       "      <td>0.958540</td>\n",
       "      <td>0.963235</td>\n",
       "      <td>0.960667</td>\n",
       "      <td>0.961949</td>\n",
       "      <td>0.976912</td>\n",
       "      <td>0.947965</td>\n",
       "      <td>0.957709</td>\n",
       "      <td>0.952812</td>\n",
       "      <td>0.967726</td>\n",
       "      <td>0.954613</td>\n",
       "      <td>0.963860</td>\n",
       "      <td>0.959214</td>\n",
       "      <td>0.965740</td>\n",
       "      <td>{'precision': 0.952449567723343, 'recall': 0.977810650887574, 'f1': 0.9649635036496351, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9113207547169812, 'recall': 0.930635838150289, 'f1': 0.9208770257387989, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9232245681381958, 'recall': 0.9562624254473161, 'f1': 0.939453125, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.125, 'f1': 0.16, 'number': 16}</td>\n",
       "      <td>{'precision': 0.14285714285714285, 'recall': 0.13333333333333333, 'f1': 0.1379310344827586, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7741935483870968, 'recall': 0.7272727272727273, 'f1': 0.7500000000000001, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9614835948644793, 'recall': 0.9711815561959655, 'f1': 0.9663082437275986, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.146516</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.962062</td>\n",
       "      <td>0.958869</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.961680</td>\n",
       "      <td>0.946525</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.961847</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.959920</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>0.944798</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>0.952367</td>\n",
       "      <td>0.971698</td>\n",
       "      <td>0.955817</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.961481</td>\n",
       "      <td>0.973064</td>\n",
       "      <td>{'precision': 0.975, 'recall': 0.9807692307692307, 'f1': 0.9778761061946902, 'number': 676}</td>\n",
       "      <td>{'precision': 0.911275415896488, 'recall': 0.9499036608863198, 'f1': 0.9301886792452829, 'number': 519}</td>\n",
       "      <td>{'precision': 0.911275415896488, 'recall': 0.9801192842942346, 'f1': 0.9444444444444445, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.25806451612903225, 'recall': 0.26666666666666666, 'f1': 0.26229508196721313, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9355742296918768, 'recall': 0.962536023054755, 'f1': 0.9488636363636364, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9442282749675746, 'recall': 0.9566360052562418, 'f1': 0.9503916449086162, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.142706</td>\n",
       "      <td>0.949331</td>\n",
       "      <td>0.965827</td>\n",
       "      <td>0.957508</td>\n",
       "      <td>0.956927</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>0.958005</td>\n",
       "      <td>0.946331</td>\n",
       "      <td>0.962388</td>\n",
       "      <td>0.957616</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.960797</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.944830</td>\n",
       "      <td>0.960646</td>\n",
       "      <td>0.952672</td>\n",
       "      <td>0.969402</td>\n",
       "      <td>0.964021</td>\n",
       "      <td>0.968331</td>\n",
       "      <td>0.966171</td>\n",
       "      <td>0.971822</td>\n",
       "      <td>{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9016697588126159, 'recall': 0.9364161849710982, 'f1': 0.9187145557655954, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9251439539347409, 'recall': 0.9582504970178927, 'f1': 0.9414062500000001, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.25, 'f1': 0.23529411764705882, 'number': 16}</td>\n",
       "      <td>{'precision': 0.23636363636363636, 'recall': 0.43333333333333335, 'f1': 0.3058823529411765, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9568965517241379, 'recall': 0.9596541786743515, 'f1': 0.958273381294964, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9521345407503234, 'recall': 0.9671484888304862, 'f1': 0.9595827900912647, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.143103</td>\n",
       "      <td>0.958524</td>\n",
       "      <td>0.970460</td>\n",
       "      <td>0.964455</td>\n",
       "      <td>0.954320</td>\n",
       "      <td>0.952850</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.959061</td>\n",
       "      <td>0.961643</td>\n",
       "      <td>0.951602</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.960713</td>\n",
       "      <td>0.966112</td>\n",
       "      <td>0.952298</td>\n",
       "      <td>0.967401</td>\n",
       "      <td>0.959790</td>\n",
       "      <td>0.963878</td>\n",
       "      <td>0.968207</td>\n",
       "      <td>0.975782</td>\n",
       "      <td>0.971980</td>\n",
       "      <td>0.976912</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9157303370786517, 'recall': 0.9421965317919075, 'f1': 0.9287749287749287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.97, 'recall': 0.9642147117296223, 'f1': 0.967098703888335, 'number': 503}</td>\n",
       "      <td>{'precision': 0.11764705882352941, 'recall': 0.25, 'f1': 0.15999999999999998, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35294117647058826, 'recall': 0.6, 'f1': 0.4444444444444445, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9529914529914529, 'recall': 0.9639769452449568, 'f1': 0.9584527220630371, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9598965071151359, 'recall': 0.9750328515111695, 'f1': 0.9674054758800521, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.133263</td>\n",
       "      <td>0.957155</td>\n",
       "      <td>0.970460</td>\n",
       "      <td>0.963762</td>\n",
       "      <td>0.960899</td>\n",
       "      <td>0.947450</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.956318</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.958471</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.952285</td>\n",
       "      <td>0.967107</td>\n",
       "      <td>0.959639</td>\n",
       "      <td>0.971636</td>\n",
       "      <td>0.963113</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>0.967933</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>{'precision': 0.9822485207100592, 'recall': 0.9822485207100592, 'f1': 0.9822485207100592, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9304511278195489, 'recall': 0.953757225433526, 'f1': 0.9419600380589914, 'number': 519}</td>\n",
       "      <td>{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.375, 'f1': 0.39999999999999997, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3404255319148936, 'recall': 0.5333333333333333, 'f1': 0.41558441558441556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9571428571428572, 'recall': 0.9654178674351584, 'f1': 0.9612625538020085, 'number': 694}</td>\n",
       "      <td>{'precision': 0.952258064516129, 'recall': 0.9697766097240473, 'f1': 0.9609375, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.130474</td>\n",
       "      <td>0.954299</td>\n",
       "      <td>0.967564</td>\n",
       "      <td>0.960886</td>\n",
       "      <td>0.964250</td>\n",
       "      <td>0.943561</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>0.968967</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.961487</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.949726</td>\n",
       "      <td>0.965345</td>\n",
       "      <td>0.957472</td>\n",
       "      <td>0.973498</td>\n",
       "      <td>0.964074</td>\n",
       "      <td>0.969821</td>\n",
       "      <td>0.966939</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>{'precision': 0.9765739385065886, 'recall': 0.9866863905325444, 'f1': 0.9816041206769685, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9176029962546817, 'recall': 0.9441233140655106, 'f1': 0.9306742640075975, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9395711500974658, 'recall': 0.9582504970178927, 'f1': 0.9488188976377953, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3269230769230769, 'recall': 0.5666666666666667, 'f1': 0.41463414634146345, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9600570613409415, 'recall': 0.9697406340057637, 'f1': 0.9648745519713262, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9507772020725389, 'recall': 0.9645203679369251, 'f1': 0.9575994781474234, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.159845</td>\n",
       "      <td>0.952057</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.961880</td>\n",
       "      <td>0.949727</td>\n",
       "      <td>0.953910</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.960375</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.946684</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.967354</td>\n",
       "      <td>0.950706</td>\n",
       "      <td>0.968576</td>\n",
       "      <td>0.959558</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.961440</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.968374</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>{'precision': 0.9866863905325444, 'recall': 0.9866863905325444, 'f1': 0.9866863905325444, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9197761194029851, 'recall': 0.9499036608863198, 'f1': 0.9345971563981044, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9625246548323472, 'recall': 0.9701789264413518, 'f1': 0.9663366336633663, 'number': 503}</td>\n",
       "      <td>{'precision': 0.1724137931034483, 'recall': 0.3125, 'f1': 0.22222222222222224, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5666666666666667, 'f1': 0.4197530864197531, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.21428571428571427, 'recall': 0.6, 'f1': 0.3157894736842105, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9612625538020086, 'recall': 0.9654178674351584, 'f1': 0.9633357296908699, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9511568123393316, 'recall': 0.9724047306176085, 'f1': 0.9616634178037686, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.131411</td>\n",
       "      <td>0.957489</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.964645</td>\n",
       "      <td>0.963257</td>\n",
       "      <td>0.947558</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.957403</td>\n",
       "      <td>0.966733</td>\n",
       "      <td>0.957839</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.963552</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>0.952065</td>\n",
       "      <td>0.968282</td>\n",
       "      <td>0.960105</td>\n",
       "      <td>0.971512</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.971779</td>\n",
       "      <td>0.980139</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9099264705882353, 'recall': 0.953757225433526, 'f1': 0.9313264346190028, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9458413926499033, 'recall': 0.9721669980119284, 'f1': 0.9588235294117646, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.375, 'f1': 0.27906976744186046, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3137254901960784, 'recall': 0.5333333333333333, 'f1': 0.3950617283950617, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9647058823529412, 'recall': 0.9697766097240473, 'f1': 0.9672346002621232, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.965073</td>\n",
       "      <td>0.976253</td>\n",
       "      <td>0.970631</td>\n",
       "      <td>0.969588</td>\n",
       "      <td>0.960166</td>\n",
       "      <td>0.974278</td>\n",
       "      <td>0.967170</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.965586</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.969113</td>\n",
       "      <td>0.981008</td>\n",
       "      <td>0.962544</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.968025</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>0.969384</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.974235</td>\n",
       "      <td>0.981256</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9911242603550295, 'f1': 0.9896602658788773, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9380863039399625, 'recall': 0.9633911368015414, 'f1': 0.9505703422053231, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3125, 'f1': 0.38461538461538464, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5172413793103449, 'recall': 0.5, 'f1': 0.5084745762711865, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9615931721194879, 'recall': 0.9740634005763689, 'f1': 0.9677881173944166, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9648894668400521, 'recall': 0.9750328515111695, 'f1': 0.9699346405228758, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.2857142857142857, 'f1': 0.23529411764705882, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>0.964736</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.969601</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.969223</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.964238</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>0.980139</td>\n",
       "      <td>0.963652</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.968440</td>\n",
       "      <td>0.976787</td>\n",
       "      <td>0.971883</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.975311</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9382022471910112, 'recall': 0.9653179190751445, 'f1': 0.9515669515669515, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9576107899807321, 'recall': 0.9880715705765407, 'f1': 0.9726027397260273, 'number': 503}</td>\n",
       "      <td>{'precision': 0.26666666666666666, 'recall': 0.25, 'f1': 0.2580645161290323, 'number': 16}</td>\n",
       "      <td>{'precision': 0.48484848484848486, 'recall': 0.5333333333333333, 'f1': 0.507936507936508, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9622395833333334, 'recall': 0.9710906701708278, 'f1': 0.9666448659254414, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>0.969488</td>\n",
       "      <td>0.975384</td>\n",
       "      <td>0.972427</td>\n",
       "      <td>0.970209</td>\n",
       "      <td>0.965195</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.970235</td>\n",
       "      <td>0.974926</td>\n",
       "      <td>0.967463</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.969395</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>0.966191</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.969865</td>\n",
       "      <td>0.978215</td>\n",
       "      <td>0.972993</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.976425</td>\n",
       "      <td>0.981877</td>\n",
       "      <td>{'precision': 0.9809104258443465, 'recall': 0.9881656804733728, 'f1': 0.9845246868091379, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9599236641221374, 'recall': 0.9691714836223507, 'f1': 0.9645254074784276, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9632495164410058, 'recall': 0.9900596421471173, 'f1': 0.9764705882352941, 'number': 503}</td>\n",
       "      <td>{'precision': 0.7142857142857143, 'recall': 0.3125, 'f1': 0.43478260869565216, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5384615384615384, 'recall': 0.4666666666666667, 'f1': 0.5, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9671897289586305, 'recall': 0.9769452449567724, 'f1': 0.9720430107526881, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.147514</td>\n",
       "      <td>0.970597</td>\n",
       "      <td>0.975094</td>\n",
       "      <td>0.972840</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.967708</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.971503</td>\n",
       "      <td>0.975422</td>\n",
       "      <td>0.970686</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.971010</td>\n",
       "      <td>0.980139</td>\n",
       "      <td>0.969015</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.977781</td>\n",
       "      <td>0.974045</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.976398</td>\n",
       "      <td>0.979270</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9896449704142012, 'f1': 0.9881831610044313, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9593810444874274, 'recall': 0.9860834990059643, 'f1': 0.9725490196078432, 'number': 503}</td>\n",
       "      <td>{'precision': 0.625, 'recall': 0.3125, 'f1': 0.4166666666666667, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6538461538461539, 'recall': 0.5666666666666667, 'f1': 0.6071428571428571, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9670958512160229, 'recall': 0.9740634005763689, 'f1': 0.9705671213208903, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.966935</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.969340</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.968130</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.968064</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.969031</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>0.965558</td>\n",
       "      <td>0.971512</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.972963</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.975854</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}</td>\n",
       "      <td>{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9649122807017544, 'recall': 0.9840954274353877, 'f1': 0.9744094488188976, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3125, 'recall': 0.3125, 'f1': 0.3125, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4838709677419355, 'recall': 0.5, 'f1': 0.4918032786885246, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9641833810888252, 'recall': 0.9697406340057637, 'f1': 0.9669540229885057, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.135775</td>\n",
       "      <td>0.966857</td>\n",
       "      <td>0.980017</td>\n",
       "      <td>0.973393</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.968229</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.972026</td>\n",
       "      <td>0.970581</td>\n",
       "      <td>0.966513</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.973867</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>0.967470</td>\n",
       "      <td>0.978267</td>\n",
       "      <td>0.972839</td>\n",
       "      <td>0.975981</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.982489</td>\n",
       "      <td>0.977934</td>\n",
       "      <td>0.981629</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9664694280078896, 'recall': 0.974155069582505, 'f1': 0.9702970297029703, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.625, 'recall': 0.6666666666666666, 'f1': 0.6451612903225806, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9700854700854701, 'recall': 0.9812680115273775, 'f1': 0.9756446991404012, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9702072538860104, 'recall': 0.9842312746386334, 'f1': 0.9771689497716896, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.125147</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>0.976253</td>\n",
       "      <td>0.972591</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.976903</td>\n",
       "      <td>0.972563</td>\n",
       "      <td>0.976663</td>\n",
       "      <td>0.968854</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.983863</td>\n",
       "      <td>0.968522</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>0.972206</td>\n",
       "      <td>0.980263</td>\n",
       "      <td>0.972243</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.975492</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4375, 'recall': 0.4375, 'f1': 0.4375, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6774193548387096, 'recall': 0.7, 'f1': 0.6885245901639343, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9700427960057061, 'recall': 0.9798270893371758, 'f1': 0.974910394265233, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9661458333333334, 'recall': 0.9750328515111695, 'f1': 0.9705689993459777, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.130863</td>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.975384</td>\n",
       "      <td>0.972848</td>\n",
       "      <td>0.968595</td>\n",
       "      <td>0.965661</td>\n",
       "      <td>0.974278</td>\n",
       "      <td>0.969950</td>\n",
       "      <td>0.971822</td>\n",
       "      <td>0.968170</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.970745</td>\n",
       "      <td>0.980263</td>\n",
       "      <td>0.966764</td>\n",
       "      <td>0.973862</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>0.976043</td>\n",
       "      <td>0.975492</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.977125</td>\n",
       "      <td>0.982001</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9664694280078896, 'recall': 0.974155069582505, 'f1': 0.9702970297029703, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.48717948717948717, 'recall': 0.6333333333333333, 'f1': 0.5507246376811593, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.140830</td>\n",
       "      <td>0.967871</td>\n",
       "      <td>0.977121</td>\n",
       "      <td>0.972474</td>\n",
       "      <td>0.968967</td>\n",
       "      <td>0.968179</td>\n",
       "      <td>0.974278</td>\n",
       "      <td>0.971219</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>0.968833</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.971410</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>0.968467</td>\n",
       "      <td>0.974156</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>0.976850</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.976805</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9593810444874274, 'recall': 0.9860834990059643, 'f1': 0.9725490196078432, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5454545454545454, 'recall': 0.375, 'f1': 0.4444444444444444, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6923076923076923, 'recall': 0.6, 'f1': 0.6428571428571429, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9655172413793104, 'recall': 0.968299711815562, 'f1': 0.9669064748201439, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9610894941634242, 'recall': 0.973718791064389, 'f1': 0.9673629242819843, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.147202</td>\n",
       "      <td>0.964511</td>\n",
       "      <td>0.975963</td>\n",
       "      <td>0.970203</td>\n",
       "      <td>0.967354</td>\n",
       "      <td>0.962597</td>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.967624</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>0.962401</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.967507</td>\n",
       "      <td>0.980015</td>\n",
       "      <td>0.962511</td>\n",
       "      <td>0.972687</td>\n",
       "      <td>0.967572</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.971524</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.975130</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9649122807017544, 'recall': 0.9840954274353877, 'f1': 0.9744094488188976, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.375, 'f1': 0.33333333333333326, 'number': 16}</td>\n",
       "      <td>{'precision': 0.45714285714285713, 'recall': 0.5333333333333333, 'f1': 0.4923076923076923, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.161692</td>\n",
       "      <td>0.965143</td>\n",
       "      <td>0.978280</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.967222</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.971518</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.961892</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.968895</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.964866</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>0.970361</td>\n",
       "      <td>0.972133</td>\n",
       "      <td>0.971587</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9705304518664047, 'recall': 0.9821073558648111, 'f1': 0.9762845849802371, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4375, 'f1': 0.37837837837837834, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9713467048710601, 'recall': 0.9769452449567724, 'f1': 0.9741379310344828, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9599483204134367, 'recall': 0.9763469119579501, 'f1': 0.9680781758957655, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9221902017291066, 'recall': 0.9467455621301775, 'f1': 0.9343065693430657, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8705035971223022, 'recall': 0.9325626204238922, 'f1': 0.9004651162790699, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8705035971223022, 'recall': 0.9622266401590457, 'f1': 0.9140698772426817, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9158485273492286, 'recall': 0.9409221902017291, 'f1': 0.9282160625444207, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9286624203821656, 'recall': 0.9579500657030223, 'f1': 0.943078913324709, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.95900439238653, 'recall': 0.9689349112426036, 'f1': 0.9639440765268579, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.881508078994614, 'recall': 0.9460500963391136, 'f1': 0.9126394052044609, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.881508078994614, 'recall': 0.9761431411530815, 'f1': 0.9264150943396227, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.06060606060606061, 'f1': 0.1142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9473684210526315, 'recall': 0.9596541786743515, 'f1': 0.9534717251252683, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9467532467532468, 'recall': 0.9579500657030223, 'f1': 0.9523187459177009, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9562043795620438, 'recall': 0.9689349112426036, 'f1': 0.9625275532696547, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9226415094339623, 'recall': 0.9421965317919075, 'f1': 0.9323164918970448, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9226415094339623, 'recall': 0.9721669980119284, 'f1': 0.9467570183930301, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23076923076923078, 'recall': 0.2, 'f1': 0.21428571428571427, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7241379310344828, 'recall': 0.6363636363636364, 'f1': 0.6774193548387097, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9531914893617022, 'recall': 0.968299711815562, 'f1': 0.9606862044317369, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9441558441558442, 'recall': 0.9553219448094612, 'f1': 0.9497060744611365, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.973568281938326, 'recall': 0.9807692307692307, 'f1': 0.9771554900515844, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9133709981167608, 'recall': 0.9344894026974951, 'f1': 0.9238095238095239, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9132075471698113, 'recall': 0.9622266401590457, 'f1': 0.9370764762826718, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.1702127659574468, 'recall': 0.26666666666666666, 'f1': 0.20779220779220778, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.948644793152639, 'recall': 0.9582132564841499, 'f1': 0.9534050179211468, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9520725388601037, 'recall': 0.9658344283837057, 'f1': 0.9589041095890412, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.952449567723343, 'recall': 0.977810650887574, 'f1': 0.9649635036496351, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9113207547169812, 'recall': 0.930635838150289, 'f1': 0.9208770257387989, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9232245681381958, 'recall': 0.9562624254473161, 'f1': 0.939453125, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.125, 'f1': 0.16, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.14285714285714285, 'recall': 0.13333333333333333, 'f1': 0.1379310344827586, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7741935483870968, 'recall': 0.7272727272727273, 'f1': 0.7500000000000001, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614835948644793, 'recall': 0.9711815561959655, 'f1': 0.9663082437275986, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9621409921671018, 'recall': 0.9684625492772667, 'f1': 0.9652914210870989, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975, 'recall': 0.9807692307692307, 'f1': 0.9778761061946902, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.911275415896488, 'recall': 0.9499036608863198, 'f1': 0.9301886792452829, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.911275415896488, 'recall': 0.9801192842942346, 'f1': 0.9444444444444445, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25806451612903225, 'recall': 0.26666666666666666, 'f1': 0.26229508196721313, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9355742296918768, 'recall': 0.962536023054755, 'f1': 0.9488636363636364, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9442282749675746, 'recall': 0.9566360052562418, 'f1': 0.9503916449086162, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9016697588126159, 'recall': 0.9364161849710982, 'f1': 0.9187145557655954, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9251439539347409, 'recall': 0.9582504970178927, 'f1': 0.9414062500000001, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.25, 'f1': 0.23529411764705882, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23636363636363636, 'recall': 0.43333333333333335, 'f1': 0.3058823529411765, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9568965517241379, 'recall': 0.9596541786743515, 'f1': 0.958273381294964, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9521345407503234, 'recall': 0.9671484888304862, 'f1': 0.9595827900912647, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9157303370786517, 'recall': 0.9421965317919075, 'f1': 0.9287749287749287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.97, 'recall': 0.9642147117296223, 'f1': 0.967098703888335, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.11764705882352941, 'recall': 0.25, 'f1': 0.15999999999999998, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35294117647058826, 'recall': 0.6, 'f1': 0.4444444444444445, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529914529914529, 'recall': 0.9639769452449568, 'f1': 0.9584527220630371, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9598965071151359, 'recall': 0.9750328515111695, 'f1': 0.9674054758800521, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9822485207100592, 'recall': 0.9822485207100592, 'f1': 0.9822485207100592, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9304511278195489, 'recall': 0.953757225433526, 'f1': 0.9419600380589914, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.375, 'f1': 0.39999999999999997, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3404255319148936, 'recall': 0.5333333333333333, 'f1': 0.41558441558441556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9571428571428572, 'recall': 0.9654178674351584, 'f1': 0.9612625538020085, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.952258064516129, 'recall': 0.9697766097240473, 'f1': 0.9609375, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9765739385065886, 'recall': 0.9866863905325444, 'f1': 0.9816041206769685, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9176029962546817, 'recall': 0.9441233140655106, 'f1': 0.9306742640075975, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9395711500974658, 'recall': 0.9582504970178927, 'f1': 0.9488188976377953, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3269230769230769, 'recall': 0.5666666666666667, 'f1': 0.41463414634146345, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.4, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9600570613409415, 'recall': 0.9697406340057637, 'f1': 0.9648745519713262, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507772020725389, 'recall': 0.9645203679369251, 'f1': 0.9575994781474234, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9866863905325444, 'recall': 0.9866863905325444, 'f1': 0.9866863905325444, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9197761194029851, 'recall': 0.9499036608863198, 'f1': 0.9345971563981044, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9625246548323472, 'recall': 0.9701789264413518, 'f1': 0.9663366336633663, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.1724137931034483, 'recall': 0.3125, 'f1': 0.22222222222222224, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5666666666666667, 'f1': 0.4197530864197531, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.21428571428571427, 'recall': 0.6, 'f1': 0.3157894736842105, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9612625538020086, 'recall': 0.9654178674351584, 'f1': 0.9633357296908699, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9511568123393316, 'recall': 0.9724047306176085, 'f1': 0.9616634178037686, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9099264705882353, 'recall': 0.953757225433526, 'f1': 0.9313264346190028, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9458413926499033, 'recall': 0.9721669980119284, 'f1': 0.9588235294117646, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.375, 'f1': 0.27906976744186046, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3137254901960784, 'recall': 0.5333333333333333, 'f1': 0.3950617283950617, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647058823529412, 'recall': 0.9697766097240473, 'f1': 0.9672346002621232, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9911242603550295, 'f1': 0.9896602658788773, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9380863039399625, 'recall': 0.9633911368015414, 'f1': 0.9505703422053231, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3125, 'f1': 0.38461538461538464, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5172413793103449, 'recall': 0.5, 'f1': 0.5084745762711865, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9615931721194879, 'recall': 0.9740634005763689, 'f1': 0.9677881173944166, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9648894668400521, 'recall': 0.9750328515111695, 'f1': 0.9699346405228758, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.2857142857142857, 'f1': 0.23529411764705882, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382022471910112, 'recall': 0.9653179190751445, 'f1': 0.9515669515669515, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9576107899807321, 'recall': 0.9880715705765407, 'f1': 0.9726027397260273, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.26666666666666666, 'recall': 0.25, 'f1': 0.2580645161290323, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.48484848484848486, 'recall': 0.5333333333333333, 'f1': 0.507936507936508, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622395833333334, 'recall': 0.9710906701708278, 'f1': 0.9666448659254414, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809104258443465, 'recall': 0.9881656804733728, 'f1': 0.9845246868091379, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9599236641221374, 'recall': 0.9691714836223507, 'f1': 0.9645254074784276, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9632495164410058, 'recall': 0.9900596421471173, 'f1': 0.9764705882352941, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7142857142857143, 'recall': 0.3125, 'f1': 0.43478260869565216, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5384615384615384, 'recall': 0.4666666666666667, 'f1': 0.5, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9671897289586305, 'recall': 0.9769452449567724, 'f1': 0.9720430107526881, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9896449704142012, 'f1': 0.9881831610044313, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9593810444874274, 'recall': 0.9860834990059643, 'f1': 0.9725490196078432, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.3125, 'f1': 0.4166666666666667, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6538461538461539, 'recall': 0.5666666666666667, 'f1': 0.6071428571428571, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9670958512160229, 'recall': 0.9740634005763689, 'f1': 0.9705671213208903, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9649122807017544, 'recall': 0.9840954274353877, 'f1': 0.9744094488188976, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3125, 'recall': 0.3125, 'f1': 0.3125, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4838709677419355, 'recall': 0.5, 'f1': 0.4918032786885246, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9641833810888252, 'recall': 0.9697406340057637, 'f1': 0.9669540229885057, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9664694280078896, 'recall': 0.974155069582505, 'f1': 0.9702970297029703, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.6666666666666666, 'f1': 0.6451612903225806, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9700854700854701, 'recall': 0.9812680115273775, 'f1': 0.9756446991404012, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9702072538860104, 'recall': 0.9842312746386334, 'f1': 0.9771689497716896, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4375, 'recall': 0.4375, 'f1': 0.4375, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6774193548387096, 'recall': 0.7, 'f1': 0.6885245901639343, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9700427960057061, 'recall': 0.9798270893371758, 'f1': 0.974910394265233, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661458333333334, 'recall': 0.9750328515111695, 'f1': 0.9705689993459777, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9664694280078896, 'recall': 0.974155069582505, 'f1': 0.9702970297029703, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.48717948717948717, 'recall': 0.6333333333333333, 'f1': 0.5507246376811593, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507575757575758, 'recall': 0.9672447013487476, 'f1': 0.958930276981853, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9593810444874274, 'recall': 0.9860834990059643, 'f1': 0.9725490196078432, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5454545454545454, 'recall': 0.375, 'f1': 0.4444444444444444, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6923076923076923, 'recall': 0.6, 'f1': 0.6428571428571429, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9655172413793104, 'recall': 0.968299711815562, 'f1': 0.9669064748201439, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9610894941634242, 'recall': 0.973718791064389, 'f1': 0.9673629242819843, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9399624765478424, 'recall': 0.9653179190751445, 'f1': 0.9524714828897339, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9649122807017544, 'recall': 0.9840954274353877, 'f1': 0.9744094488188976, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.375, 'f1': 0.33333333333333326, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45714285714285713, 'recall': 0.5333333333333333, 'f1': 0.4923076923076923, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9452830188679245, 'recall': 0.9653179190751445, 'f1': 0.9551954242135366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705304518664047, 'recall': 0.9821073558648111, 'f1': 0.9762845849802371, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4375, 'f1': 0.37837837837837834, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9713467048710601, 'recall': 0.9769452449567724, 'f1': 0.9741379310344828, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9599483204134367, 'recall': 0.9763469119579501, 'f1': 0.9680781758957655, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800 (score: 0.973392780094923).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727649496743636, 'recall': 0.9750741839762611, 'f1': 0.973918197984588, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8881932021466905, 'recall': 0.9076782449725777, 'f1': 0.8978300180831826, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935609756097561, 'recall': 0.930164888457808, 'f1': 0.9328793774319066, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3655913978494624, 'recall': 0.5396825396825397, 'f1': 0.4358974358974359, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4528301886792453, 'recall': 0.6075949367088608, 'f1': 0.518918918918919, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9555555555555556, 'recall': 1.0, 'f1': 0.9772727272727273, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5161290322580645, 'recall': 0.48484848484848486, 'f1': 0.5, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.971655328798186, 'recall': 0.9811104751001717, 'f1': 0.9763600113927656, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9695121951219512, 'recall': 0.978735310576385, 'f1': 0.9741019214703426, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9965811965811966, 'recall': 0.9988577955454027, 'f1': 0.997718197375927, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.7142857142857143, 'f1': 0.588235294117647, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9664694280078896, 'recall': 0.974155069582505, 'f1': 0.9702970297029703, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.6666666666666666, 'f1': 0.6451612903225806, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9700854700854701, 'recall': 0.9812680115273775, 'f1': 0.9756446991404012, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9702072538860104, 'recall': 0.9842312746386334, 'f1': 0.9771689497716896, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-PER+O\",\n",
      "    \"2\": \"I-PER+i_TITREH\",\n",
      "    \"3\": \"I-ACT+O\",\n",
      "    \"4\": \"I-DESC+O\",\n",
      "    \"5\": \"I-DESC+i_ACT\",\n",
      "    \"6\": \"I-DESC+i_TITREP\",\n",
      "    \"7\": \"I-SPAT+O\",\n",
      "    \"8\": \"I-SPAT+i_LOC\",\n",
      "    \"9\": \"I-SPAT+i_CARDINAL\",\n",
      "    \"10\": \"I-SPAT+i_FT\",\n",
      "    \"11\": \"I-TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT+O\": 3,\n",
      "    \"I-DESC+O\": 4,\n",
      "    \"I-DESC+i_ACT\": 5,\n",
      "    \"I-DESC+i_TITREP\": 6,\n",
      "    \"I-PER+O\": 1,\n",
      "    \"I-PER+i_TITREH\": 2,\n",
      "    \"I-SPAT+O\": 7,\n",
      "    \"I-SPAT+i_CARDINAL\": 9,\n",
      "    \"I-SPAT+i_FT\": 10,\n",
      "    \"I-SPAT+i_LOC\": 8,\n",
      "    \"I-TITRE+O\": 11,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([12, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([12]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110040588\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 08:16 < 19:20, 3.01 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353229</td>\n",
       "      <td>0.939252</td>\n",
       "      <td>0.931364</td>\n",
       "      <td>0.935292</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>0.901015</td>\n",
       "      <td>0.931759</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.943520</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.950287</td>\n",
       "      <td>0.973188</td>\n",
       "      <td>0.927925</td>\n",
       "      <td>0.933921</td>\n",
       "      <td>0.930913</td>\n",
       "      <td>0.958354</td>\n",
       "      <td>0.931431</td>\n",
       "      <td>0.936289</td>\n",
       "      <td>0.933854</td>\n",
       "      <td>0.952458</td>\n",
       "      <td>{'precision': 0.9248554913294798, 'recall': 0.9467455621301775, 'f1': 0.935672514619883, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8797814207650273, 'recall': 0.930635838150289, 'f1': 0.9044943820224719, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8797814207650273, 'recall': 0.9602385685884692, 'f1': 0.9182509505703422, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.8943758573388203, 'recall': 0.9394812680115274, 'f1': 0.9163738580463809, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9420103092783505, 'recall': 0.9605781865965834, 'f1': 0.9512036434612882, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261214</td>\n",
       "      <td>0.932529</td>\n",
       "      <td>0.940631</td>\n",
       "      <td>0.936563</td>\n",
       "      <td>0.943520</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.947507</td>\n",
       "      <td>0.931613</td>\n",
       "      <td>0.952458</td>\n",
       "      <td>0.955722</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>0.945418</td>\n",
       "      <td>0.971326</td>\n",
       "      <td>0.933101</td>\n",
       "      <td>0.942144</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.961892</td>\n",
       "      <td>0.931441</td>\n",
       "      <td>0.941505</td>\n",
       "      <td>0.936446</td>\n",
       "      <td>0.956678</td>\n",
       "      <td>{'precision': 0.9461426491994177, 'recall': 0.9615384615384616, 'f1': 0.9537784299339691, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8745519713261649, 'recall': 0.9402697495183044, 'f1': 0.9062209842154133, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8745519713261649, 'recall': 0.9701789264413518, 'f1': 0.9198868991517437, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9367977528089888, 'recall': 0.9610951008645533, 'f1': 0.9487908961593172, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9287531806615776, 'recall': 0.9592641261498029, 'f1': 0.9437621202327086, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9868035190615836, 'recall': 0.9926253687315634, 'f1': 0.9897058823529412, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.948286</td>\n",
       "      <td>0.945265</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>0.949851</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>0.959782</td>\n",
       "      <td>0.951962</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.944929</td>\n",
       "      <td>0.969215</td>\n",
       "      <td>0.945630</td>\n",
       "      <td>0.950073</td>\n",
       "      <td>0.947846</td>\n",
       "      <td>0.964499</td>\n",
       "      <td>0.949627</td>\n",
       "      <td>0.948212</td>\n",
       "      <td>0.948919</td>\n",
       "      <td>0.960402</td>\n",
       "      <td>{'precision': 0.9662261380323054, 'recall': 0.9733727810650887, 'f1': 0.969786293294031, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9292543021032504, 'recall': 0.9364161849710982, 'f1': 0.9328214971209213, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9292543021032504, 'recall': 0.9662027833001988, 'f1': 0.9473684210526316, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.28125, 'recall': 0.3, 'f1': 0.29032258064516125, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5625, 'recall': 0.5454545454545454, 'f1': 0.5538461538461538, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9547383309759547, 'recall': 0.9726224783861671, 'f1': 0.9635974304068521, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9404915912031048, 'recall': 0.9553219448094612, 'f1': 0.9478487614080835, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9836552748885586, 'recall': 0.976401179941003, 'f1': 0.9800148038490007, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.169980</td>\n",
       "      <td>0.940976</td>\n",
       "      <td>0.960324</td>\n",
       "      <td>0.950552</td>\n",
       "      <td>0.955313</td>\n",
       "      <td>0.939099</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.951024</td>\n",
       "      <td>0.962885</td>\n",
       "      <td>0.945623</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.948138</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>0.941941</td>\n",
       "      <td>0.957709</td>\n",
       "      <td>0.949760</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.956747</td>\n",
       "      <td>0.964232</td>\n",
       "      <td>0.960475</td>\n",
       "      <td>0.971698</td>\n",
       "      <td>{'precision': 0.9736070381231672, 'recall': 0.9822485207100592, 'f1': 0.9779086892488954, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9132841328413284, 'recall': 0.953757225433526, 'f1': 0.9330819981149858, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9356060606060606, 'recall': 0.9821073558648111, 'f1': 0.9582929194956353, 'number': 503}</td>\n",
       "      <td>{'precision': 0.07142857142857142, 'recall': 0.0625, 'f1': 0.06666666666666667, 'number': 16}</td>\n",
       "      <td>{'precision': 0.18181818181818182, 'recall': 0.26666666666666666, 'f1': 0.21621621621621623, 'number': 30}</td>\n",
       "      <td>{'precision': 0.6111111111111112, 'recall': 0.6666666666666666, 'f1': 0.6376811594202899, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9557142857142857, 'recall': 0.9639769452449568, 'f1': 0.9598278335724534, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9393548387096774, 'recall': 0.9566360052562418, 'f1': 0.9479166666666666, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.160786</td>\n",
       "      <td>0.948659</td>\n",
       "      <td>0.963220</td>\n",
       "      <td>0.955884</td>\n",
       "      <td>0.951216</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.954818</td>\n",
       "      <td>0.958788</td>\n",
       "      <td>0.941215</td>\n",
       "      <td>0.960667</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>0.946165</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>0.953061</td>\n",
       "      <td>0.962388</td>\n",
       "      <td>0.954646</td>\n",
       "      <td>0.964605</td>\n",
       "      <td>0.959600</td>\n",
       "      <td>0.969340</td>\n",
       "      <td>{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9058380414312618, 'recall': 0.9267822736030829, 'f1': 0.9161904761904761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9403578528827038, 'recall': 0.9403578528827038, 'f1': 0.9403578528827038, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.5, 'f1': 0.36363636363636365, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2, 'f1': 0.28571428571428575, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9545454545454546, 'recall': 0.968299711815562, 'f1': 0.9613733905579399, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9272030651340997, 'recall': 0.9540078843626807, 'f1': 0.9404145077720208, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.159154</td>\n",
       "      <td>0.953402</td>\n",
       "      <td>0.965827</td>\n",
       "      <td>0.959574</td>\n",
       "      <td>0.960030</td>\n",
       "      <td>0.942594</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.953838</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>0.949669</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.945680</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.953394</td>\n",
       "      <td>0.969774</td>\n",
       "      <td>0.958088</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>{'precision': 0.9794419970631424, 'recall': 0.9866863905325444, 'f1': 0.983050847457627, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9342105263157895, 'recall': 0.9576107899807321, 'f1': 0.9457659372026641, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9340866290018832, 'recall': 0.9860834990059643, 'f1': 0.9593810444874274, 'number': 503}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.3, 'f1': 0.3, 'number': 30}</td>\n",
       "      <td>{'precision': 0.775, 'recall': 0.9393939393939394, 'f1': 0.8493150684931509, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9407616361071932, 'recall': 0.9610951008645533, 'f1': 0.9508196721311475, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9273885350318471, 'recall': 0.9566360052562418, 'f1': 0.9417852522639067, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.160363</td>\n",
       "      <td>0.952096</td>\n",
       "      <td>0.966985</td>\n",
       "      <td>0.959483</td>\n",
       "      <td>0.955313</td>\n",
       "      <td>0.948320</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.961519</td>\n",
       "      <td>0.956320</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.959814</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.951828</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.957524</td>\n",
       "      <td>0.966547</td>\n",
       "      <td>0.961567</td>\n",
       "      <td>0.969449</td>\n",
       "      <td>0.965492</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9342105263157895, 'recall': 0.9576107899807321, 'f1': 0.9457659372026641, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9571984435797666, 'recall': 0.9781312127236581, 'f1': 0.967551622418879, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2777777777777778, 'recall': 0.3125, 'f1': 0.29411764705882354, 'number': 16}</td>\n",
       "      <td>{'precision': 0.32558139534883723, 'recall': 0.4666666666666667, 'f1': 0.3835616438356165, 'number': 30}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.9090909090909091, 'f1': 0.821917808219178, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9528571428571428, 'recall': 0.9610951008645533, 'f1': 0.9569583931133429, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9520725388601037, 'recall': 0.9658344283837057, 'f1': 0.9589041095890412, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.130537</td>\n",
       "      <td>0.958058</td>\n",
       "      <td>0.965827</td>\n",
       "      <td>0.961927</td>\n",
       "      <td>0.958168</td>\n",
       "      <td>0.946604</td>\n",
       "      <td>0.958530</td>\n",
       "      <td>0.952530</td>\n",
       "      <td>0.963257</td>\n",
       "      <td>0.959736</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.964511</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.957804</td>\n",
       "      <td>0.968098</td>\n",
       "      <td>0.962922</td>\n",
       "      <td>0.967586</td>\n",
       "      <td>0.965248</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8975791433891993, 'recall': 0.928709055876686, 'f1': 0.912878787878788, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9346534653465347, 'recall': 0.9383697813121272, 'f1': 0.9365079365079366, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3125, 'recall': 0.625, 'f1': 0.4166666666666667, 'number': 16}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9645669291338582, 'recall': 0.9658344283837057, 'f1': 0.9652002626395274, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.127793</td>\n",
       "      <td>0.962356</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.966104</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.949563</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.958940</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.956433</td>\n",
       "      <td>0.967107</td>\n",
       "      <td>0.961741</td>\n",
       "      <td>0.974491</td>\n",
       "      <td>0.968148</td>\n",
       "      <td>0.973920</td>\n",
       "      <td>0.971025</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>{'precision': 0.9779086892488954, 'recall': 0.9822485207100592, 'f1': 0.9800738007380073, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9392789373814042, 'recall': 0.953757225433526, 'f1': 0.9464627151051626, 'number': 519}</td>\n",
       "      <td>{'precision': 0.944337811900192, 'recall': 0.9781312127236581, 'f1': 0.9609375, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.1875, 'f1': 0.2727272727272727, 'number': 16}</td>\n",
       "      <td>{'precision': 0.30952380952380953, 'recall': 0.43333333333333335, 'f1': 0.3611111111111111, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9546044098573282, 'recall': 0.9671484888304862, 'f1': 0.9608355091383812, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.126270</td>\n",
       "      <td>0.966131</td>\n",
       "      <td>0.974805</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.959285</td>\n",
       "      <td>0.964639</td>\n",
       "      <td>0.973753</td>\n",
       "      <td>0.969175</td>\n",
       "      <td>0.963630</td>\n",
       "      <td>0.963134</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.969195</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.969184</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.974388</td>\n",
       "      <td>0.978018</td>\n",
       "      <td>0.976199</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9377358490566038, 'recall': 0.9576107899807321, 'f1': 0.9475691134413726, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9759036144578314, 'recall': 0.9662027833001988, 'f1': 0.971028971028971, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34375, 'recall': 0.6875, 'f1': 0.4583333333333333, 'number': 16}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.7, 'f1': 0.5316455696202531, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9776021080368906, 'recall': 0.9750328515111695, 'f1': 0.9763157894736841, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.956921</td>\n",
       "      <td>0.964958</td>\n",
       "      <td>0.960923</td>\n",
       "      <td>0.963133</td>\n",
       "      <td>0.959152</td>\n",
       "      <td>0.973753</td>\n",
       "      <td>0.966397</td>\n",
       "      <td>0.971202</td>\n",
       "      <td>0.961282</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960640</td>\n",
       "      <td>0.976043</td>\n",
       "      <td>0.960082</td>\n",
       "      <td>0.967695</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>0.966468</td>\n",
       "      <td>0.965389</td>\n",
       "      <td>0.977905</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9911242603550295, 'f1': 0.9896602658788773, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9669260700389105, 'recall': 0.9880715705765407, 'f1': 0.9773844641101278, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3125, 'f1': 0.3225806451612903, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2926829268292683, 'recall': 0.4, 'f1': 0.3380281690140845, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8333333333333334, 'recall': 0.45454545454545453, 'f1': 0.5882352941176471, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9598445595854922, 'recall': 0.973718791064389, 'f1': 0.9667318982387476, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.126824</td>\n",
       "      <td>0.966121</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.960703</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.967960</td>\n",
       "      <td>0.972195</td>\n",
       "      <td>0.964262</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.967785</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>0.973713</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.976787</td>\n",
       "      <td>0.981877</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9437148217636022, 'recall': 0.9691714836223507, 'f1': 0.9562737642585553, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9669260700389105, 'recall': 0.9880715705765407, 'f1': 0.9773844641101278, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3157894736842105, 'recall': 0.375, 'f1': 0.34285714285714286, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35135135135135137, 'recall': 0.43333333333333335, 'f1': 0.3880597014925374, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.6, 'f1': 0.6666666666666665, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9630681818181818, 'recall': 0.9769452449567724, 'f1': 0.9699570815450643, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.139323</td>\n",
       "      <td>0.965775</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>0.969120</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.958118</td>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.965356</td>\n",
       "      <td>0.974553</td>\n",
       "      <td>0.967463</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.969395</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>0.962209</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.967129</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.966802</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.971640</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9483747609942639, 'recall': 0.9860834990059643, 'f1': 0.9668615984405459, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.25, 'f1': 0.32, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5925925925925926, 'recall': 0.5333333333333333, 'f1': 0.5614035087719299, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9589235127478754, 'recall': 0.9755043227665706, 'f1': 0.9671428571428571, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3076923076923077, 'recall': 0.5714285714285714, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.145991</td>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>0.966485</td>\n",
       "      <td>0.960552</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.967229</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.961896</td>\n",
       "      <td>0.971219</td>\n",
       "      <td>0.966535</td>\n",
       "      <td>0.971450</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9340866290018832, 'recall': 0.9556840077071291, 'f1': 0.9447619047619048, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9701789264413518, 'recall': 0.9701789264413518, 'f1': 0.9701789264413518, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.5, 'f1': 0.36363636363636365, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4878048780487805, 'recall': 0.6666666666666666, 'f1': 0.5633802816901409, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9669064748201439, 'recall': 0.968299711815562, 'f1': 0.9676025917926565, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.148107</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.969295</td>\n",
       "      <td>0.967105</td>\n",
       "      <td>0.962058</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>0.966832</td>\n",
       "      <td>0.972071</td>\n",
       "      <td>0.966799</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>0.978898</td>\n",
       "      <td>0.964140</td>\n",
       "      <td>0.971219</td>\n",
       "      <td>0.967666</td>\n",
       "      <td>0.975484</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.976912</td>\n",
       "      <td>{'precision': 0.985207100591716, 'recall': 0.985207100591716, 'f1': 0.985207100591716, 'number': 676}</td>\n",
       "      <td>{'precision': 0.943289224952741, 'recall': 0.9614643545279383, 'f1': 0.9522900763358778, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9482758620689655, 'recall': 0.9840954274353877, 'f1': 0.9658536585365853, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.25, 'f1': 0.34782608695652173, 'number': 16}</td>\n",
       "      <td>{'precision': 0.625, 'recall': 0.5, 'f1': 0.5555555555555556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9615384615384616, 'recall': 0.9726224783861671, 'f1': 0.9670487106017192, 'number': 694}</td>\n",
       "      <td>{'precision': 0.959792477302205, 'recall': 0.9724047306176085, 'f1': 0.9660574412532638, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9248554913294798, 'recall': 0.9467455621301775, 'f1': 0.935672514619883, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8797814207650273, 'recall': 0.930635838150289, 'f1': 0.9044943820224719, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8797814207650273, 'recall': 0.9602385685884692, 'f1': 0.9182509505703422, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8943758573388203, 'recall': 0.9394812680115274, 'f1': 0.9163738580463809, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9420103092783505, 'recall': 0.9605781865965834, 'f1': 0.9512036434612882, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9461426491994177, 'recall': 0.9615384615384616, 'f1': 0.9537784299339691, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8745519713261649, 'recall': 0.9402697495183044, 'f1': 0.9062209842154133, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8745519713261649, 'recall': 0.9701789264413518, 'f1': 0.9198868991517437, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9367977528089888, 'recall': 0.9610951008645533, 'f1': 0.9487908961593172, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9287531806615776, 'recall': 0.9592641261498029, 'f1': 0.9437621202327086, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9868035190615836, 'recall': 0.9926253687315634, 'f1': 0.9897058823529412, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9662261380323054, 'recall': 0.9733727810650887, 'f1': 0.969786293294031, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9292543021032504, 'recall': 0.9364161849710982, 'f1': 0.9328214971209213, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9292543021032504, 'recall': 0.9662027833001988, 'f1': 0.9473684210526316, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.28125, 'recall': 0.3, 'f1': 0.29032258064516125, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5625, 'recall': 0.5454545454545454, 'f1': 0.5538461538461538, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9547383309759547, 'recall': 0.9726224783861671, 'f1': 0.9635974304068521, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9404915912031048, 'recall': 0.9553219448094612, 'f1': 0.9478487614080835, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9836552748885586, 'recall': 0.976401179941003, 'f1': 0.9800148038490007, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736070381231672, 'recall': 0.9822485207100592, 'f1': 0.9779086892488954, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9132841328413284, 'recall': 0.953757225433526, 'f1': 0.9330819981149858, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9356060606060606, 'recall': 0.9821073558648111, 'f1': 0.9582929194956353, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.07142857142857142, 'recall': 0.0625, 'f1': 0.06666666666666667, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18181818181818182, 'recall': 0.26666666666666666, 'f1': 0.21621621621621623, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6111111111111112, 'recall': 0.6666666666666666, 'f1': 0.6376811594202899, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557142857142857, 'recall': 0.9639769452449568, 'f1': 0.9598278335724534, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393548387096774, 'recall': 0.9566360052562418, 'f1': 0.9479166666666666, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882869692532943, 'recall': 0.995575221238938, 'f1': 0.9919177075679647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9058380414312618, 'recall': 0.9267822736030829, 'f1': 0.9161904761904761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9403578528827038, 'recall': 0.9403578528827038, 'f1': 0.9403578528827038, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.5, 'f1': 0.36363636363636365, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2, 'f1': 0.28571428571428575, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9545454545454546, 'recall': 0.968299711815562, 'f1': 0.9613733905579399, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9272030651340997, 'recall': 0.9540078843626807, 'f1': 0.9404145077720208, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794419970631424, 'recall': 0.9866863905325444, 'f1': 0.983050847457627, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9342105263157895, 'recall': 0.9576107899807321, 'f1': 0.9457659372026641, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9340866290018832, 'recall': 0.9860834990059643, 'f1': 0.9593810444874274, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.3, 'f1': 0.3, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.9393939393939394, 'f1': 0.8493150684931509, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9407616361071932, 'recall': 0.9610951008645533, 'f1': 0.9508196721311475, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9273885350318471, 'recall': 0.9566360052562418, 'f1': 0.9417852522639067, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9342105263157895, 'recall': 0.9576107899807321, 'f1': 0.9457659372026641, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9571984435797666, 'recall': 0.9781312127236581, 'f1': 0.967551622418879, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2777777777777778, 'recall': 0.3125, 'f1': 0.29411764705882354, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.32558139534883723, 'recall': 0.4666666666666667, 'f1': 0.3835616438356165, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.9090909090909091, 'f1': 0.821917808219178, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9528571428571428, 'recall': 0.9610951008645533, 'f1': 0.9569583931133429, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9520725388601037, 'recall': 0.9658344283837057, 'f1': 0.9589041095890412, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8975791433891993, 'recall': 0.928709055876686, 'f1': 0.912878787878788, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9346534653465347, 'recall': 0.9383697813121272, 'f1': 0.9365079365079366, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3125, 'recall': 0.625, 'f1': 0.4166666666666667, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9645669291338582, 'recall': 0.9658344283837057, 'f1': 0.9652002626395274, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779086892488954, 'recall': 0.9822485207100592, 'f1': 0.9800738007380073, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9392789373814042, 'recall': 0.953757225433526, 'f1': 0.9464627151051626, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944337811900192, 'recall': 0.9781312127236581, 'f1': 0.9609375, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.1875, 'f1': 0.2727272727272727, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.30952380952380953, 'recall': 0.43333333333333335, 'f1': 0.3611111111111111, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9546044098573282, 'recall': 0.9671484888304862, 'f1': 0.9608355091383812, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9377358490566038, 'recall': 0.9576107899807321, 'f1': 0.9475691134413726, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9759036144578314, 'recall': 0.9662027833001988, 'f1': 0.971028971028971, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34375, 'recall': 0.6875, 'f1': 0.4583333333333333, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.7, 'f1': 0.5316455696202531, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9776021080368906, 'recall': 0.9750328515111695, 'f1': 0.9763157894736841, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9911242603550295, 'f1': 0.9896602658788773, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9489603024574669, 'recall': 0.9672447013487476, 'f1': 0.9580152671755725, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669260700389105, 'recall': 0.9880715705765407, 'f1': 0.9773844641101278, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3125, 'f1': 0.3225806451612903, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2926829268292683, 'recall': 0.4, 'f1': 0.3380281690140845, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.45454545454545453, 'f1': 0.5882352941176471, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9598445595854922, 'recall': 0.973718791064389, 'f1': 0.9667318982387476, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9437148217636022, 'recall': 0.9691714836223507, 'f1': 0.9562737642585553, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669260700389105, 'recall': 0.9880715705765407, 'f1': 0.9773844641101278, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3157894736842105, 'recall': 0.375, 'f1': 0.34285714285714286, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35135135135135137, 'recall': 0.43333333333333335, 'f1': 0.3880597014925374, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.6, 'f1': 0.6666666666666665, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9630681818181818, 'recall': 0.9769452449567724, 'f1': 0.9699570815450643, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9483747609942639, 'recall': 0.9860834990059643, 'f1': 0.9668615984405459, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.25, 'f1': 0.32, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5925925925925926, 'recall': 0.5333333333333333, 'f1': 0.5614035087719299, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9589235127478754, 'recall': 0.9755043227665706, 'f1': 0.9671428571428571, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3076923076923077, 'recall': 0.5714285714285714, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9340866290018832, 'recall': 0.9556840077071291, 'f1': 0.9447619047619048, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9701789264413518, 'recall': 0.9701789264413518, 'f1': 0.9701789264413518, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.5, 'f1': 0.36363636363636365, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4878048780487805, 'recall': 0.6666666666666666, 'f1': 0.5633802816901409, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669064748201439, 'recall': 0.968299711815562, 'f1': 0.9676025917926565, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.985207100591716, 'recall': 0.985207100591716, 'f1': 0.985207100591716, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943289224952741, 'recall': 0.9614643545279383, 'f1': 0.9522900763358778, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482758620689655, 'recall': 0.9840954274353877, 'f1': 0.9658536585365853, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.25, 'f1': 0.34782608695652173, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.5, 'f1': 0.5555555555555556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9615384615384616, 'recall': 0.9726224783861671, 'f1': 0.9670487106017192, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.959792477302205, 'recall': 0.9724047306176085, 'f1': 0.9660574412532638, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000 (score: 0.9704483205996829).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9589201877934272, 'recall': 0.96973293768546, 'f1': 0.9642962525818826, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8928892889288929, 'recall': 0.906764168190128, 'f1': 0.8997732426303855, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724208375893769, 'recall': 0.9233753637245393, 'f1': 0.9472636815920398, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.30303030303030304, 'recall': 0.6349206349206349, 'f1': 0.4102564102564103, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.810126582278481, 'f1': 0.5739910313901344, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.9767441860465116, 'f1': 0.988235294117647, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7307692307692307, 'recall': 0.5757575757575758, 'f1': 0.6440677966101696, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9714774671990872, 'recall': 0.9748139668002289, 'f1': 0.9731428571428572, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9820325659741718, 'recall': 0.978735310576385, 'f1': 0.9803811659192825, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9971461187214612, 'recall': 0.9977155910908052, 'f1': 0.9974307736226091, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9911242603550295, 'f1': 0.9889298892988929, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9377358490566038, 'recall': 0.9576107899807321, 'f1': 0.9475691134413726, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9759036144578314, 'recall': 0.9662027833001988, 'f1': 0.971028971028971, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34375, 'recall': 0.6875, 'f1': 0.4583333333333333, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.7, 'f1': 0.5316455696202531, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.8, 'f1': 0.5714285714285714, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9776021080368906, 'recall': 0.9750328515111695, 'f1': 0.9763157894736841, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-PER+O\",\n",
      "    \"2\": \"I-PER+i_TITREH\",\n",
      "    \"3\": \"I-ACT+O\",\n",
      "    \"4\": \"I-DESC+O\",\n",
      "    \"5\": \"I-DESC+i_ACT\",\n",
      "    \"6\": \"I-DESC+i_TITREP\",\n",
      "    \"7\": \"I-SPAT+O\",\n",
      "    \"8\": \"I-SPAT+i_LOC\",\n",
      "    \"9\": \"I-SPAT+i_CARDINAL\",\n",
      "    \"10\": \"I-SPAT+i_FT\",\n",
      "    \"11\": \"I-TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT+O\": 3,\n",
      "    \"I-DESC+O\": 4,\n",
      "    \"I-DESC+i_ACT\": 5,\n",
      "    \"I-DESC+i_TITREP\": 6,\n",
      "    \"I-PER+O\": 1,\n",
      "    \"I-PER+i_TITREH\": 2,\n",
      "    \"I-SPAT+O\": 7,\n",
      "    \"I-SPAT+i_CARDINAL\": 9,\n",
      "    \"I-SPAT+i_FT\": 10,\n",
      "    \"I-SPAT+i_LOC\": 8,\n",
      "    \"I-TITRE+O\": 11,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([12, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([12]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110040588\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/5000 22:13 < 02:28, 3.37 it/s, Epoch 11/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351355</td>\n",
       "      <td>0.940238</td>\n",
       "      <td>0.938604</td>\n",
       "      <td>0.939420</td>\n",
       "      <td>0.937314</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.924409</td>\n",
       "      <td>0.907264</td>\n",
       "      <td>0.940914</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.970829</td>\n",
       "      <td>0.921443</td>\n",
       "      <td>0.930103</td>\n",
       "      <td>0.925753</td>\n",
       "      <td>0.955871</td>\n",
       "      <td>0.931149</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.950968</td>\n",
       "      <td>{'precision': 0.8992805755395683, 'recall': 0.9245562130177515, 'f1': 0.911743253099927, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8556149732620321, 'recall': 0.9248554913294798, 'f1': 0.888888888888889, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8556149732620321, 'recall': 0.9542743538767395, 'f1': 0.9022556390977442, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9098474341192788, 'recall': 0.9452449567723343, 'f1': 0.9272084805653711, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9420849420849421, 'recall': 0.961892247043364, 'f1': 0.9518855656697008, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263622</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.951347</td>\n",
       "      <td>0.944101</td>\n",
       "      <td>0.943520</td>\n",
       "      <td>0.911246</td>\n",
       "      <td>0.948556</td>\n",
       "      <td>0.929527</td>\n",
       "      <td>0.948486</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.944426</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.947430</td>\n",
       "      <td>0.936022</td>\n",
       "      <td>0.958788</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.955663</td>\n",
       "      <td>0.945099</td>\n",
       "      <td>0.957547</td>\n",
       "      <td>{'precision': 0.945906432748538, 'recall': 0.9571005917159763, 'f1': 0.9514705882352941, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8678571428571429, 'recall': 0.9364161849710982, 'f1': 0.9008341056533826, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8678571428571429, 'recall': 0.9662027833001988, 'f1': 0.9143932267168391, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7368421052631579, 'recall': 0.42424242424242425, 'f1': 0.5384615384615385, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9207650273224044, 'recall': 0.9711815561959655, 'f1': 0.9453015427769985, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9093167701863354, 'recall': 0.961892247043364, 'f1': 0.9348659003831418, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197569</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>0.960904</td>\n",
       "      <td>0.960347</td>\n",
       "      <td>0.958788</td>\n",
       "      <td>0.946715</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.962388</td>\n",
       "      <td>0.961719</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.958180</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.953244</td>\n",
       "      <td>0.958003</td>\n",
       "      <td>0.955617</td>\n",
       "      <td>0.968098</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.964978</td>\n",
       "      <td>0.962289</td>\n",
       "      <td>0.971822</td>\n",
       "      <td>{'precision': 0.9678832116788321, 'recall': 0.9807692307692307, 'f1': 0.9742836149889786, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9224952741020794, 'recall': 0.9402697495183044, 'f1': 0.9312977099236641, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9224952741020794, 'recall': 0.9701789264413518, 'f1': 0.9457364341085271, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4666666666666667, 'recall': 0.23333333333333334, 'f1': 0.31111111111111117, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9545454545454546, 'recall': 0.968299711815562, 'f1': 0.9613733905579399, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9455252918287937, 'recall': 0.9579500657030223, 'f1': 0.9516971279373369, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.161515</td>\n",
       "      <td>0.948059</td>\n",
       "      <td>0.962062</td>\n",
       "      <td>0.955009</td>\n",
       "      <td>0.958044</td>\n",
       "      <td>0.912869</td>\n",
       "      <td>0.956955</td>\n",
       "      <td>0.934393</td>\n",
       "      <td>0.962016</td>\n",
       "      <td>0.965703</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>0.978153</td>\n",
       "      <td>0.935419</td>\n",
       "      <td>0.957122</td>\n",
       "      <td>0.946146</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.956985</td>\n",
       "      <td>0.969821</td>\n",
       "      <td>0.963360</td>\n",
       "      <td>0.971822</td>\n",
       "      <td>{'precision': 0.9620991253644315, 'recall': 0.9763313609467456, 'f1': 0.9691629955947137, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8945454545454545, 'recall': 0.9479768786127167, 'f1': 0.9204864359214219, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8945454545454545, 'recall': 0.9781312127236581, 'f1': 0.9344729344729346, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.14285714285714285, 'recall': 0.23333333333333334, 'f1': 0.17721518987341772, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7837837837837838, 'recall': 0.8787878787878788, 'f1': 0.8285714285714285, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9325842696629213, 'recall': 0.9567723342939481, 'f1': 0.9445234708392602, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9532467532467532, 'recall': 0.9645203679369251, 'f1': 0.9588504245591117, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.174543</td>\n",
       "      <td>0.958983</td>\n",
       "      <td>0.961483</td>\n",
       "      <td>0.960231</td>\n",
       "      <td>0.955809</td>\n",
       "      <td>0.940391</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.950402</td>\n",
       "      <td>0.959037</td>\n",
       "      <td>0.958445</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.974801</td>\n",
       "      <td>0.948226</td>\n",
       "      <td>0.957416</td>\n",
       "      <td>0.952798</td>\n",
       "      <td>0.966919</td>\n",
       "      <td>0.957658</td>\n",
       "      <td>0.969076</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>{'precision': 0.9679767103347889, 'recall': 0.9837278106508875, 'f1': 0.9757887013939839, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9186691312384473, 'recall': 0.9576107899807321, 'f1': 0.9377358490566037, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9186691312384473, 'recall': 0.9880715705765407, 'f1': 0.9521072796934865, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.2, 'f1': 0.3, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7435897435897436, 'recall': 0.8787878787878788, 'f1': 0.8055555555555556, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9350282485875706, 'recall': 0.9538904899135446, 'f1': 0.9443651925820257, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9404915912031048, 'recall': 0.9553219448094612, 'f1': 0.9478487614080835, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.137651</td>\n",
       "      <td>0.962514</td>\n",
       "      <td>0.966696</td>\n",
       "      <td>0.964600</td>\n",
       "      <td>0.963381</td>\n",
       "      <td>0.945529</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.955596</td>\n",
       "      <td>0.967354</td>\n",
       "      <td>0.968435</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.977781</td>\n",
       "      <td>0.955459</td>\n",
       "      <td>0.963877</td>\n",
       "      <td>0.959649</td>\n",
       "      <td>0.972567</td>\n",
       "      <td>0.963771</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.967526</td>\n",
       "      <td>0.975794</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9180633147113594, 'recall': 0.9499036608863198, 'f1': 0.9337121212121212, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9180633147113594, 'recall': 0.9801192842942346, 'f1': 0.9480769230769232, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3, 'f1': 0.3157894736842105, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7894736842105263, 'recall': 0.9090909090909091, 'f1': 0.8450704225352113, 'number': 33}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2, 'f1': 0.33333333333333337, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9570871261378413, 'recall': 0.9671484888304862, 'f1': 0.9620915032679739, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.130465</td>\n",
       "      <td>0.956509</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>0.962291</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.951081</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.960229</td>\n",
       "      <td>0.963505</td>\n",
       "      <td>0.953104</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.957532</td>\n",
       "      <td>0.972195</td>\n",
       "      <td>0.951968</td>\n",
       "      <td>0.966226</td>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.964867</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.974553</td>\n",
       "      <td>{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9217877094972067, 'recall': 0.953757225433526, 'f1': 0.9375, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9459459459459459, 'recall': 0.974155069582505, 'f1': 0.9598432908912832, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2631578947368421, 'recall': 0.3125, 'f1': 0.2857142857142857, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4666666666666667, 'f1': 0.3888888888888889, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2, 'f1': 0.28571428571428575, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9643874643874644, 'recall': 0.9755043227665706, 'f1': 0.969914040114613, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9432258064516129, 'recall': 0.9605781865965834, 'f1': 0.9518229166666666, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.145785</td>\n",
       "      <td>0.959312</td>\n",
       "      <td>0.969592</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.961023</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.959147</td>\n",
       "      <td>0.965243</td>\n",
       "      <td>0.959022</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>0.963160</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.954506</td>\n",
       "      <td>0.967401</td>\n",
       "      <td>0.960910</td>\n",
       "      <td>0.970271</td>\n",
       "      <td>0.966014</td>\n",
       "      <td>0.974292</td>\n",
       "      <td>0.970135</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9202226345083488, 'recall': 0.9556840077071291, 'f1': 0.9376181474480151, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9533980582524272, 'recall': 0.9761431411530815, 'f1': 0.9646365422396858, 'number': 503}</td>\n",
       "      <td>{'precision': 0.20833333333333334, 'recall': 0.3125, 'f1': 0.25, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3111111111111111, 'recall': 0.4666666666666667, 'f1': 0.37333333333333335, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9633986928104575, 'recall': 0.9684625492772667, 'f1': 0.9659239842726082, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.138719</td>\n",
       "      <td>0.956236</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>0.962153</td>\n",
       "      <td>0.961768</td>\n",
       "      <td>0.946364</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.954735</td>\n",
       "      <td>0.966485</td>\n",
       "      <td>0.953978</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>0.960609</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>0.949711</td>\n",
       "      <td>0.965051</td>\n",
       "      <td>0.957320</td>\n",
       "      <td>0.970209</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.965045</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>{'precision': 0.9677891654465594, 'recall': 0.977810650887574, 'f1': 0.9727740986019133, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9257884972170687, 'recall': 0.9614643545279383, 'f1': 0.9432892249527409, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9479768786127167, 'recall': 0.9781312127236581, 'f1': 0.9628180039138944, 'number': 503}</td>\n",
       "      <td>{'precision': 0.35, 'recall': 0.4375, 'f1': 0.38888888888888884, 'number': 16}</td>\n",
       "      <td>{'precision': 0.39473684210526316, 'recall': 0.5, 'f1': 0.4411764705882353, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.8, 'f1': 0.47058823529411764, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9542203147353362, 'recall': 0.9610951008645533, 'f1': 0.9576453697056713, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9544863459037711, 'recall': 0.9645203679369251, 'f1': 0.9594771241830065, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>0.963432</td>\n",
       "      <td>0.969012</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.958913</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.960021</td>\n",
       "      <td>0.962388</td>\n",
       "      <td>0.960344</td>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.964487</td>\n",
       "      <td>0.971946</td>\n",
       "      <td>0.957787</td>\n",
       "      <td>0.966226</td>\n",
       "      <td>0.961988</td>\n",
       "      <td>0.967167</td>\n",
       "      <td>0.968101</td>\n",
       "      <td>0.972429</td>\n",
       "      <td>0.970260</td>\n",
       "      <td>0.978153</td>\n",
       "      <td>{'precision': 0.9837997054491899, 'recall': 0.9881656804733728, 'f1': 0.9859778597785979, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9299242424242424, 'recall': 0.9460500963391136, 'f1': 0.9379178605539636, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9563492063492064, 'recall': 0.9582504970178927, 'f1': 0.9572989076464746, 'number': 503}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}</td>\n",
       "      <td>{'precision': 0.475, 'recall': 0.6333333333333333, 'f1': 0.5428571428571427, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8787878787878788, 'recall': 0.8787878787878788, 'f1': 0.8787878787878788, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9556509298998569, 'recall': 0.962536023054755, 'f1': 0.9590811198851399, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9597402597402598, 'recall': 0.9710906701708278, 'f1': 0.9653821032005226, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.956906</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.963921</td>\n",
       "      <td>0.958416</td>\n",
       "      <td>0.958833</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>0.965119</td>\n",
       "      <td>0.952005</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.958623</td>\n",
       "      <td>0.972691</td>\n",
       "      <td>0.955814</td>\n",
       "      <td>0.965639</td>\n",
       "      <td>0.960701</td>\n",
       "      <td>0.968905</td>\n",
       "      <td>0.963482</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>0.968304</td>\n",
       "      <td>0.976043</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9307116104868914, 'recall': 0.9576107899807321, 'f1': 0.9439696106362773, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9645669291338582, 'recall': 0.974155069582505, 'f1': 0.9693372898120672, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2692307692307692, 'recall': 0.4375, 'f1': 0.33333333333333337, 'number': 16}</td>\n",
       "      <td>{'precision': 0.475, 'recall': 0.6333333333333333, 'f1': 0.5428571428571427, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.14285714285714285, 'recall': 0.4, 'f1': 0.21052631578947364, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9567723342939481, 'recall': 0.9567723342939481, 'f1': 0.9567723342939481, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.962910</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.966383</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>0.954428</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.960897</td>\n",
       "      <td>0.960650</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.963455</td>\n",
       "      <td>0.969588</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.967107</td>\n",
       "      <td>0.962022</td>\n",
       "      <td>0.965119</td>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>0.971004</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.928436911487759, 'recall': 0.9499036608863198, 'f1': 0.939047619047619, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9604743083003953, 'recall': 0.9662027833001988, 'f1': 0.9633300297324084, 'number': 503}</td>\n",
       "      <td>{'precision': 0.28, 'recall': 0.4375, 'f1': 0.34146341463414637, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3958333333333333, 'recall': 0.6333333333333333, 'f1': 0.4871794871794872, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9568627450980393, 'recall': 0.961892247043364, 'f1': 0.9593709043250329, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.126449</td>\n",
       "      <td>0.963642</td>\n",
       "      <td>0.974805</td>\n",
       "      <td>0.969191</td>\n",
       "      <td>0.970457</td>\n",
       "      <td>0.951157</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.965220</td>\n",
       "      <td>0.979891</td>\n",
       "      <td>0.954677</td>\n",
       "      <td>0.971219</td>\n",
       "      <td>0.962877</td>\n",
       "      <td>0.976850</td>\n",
       "      <td>0.966164</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.972423</td>\n",
       "      <td>0.979518</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9896449704142012, 'f1': 0.9874538745387453, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9330855018587361, 'recall': 0.9672447013487476, 'f1': 0.9498580889309367, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9475920679886686, 'recall': 0.9639769452449568, 'f1': 0.9557142857142857, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9496774193548387, 'recall': 0.9671484888304862, 'f1': 0.9583333333333334, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.42857142857142855, 'f1': 0.375, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.153405</td>\n",
       "      <td>0.964306</td>\n",
       "      <td>0.970171</td>\n",
       "      <td>0.967230</td>\n",
       "      <td>0.958416</td>\n",
       "      <td>0.960062</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>0.965823</td>\n",
       "      <td>0.962761</td>\n",
       "      <td>0.959709</td>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.964167</td>\n",
       "      <td>0.969215</td>\n",
       "      <td>0.959907</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.965094</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>0.969607</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.972129</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9283018867924528, 'recall': 0.9479768786127167, 'f1': 0.9380362249761677, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9662698412698413, 'recall': 0.9681908548707754, 'f1': 0.9672293942403178, 'number': 503}</td>\n",
       "      <td>{'precision': 0.19230769230769232, 'recall': 0.3125, 'f1': 0.2380952380952381, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4666666666666667, 'recall': 0.7, 'f1': 0.56, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9608865710560626, 'recall': 0.9684625492772667, 'f1': 0.9646596858638743, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>0.963261</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.967565</td>\n",
       "      <td>0.963257</td>\n",
       "      <td>0.949231</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>0.960311</td>\n",
       "      <td>0.966733</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.965174</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.954113</td>\n",
       "      <td>0.970925</td>\n",
       "      <td>0.962445</td>\n",
       "      <td>0.971884</td>\n",
       "      <td>0.965733</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.976663</td>\n",
       "      <td>{'precision': 0.9823529411764705, 'recall': 0.9881656804733728, 'f1': 0.9852507374631269, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.953757225433526, 'f1': 0.9455587392550143, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9477756286266924, 'recall': 0.974155069582505, 'f1': 0.9607843137254902, 'number': 503}</td>\n",
       "      <td>{'precision': 0.45454545454545453, 'recall': 0.3125, 'f1': 0.3703703703703703, 'number': 16}</td>\n",
       "      <td>{'precision': 0.358974358974359, 'recall': 0.4666666666666667, 'f1': 0.40579710144927544, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9509803921568627, 'recall': 0.978386167146974, 'f1': 0.9644886363636364, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9561290322580646, 'recall': 0.973718791064389, 'f1': 0.9648437500000001, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.143893</td>\n",
       "      <td>0.963261</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.967565</td>\n",
       "      <td>0.965119</td>\n",
       "      <td>0.963174</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.968954</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.959157</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.964877</td>\n",
       "      <td>0.976167</td>\n",
       "      <td>0.961405</td>\n",
       "      <td>0.972981</td>\n",
       "      <td>0.967158</td>\n",
       "      <td>0.973870</td>\n",
       "      <td>0.968946</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.972722</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9465648854961832, 'recall': 0.9556840077071291, 'f1': 0.9511025886864813, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9665354330708661, 'recall': 0.9761431411530815, 'f1': 0.9713155291790306, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3125, 'recall': 0.3125, 'f1': 0.3125, 'number': 16}</td>\n",
       "      <td>{'precision': 0.425, 'recall': 0.5666666666666667, 'f1': 0.48571428571428565, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9700854700854701, 'recall': 0.9812680115273775, 'f1': 0.9756446991404012, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.42857142857142855, 'f1': 0.3157894736842105, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.128757</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.974225</td>\n",
       "      <td>0.970431</td>\n",
       "      <td>0.969960</td>\n",
       "      <td>0.965696</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.970488</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.968792</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>0.967055</td>\n",
       "      <td>0.974156</td>\n",
       "      <td>0.970593</td>\n",
       "      <td>0.977718</td>\n",
       "      <td>0.974036</td>\n",
       "      <td>0.978390</td>\n",
       "      <td>0.976208</td>\n",
       "      <td>0.981629</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.941398865784499, 'recall': 0.9595375722543352, 'f1': 0.950381679389313, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3888888888888889, 'recall': 0.4375, 'f1': 0.411764705882353, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5128205128205128, 'recall': 0.6666666666666666, 'f1': 0.5797101449275363, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9755747126436781, 'recall': 0.978386167146974, 'f1': 0.976978417266187, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9685863874345549, 'recall': 0.9724047306176085, 'f1': 0.9704918032786886, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.140220</td>\n",
       "      <td>0.965567</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.970020</td>\n",
       "      <td>0.964623</td>\n",
       "      <td>0.962019</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.968098</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.970461</td>\n",
       "      <td>0.979022</td>\n",
       "      <td>0.963901</td>\n",
       "      <td>0.972394</td>\n",
       "      <td>0.968129</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.971090</td>\n",
       "      <td>0.976155</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.976787</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9264150943396227, 'recall': 0.9460500963391136, 'f1': 0.9361296472831266, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9508840864440079, 'recall': 0.9622266401590457, 'f1': 0.9565217391304347, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4375, 'f1': 0.37837837837837834, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9741379310344828, 'recall': 0.9769452449567724, 'f1': 0.9755395683453238, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9686274509803922, 'recall': 0.973718791064389, 'f1': 0.9711664482306683, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.156826</td>\n",
       "      <td>0.966350</td>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.963257</td>\n",
       "      <td>0.959627</td>\n",
       "      <td>0.973228</td>\n",
       "      <td>0.966380</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.968149</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>0.974801</td>\n",
       "      <td>0.963361</td>\n",
       "      <td>0.972981</td>\n",
       "      <td>0.968147</td>\n",
       "      <td>0.970891</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.975782</td>\n",
       "      <td>0.972521</td>\n",
       "      <td>0.980263</td>\n",
       "      <td>{'precision': 0.9779411764705882, 'recall': 0.9837278106508875, 'f1': 0.980825958702065, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9551656920077972, 'recall': 0.974155069582505, 'f1': 0.9645669291338583, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5128205128205128, 'recall': 0.6666666666666666, 'f1': 0.5797101449275363, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}</td>\n",
       "      <td>{'precision': 0.97, 'recall': 0.978386167146974, 'f1': 0.9741750358680057, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9686684073107049, 'recall': 0.9750328515111695, 'f1': 0.9718402095612311, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.139748</td>\n",
       "      <td>0.965675</td>\n",
       "      <td>0.977701</td>\n",
       "      <td>0.971651</td>\n",
       "      <td>0.969712</td>\n",
       "      <td>0.966163</td>\n",
       "      <td>0.974278</td>\n",
       "      <td>0.970204</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.968977</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.973798</td>\n",
       "      <td>0.983739</td>\n",
       "      <td>0.967404</td>\n",
       "      <td>0.976211</td>\n",
       "      <td>0.971788</td>\n",
       "      <td>0.978587</td>\n",
       "      <td>0.972623</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.976053</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>{'precision': 0.985207100591716, 'recall': 0.985207100591716, 'f1': 0.985207100591716, 'number': 676}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9607072691552063, 'recall': 0.9721669980119284, 'f1': 0.966403162055336, 'number': 503}</td>\n",
       "      <td>{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5384615384615384, 'recall': 0.7, 'f1': 0.608695652173913, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9769784172661871, 'recall': 0.978386167146974, 'f1': 0.9776817854571634, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9687906371911573, 'recall': 0.9789750328515112, 'f1': 0.9738562091503269, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.5714285714285714, 'f1': 0.7272727272727273, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.142806</td>\n",
       "      <td>0.963907</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.969182</td>\n",
       "      <td>0.963381</td>\n",
       "      <td>0.958876</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.962886</td>\n",
       "      <td>0.967354</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.968812</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>0.961281</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.965497</td>\n",
       "      <td>0.972505</td>\n",
       "      <td>0.972181</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.974349</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9395085066162571, 'recall': 0.9576107899807321, 'f1': 0.9484732824427481, 'number': 519}</td>\n",
       "      <td>{'precision': 0.976, 'recall': 0.9701789264413518, 'f1': 0.9730807577268196, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3103448275862069, 'recall': 0.5625, 'f1': 0.4, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4166666666666667, 'recall': 0.6666666666666666, 'f1': 0.5128205128205129, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.4, 'f1': 0.4444444444444445, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9568345323741008, 'recall': 0.9582132564841499, 'f1': 0.9575233981281498, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9711286089238845, 'recall': 0.9724047306176085, 'f1': 0.9717662508207485, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.157965</td>\n",
       "      <td>0.966935</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.961395</td>\n",
       "      <td>0.961019</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.965787</td>\n",
       "      <td>0.964995</td>\n",
       "      <td>0.967528</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.970422</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>0.963880</td>\n",
       "      <td>0.971806</td>\n",
       "      <td>0.967827</td>\n",
       "      <td>0.969588</td>\n",
       "      <td>0.972542</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9701789264413518, 'recall': 0.9701789264413518, 'f1': 0.9701789264413518, 'number': 503}</td>\n",
       "      <td>{'precision': 0.36, 'recall': 0.5625, 'f1': 0.43902439024390244, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9684813753581661, 'recall': 0.9740634005763689, 'f1': 0.9712643678160918, 'number': 694}</td>\n",
       "      <td>{'precision': 0.968503937007874, 'recall': 0.9697766097240473, 'f1': 0.96913985554826, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>0.966495</td>\n",
       "      <td>0.977411</td>\n",
       "      <td>0.971922</td>\n",
       "      <td>0.966733</td>\n",
       "      <td>0.964137</td>\n",
       "      <td>0.973753</td>\n",
       "      <td>0.968921</td>\n",
       "      <td>0.970705</td>\n",
       "      <td>0.965767</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.971845</td>\n",
       "      <td>0.978401</td>\n",
       "      <td>0.964856</td>\n",
       "      <td>0.975624</td>\n",
       "      <td>0.970210</td>\n",
       "      <td>0.974553</td>\n",
       "      <td>0.973373</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.976986</td>\n",
       "      <td>0.981380</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}</td>\n",
       "      <td>{'precision': 0.974155069582505, 'recall': 0.974155069582505, 'f1': 0.974155069582505, 'number': 503}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.7, 'f1': 0.5833333333333334, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9674902470741222, 'recall': 0.9776609724047306, 'f1': 0.9725490196078431, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.151129</td>\n",
       "      <td>0.967575</td>\n",
       "      <td>0.976542</td>\n",
       "      <td>0.972038</td>\n",
       "      <td>0.964374</td>\n",
       "      <td>0.963079</td>\n",
       "      <td>0.972178</td>\n",
       "      <td>0.967607</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.970218</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.973763</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>0.966220</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.970317</td>\n",
       "      <td>0.972815</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.974912</td>\n",
       "      <td>0.979891</td>\n",
       "      <td>{'precision': 0.9837278106508875, 'recall': 0.9837278106508875, 'f1': 0.9837278106508875, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9644268774703557, 'recall': 0.9701789264413518, 'f1': 0.9672943508424182, 'number': 503}</td>\n",
       "      <td>{'precision': 0.45454545454545453, 'recall': 0.625, 'f1': 0.5263157894736842, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5238095238095238, 'recall': 0.7333333333333333, 'f1': 0.611111111111111, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.96987087517934, 'recall': 0.9740634005763689, 'f1': 0.9719626168224298, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9725130890052356, 'recall': 0.9763469119579501, 'f1': 0.9744262295081966, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.161556</td>\n",
       "      <td>0.970351</td>\n",
       "      <td>0.976253</td>\n",
       "      <td>0.973293</td>\n",
       "      <td>0.966485</td>\n",
       "      <td>0.966684</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.970727</td>\n",
       "      <td>0.970209</td>\n",
       "      <td>0.970764</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.972379</td>\n",
       "      <td>0.977532</td>\n",
       "      <td>0.968476</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.971454</td>\n",
       "      <td>0.973870</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.976217</td>\n",
       "      <td>0.980884</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9485714285714286, 'recall': 0.9595375722543352, 'f1': 0.9540229885057472, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9627450980392157, 'recall': 0.9761431411530815, 'f1': 0.9693978282329714, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}</td>\n",
       "      <td>{'precision': 0.53125, 'recall': 0.5666666666666667, 'f1': 0.5483870967741935, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9756446991404012, 'recall': 0.9812680115273775, 'f1': 0.9784482758620688, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.167396</td>\n",
       "      <td>0.971240</td>\n",
       "      <td>0.977990</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>0.967708</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.971503</td>\n",
       "      <td>0.969712</td>\n",
       "      <td>0.971504</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.974410</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>0.969379</td>\n",
       "      <td>0.976211</td>\n",
       "      <td>0.972783</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.977703</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9684418145956607, 'recall': 0.9761431411530815, 'f1': 0.9722772277227723, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.6666666666666666, 'f1': 0.6153846153846153, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.158528</td>\n",
       "      <td>0.969019</td>\n",
       "      <td>0.978280</td>\n",
       "      <td>0.973627</td>\n",
       "      <td>0.969215</td>\n",
       "      <td>0.967792</td>\n",
       "      <td>0.977953</td>\n",
       "      <td>0.972846</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>0.969536</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.972757</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>0.968559</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.972807</td>\n",
       "      <td>0.976539</td>\n",
       "      <td>0.975899</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.978257</td>\n",
       "      <td>0.982746</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.962890625, 'recall': 0.9801192842942346, 'f1': 0.9714285714285714, 'number': 503}</td>\n",
       "      <td>{'precision': 0.35, 'recall': 0.4375, 'f1': 0.38888888888888884, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5555555555555556, 'recall': 0.6666666666666666, 'f1': 0.606060606060606, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9756446991404012, 'recall': 0.9812680115273775, 'f1': 0.9784482758620688, 'number': 694}</td>\n",
       "      <td>{'precision': 0.96875, 'recall': 0.9776609724047306, 'f1': 0.9731850882930019, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.154352</td>\n",
       "      <td>0.966189</td>\n",
       "      <td>0.976542</td>\n",
       "      <td>0.971338</td>\n",
       "      <td>0.970829</td>\n",
       "      <td>0.965785</td>\n",
       "      <td>0.977953</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.964947</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.968792</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.965417</td>\n",
       "      <td>0.975624</td>\n",
       "      <td>0.970494</td>\n",
       "      <td>0.978153</td>\n",
       "      <td>0.971207</td>\n",
       "      <td>0.980253</td>\n",
       "      <td>0.975709</td>\n",
       "      <td>0.980636</td>\n",
       "      <td>{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9420560747663551, 'recall': 0.9710982658959537, 'f1': 0.9563567362428842, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9576923076923077, 'recall': 0.9900596421471173, 'f1': 0.9736070381231671, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.375, 'f1': 0.38709677419354843, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5454545454545454, 'recall': 0.6, 'f1': 0.5714285714285713, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.4, 'f1': 0.3076923076923077, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9713055954088953, 'recall': 0.9755043227665706, 'f1': 0.9734004313443565, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.142604</td>\n",
       "      <td>0.971815</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.975794</td>\n",
       "      <td>0.969223</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>0.972266</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>0.971448</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.973387</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>0.970202</td>\n",
       "      <td>0.975330</td>\n",
       "      <td>0.972759</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.975158</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.977513</td>\n",
       "      <td>0.983739</td>\n",
       "      <td>{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9636711281070746, 'recall': 0.9710982658959537, 'f1': 0.9673704414587332, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9724950884086444, 'recall': 0.9840954274353877, 'f1': 0.9782608695652174, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6428571428571429, 'recall': 0.5625, 'f1': 0.6000000000000001, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.7333333333333333, 'f1': 0.6984126984126984, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9683908045977011, 'recall': 0.9711815561959655, 'f1': 0.9697841726618706, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9673629242819843, 'recall': 0.973718791064389, 'f1': 0.9705304518664047, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.135696</td>\n",
       "      <td>0.971535</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.975040</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.970772</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.973567</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.971485</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.974069</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.971086</td>\n",
       "      <td>0.976505</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.983553</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>0.981371</td>\n",
       "      <td>0.978818</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5294117647058824, 'recall': 0.5625, 'f1': 0.5454545454545455, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.7333333333333333, 'f1': 0.6984126984126984, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9712230215827338, 'recall': 0.9726224783861671, 'f1': 0.9719222462203023, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9699738903394256, 'recall': 0.9763469119579501, 'f1': 0.9731499672560576, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.138278</td>\n",
       "      <td>0.972390</td>\n",
       "      <td>0.979149</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.976787</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.977428</td>\n",
       "      <td>0.974104</td>\n",
       "      <td>0.979891</td>\n",
       "      <td>0.973475</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.976064</td>\n",
       "      <td>0.985477</td>\n",
       "      <td>0.971979</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.974967</td>\n",
       "      <td>0.982684</td>\n",
       "      <td>0.975565</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.978644</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}</td>\n",
       "      <td>{'precision': 0.625, 'recall': 0.625, 'f1': 0.625, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6875, 'recall': 0.7333333333333333, 'f1': 0.7096774193548386, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9726205997392438, 'recall': 0.9802890932982917, 'f1': 0.9764397905759162, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.144769</td>\n",
       "      <td>0.970124</td>\n",
       "      <td>0.977990</td>\n",
       "      <td>0.974041</td>\n",
       "      <td>0.973188</td>\n",
       "      <td>0.969239</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.972535</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>0.972074</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.973369</td>\n",
       "      <td>0.983863</td>\n",
       "      <td>0.970485</td>\n",
       "      <td>0.975330</td>\n",
       "      <td>0.972902</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>0.974815</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.977712</td>\n",
       "      <td>0.982622</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9611650485436893, 'recall': 0.9840954274353877, 'f1': 0.9724950884086444, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.375, 'f1': 0.4615384615384615, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6551724137931034, 'recall': 0.6333333333333333, 'f1': 0.6440677966101694, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9698275862068966, 'recall': 0.9726224783861671, 'f1': 0.9712230215827338, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9661898569570871, 'recall': 0.9763469119579501, 'f1': 0.9712418300653595, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.139896</td>\n",
       "      <td>0.971035</td>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.975793</td>\n",
       "      <td>0.969464</td>\n",
       "      <td>0.968229</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.972026</td>\n",
       "      <td>0.972691</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.976775</td>\n",
       "      <td>0.981877</td>\n",
       "      <td>0.970006</td>\n",
       "      <td>0.978267</td>\n",
       "      <td>0.974119</td>\n",
       "      <td>0.977284</td>\n",
       "      <td>0.976305</td>\n",
       "      <td>0.982489</td>\n",
       "      <td>0.979387</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9722772277227723, 'recall': 0.9761431411530815, 'f1': 0.9742063492063492, 'number': 503}</td>\n",
       "      <td>{'precision': 0.45, 'recall': 0.5625, 'f1': 0.5, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5675675675675675, 'recall': 0.7, 'f1': 0.626865671641791, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.160406</td>\n",
       "      <td>0.969332</td>\n",
       "      <td>0.979438</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.966609</td>\n",
       "      <td>0.968229</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.972026</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.970238</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.974104</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.969114</td>\n",
       "      <td>0.976799</td>\n",
       "      <td>0.972941</td>\n",
       "      <td>0.974615</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.982125</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9723865877712031, 'recall': 0.9801192842942346, 'f1': 0.9762376237623762, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5384615384615384, 'recall': 0.7, 'f1': 0.608695652173913, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9712643678160919, 'recall': 0.9740634005763689, 'f1': 0.9726618705035971, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9700520833333334, 'recall': 0.9789750328515112, 'f1': 0.9744931327665142, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.156030</td>\n",
       "      <td>0.971027</td>\n",
       "      <td>0.980307</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>0.971860</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.975418</td>\n",
       "      <td>0.974801</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.975448</td>\n",
       "      <td>0.981008</td>\n",
       "      <td>0.971454</td>\n",
       "      <td>0.979442</td>\n",
       "      <td>0.975431</td>\n",
       "      <td>0.977905</td>\n",
       "      <td>0.977037</td>\n",
       "      <td>0.982861</td>\n",
       "      <td>0.979941</td>\n",
       "      <td>0.984484</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9524714828897338, 'recall': 0.9653179190751445, 'f1': 0.9588516746411484, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9704142011834319, 'recall': 0.9781312127236581, 'f1': 0.9742574257425742, 'number': 503}</td>\n",
       "      <td>{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5945945945945946, 'recall': 0.7333333333333333, 'f1': 0.6567164179104478, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9688311688311688, 'recall': 0.9802890932982917, 'f1': 0.9745264532984976, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.158178</td>\n",
       "      <td>0.968499</td>\n",
       "      <td>0.979438</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.970581</td>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.977428</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.967062</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.972830</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.969432</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.977781</td>\n",
       "      <td>0.975583</td>\n",
       "      <td>0.982489</td>\n",
       "      <td>0.979024</td>\n",
       "      <td>0.983739</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9508506616257089, 'recall': 0.9691714836223507, 'f1': 0.9599236641221374, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9743589743589743, 'recall': 0.9821073558648111, 'f1': 0.9782178217821782, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4090909090909091, 'recall': 0.5625, 'f1': 0.47368421052631576, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6285714285714286, 'recall': 0.7333333333333333, 'f1': 0.6769230769230768, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9713055954088953, 'recall': 0.9755043227665706, 'f1': 0.9734004313443565, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.154625</td>\n",
       "      <td>0.970977</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.974758</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.971860</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.975418</td>\n",
       "      <td>0.979518</td>\n",
       "      <td>0.972149</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.974734</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>0.971987</td>\n",
       "      <td>0.978267</td>\n",
       "      <td>0.975117</td>\n",
       "      <td>0.981815</td>\n",
       "      <td>0.973743</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.977357</td>\n",
       "      <td>0.984732</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9580952380952381, 'recall': 0.9691714836223507, 'f1': 0.96360153256705, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9630350194552529, 'recall': 0.9840954274353877, 'f1': 0.9734513274336284, 'number': 503}</td>\n",
       "      <td>{'precision': 0.7272727272727273, 'recall': 0.5, 'f1': 0.5925925925925926, 'number': 16}</td>\n",
       "      <td>{'precision': 0.7, 'recall': 0.7, 'f1': 0.7, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}</td>\n",
       "      <td>{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.147133</td>\n",
       "      <td>0.973548</td>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.977060</td>\n",
       "      <td>0.976043</td>\n",
       "      <td>0.975444</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.977743</td>\n",
       "      <td>0.980139</td>\n",
       "      <td>0.974801</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.977394</td>\n",
       "      <td>0.984359</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.980029</td>\n",
       "      <td>0.977589</td>\n",
       "      <td>0.982249</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9619047619047619, 'recall': 0.9730250481695568, 'f1': 0.9674329501915709, 'number': 519}</td>\n",
       "      <td>{'precision': 0.970703125, 'recall': 0.9880715705765407, 'f1': 0.9793103448275862, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}</td>\n",
       "      <td>{'precision': 0.7777777777777778, 'recall': 0.7, 'f1': 0.7368421052631577, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.147555</td>\n",
       "      <td>0.969940</td>\n",
       "      <td>0.981176</td>\n",
       "      <td>0.975525</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>0.967324</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.973128</td>\n",
       "      <td>0.976787</td>\n",
       "      <td>0.970375</td>\n",
       "      <td>0.982667</td>\n",
       "      <td>0.976482</td>\n",
       "      <td>0.982249</td>\n",
       "      <td>0.968668</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.974606</td>\n",
       "      <td>0.979518</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.984724</td>\n",
       "      <td>0.981433</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5238095238095238, 'recall': 0.7333333333333333, 'f1': 0.611111111111111, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9778357235984355, 'recall': 0.985545335085414, 'f1': 0.9816753926701572, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.153371</td>\n",
       "      <td>0.973873</td>\n",
       "      <td>0.982334</td>\n",
       "      <td>0.978085</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>0.971414</td>\n",
       "      <td>0.981102</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.976760</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>0.978709</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>0.973761</td>\n",
       "      <td>0.980910</td>\n",
       "      <td>0.977323</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.979630</td>\n",
       "      <td>0.985469</td>\n",
       "      <td>0.982541</td>\n",
       "      <td>0.985849</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9601518026565465, 'recall': 0.9749518304431599, 'f1': 0.9674952198852773, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9669902912621359, 'recall': 0.9900596421471173, 'f1': 0.9783889980353634, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6176470588235294, 'recall': 0.7, 'f1': 0.65625, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.149974</td>\n",
       "      <td>0.972732</td>\n",
       "      <td>0.981465</td>\n",
       "      <td>0.977079</td>\n",
       "      <td>0.975794</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.973890</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.976760</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>0.978709</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>0.972311</td>\n",
       "      <td>0.979736</td>\n",
       "      <td>0.976009</td>\n",
       "      <td>0.982001</td>\n",
       "      <td>0.979244</td>\n",
       "      <td>0.984352</td>\n",
       "      <td>0.981791</td>\n",
       "      <td>0.985477</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9591439688715954, 'recall': 0.9801192842942346, 'f1': 0.9695181907571288, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.5, 'f1': 0.5333333333333333, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5833333333333334, 'recall': 0.7, 'f1': 0.6363636363636365, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9765013054830287, 'recall': 0.9829172141918529, 'f1': 0.9796987557301899, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.154111</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.979149</td>\n",
       "      <td>0.975476</td>\n",
       "      <td>0.975174</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.974145</td>\n",
       "      <td>0.978898</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.976698</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>0.971995</td>\n",
       "      <td>0.978561</td>\n",
       "      <td>0.975267</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>0.978132</td>\n",
       "      <td>0.983234</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9545454545454546, 'recall': 0.9710982658959537, 'f1': 0.9627507163323782, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9631067961165048, 'recall': 0.9860834990059643, 'f1': 0.9744597249508842, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}</td>\n",
       "      <td>{'precision': 0.6363636363636364, 'recall': 0.7, 'f1': 0.6666666666666666, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9713168187744459, 'recall': 0.9789750328515112, 'f1': 0.975130890052356, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.164676</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.973635</td>\n",
       "      <td>0.970581</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.977953</td>\n",
       "      <td>0.973100</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.969577</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.973440</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>0.968859</td>\n",
       "      <td>0.977680</td>\n",
       "      <td>0.973250</td>\n",
       "      <td>0.977470</td>\n",
       "      <td>0.978116</td>\n",
       "      <td>0.982489</td>\n",
       "      <td>0.980297</td>\n",
       "      <td>0.984359</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9667318982387475, 'recall': 0.9821073558648111, 'f1': 0.9743589743589743, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9741750358680057, 'recall': 0.978386167146974, 'f1': 0.9762760603882099, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.165014</td>\n",
       "      <td>0.971847</td>\n",
       "      <td>0.979728</td>\n",
       "      <td>0.975772</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>0.971339</td>\n",
       "      <td>0.978478</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.974677</td>\n",
       "      <td>0.971523</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.974751</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.971420</td>\n",
       "      <td>0.978267</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.977718</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.983234</td>\n",
       "      <td>0.980859</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9744094488188977, 'recall': 0.9840954274353877, 'f1': 0.9792284866468843, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5833333333333334, 'recall': 0.7, 'f1': 0.6363636363636365, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9741750358680057, 'recall': 0.978386167146974, 'f1': 0.9762760603882099, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.169158</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.980017</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>0.969836</td>\n",
       "      <td>0.969319</td>\n",
       "      <td>0.978478</td>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.975124</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.979148</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0.976539</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.980684</td>\n",
       "      <td>0.984484</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}</td>\n",
       "      <td>{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9739243807040417, 'recall': 0.9816031537450722, 'f1': 0.9777486910994765, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8992805755395683, 'recall': 0.9245562130177515, 'f1': 0.911743253099927, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8556149732620321, 'recall': 0.9248554913294798, 'f1': 0.888888888888889, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8556149732620321, 'recall': 0.9542743538767395, 'f1': 0.9022556390977442, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9098474341192788, 'recall': 0.9452449567723343, 'f1': 0.9272084805653711, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9420849420849421, 'recall': 0.961892247043364, 'f1': 0.9518855656697008, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945906432748538, 'recall': 0.9571005917159763, 'f1': 0.9514705882352941, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8678571428571429, 'recall': 0.9364161849710982, 'f1': 0.9008341056533826, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8678571428571429, 'recall': 0.9662027833001988, 'f1': 0.9143932267168391, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7368421052631579, 'recall': 0.42424242424242425, 'f1': 0.5384615384615385, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9207650273224044, 'recall': 0.9711815561959655, 'f1': 0.9453015427769985, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9093167701863354, 'recall': 0.961892247043364, 'f1': 0.9348659003831418, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882525697503671, 'recall': 0.9926253687315634, 'f1': 0.9904341427520236, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9678832116788321, 'recall': 0.9807692307692307, 'f1': 0.9742836149889786, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9224952741020794, 'recall': 0.9402697495183044, 'f1': 0.9312977099236641, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9224952741020794, 'recall': 0.9701789264413518, 'f1': 0.9457364341085271, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.23333333333333334, 'f1': 0.31111111111111117, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9545454545454546, 'recall': 0.968299711815562, 'f1': 0.9613733905579399, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9455252918287937, 'recall': 0.9579500657030223, 'f1': 0.9516971279373369, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9620991253644315, 'recall': 0.9763313609467456, 'f1': 0.9691629955947137, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8945454545454545, 'recall': 0.9479768786127167, 'f1': 0.9204864359214219, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8945454545454545, 'recall': 0.9781312127236581, 'f1': 0.9344729344729346, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.14285714285714285, 'recall': 0.23333333333333334, 'f1': 0.17721518987341772, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7837837837837838, 'recall': 0.8787878787878788, 'f1': 0.8285714285714285, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9325842696629213, 'recall': 0.9567723342939481, 'f1': 0.9445234708392602, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9532467532467532, 'recall': 0.9645203679369251, 'f1': 0.9588504245591117, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9679767103347889, 'recall': 0.9837278106508875, 'f1': 0.9757887013939839, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9186691312384473, 'recall': 0.9576107899807321, 'f1': 0.9377358490566037, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9186691312384473, 'recall': 0.9880715705765407, 'f1': 0.9521072796934865, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.2, 'f1': 0.3, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7435897435897436, 'recall': 0.8787878787878788, 'f1': 0.8055555555555556, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9350282485875706, 'recall': 0.9538904899135446, 'f1': 0.9443651925820257, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9404915912031048, 'recall': 0.9553219448094612, 'f1': 0.9478487614080835, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9180633147113594, 'recall': 0.9499036608863198, 'f1': 0.9337121212121212, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9180633147113594, 'recall': 0.9801192842942346, 'f1': 0.9480769230769232, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3, 'f1': 0.3157894736842105, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7894736842105263, 'recall': 0.9090909090909091, 'f1': 0.8450704225352113, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2, 'f1': 0.33333333333333337, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9570871261378413, 'recall': 0.9671484888304862, 'f1': 0.9620915032679739, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9217877094972067, 'recall': 0.953757225433526, 'f1': 0.9375, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9459459459459459, 'recall': 0.974155069582505, 'f1': 0.9598432908912832, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2631578947368421, 'recall': 0.3125, 'f1': 0.2857142857142857, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4666666666666667, 'f1': 0.3888888888888889, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2, 'f1': 0.28571428571428575, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9643874643874644, 'recall': 0.9755043227665706, 'f1': 0.969914040114613, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9432258064516129, 'recall': 0.9605781865965834, 'f1': 0.9518229166666666, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9202226345083488, 'recall': 0.9556840077071291, 'f1': 0.9376181474480151, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9533980582524272, 'recall': 0.9761431411530815, 'f1': 0.9646365422396858, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.20833333333333334, 'recall': 0.3125, 'f1': 0.25, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3111111111111111, 'recall': 0.4666666666666667, 'f1': 0.37333333333333335, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633986928104575, 'recall': 0.9684625492772667, 'f1': 0.9659239842726082, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9677891654465594, 'recall': 0.977810650887574, 'f1': 0.9727740986019133, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9257884972170687, 'recall': 0.9614643545279383, 'f1': 0.9432892249527409, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9479768786127167, 'recall': 0.9781312127236581, 'f1': 0.9628180039138944, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35, 'recall': 0.4375, 'f1': 0.38888888888888884, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.39473684210526316, 'recall': 0.5, 'f1': 0.4411764705882353, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.8, 'f1': 0.47058823529411764, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542203147353362, 'recall': 0.9610951008645533, 'f1': 0.9576453697056713, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544863459037711, 'recall': 0.9645203679369251, 'f1': 0.9594771241830065, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837997054491899, 'recall': 0.9881656804733728, 'f1': 0.9859778597785979, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9299242424242424, 'recall': 0.9460500963391136, 'f1': 0.9379178605539636, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9563492063492064, 'recall': 0.9582504970178927, 'f1': 0.9572989076464746, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.475, 'recall': 0.6333333333333333, 'f1': 0.5428571428571427, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8787878787878788, 'recall': 0.8787878787878788, 'f1': 0.8787878787878788, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9556509298998569, 'recall': 0.962536023054755, 'f1': 0.9590811198851399, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9597402597402598, 'recall': 0.9710906701708278, 'f1': 0.9653821032005226, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9307116104868914, 'recall': 0.9576107899807321, 'f1': 0.9439696106362773, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9645669291338582, 'recall': 0.974155069582505, 'f1': 0.9693372898120672, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2692307692307692, 'recall': 0.4375, 'f1': 0.33333333333333337, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.475, 'recall': 0.6333333333333333, 'f1': 0.5428571428571427, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.14285714285714285, 'recall': 0.4, 'f1': 0.21052631578947364, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9567723342939481, 'recall': 0.9567723342939481, 'f1': 0.9567723342939481, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9594771241830066, 'recall': 0.9645203679369251, 'f1': 0.9619921363040629, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896907216494846, 'recall': 0.9911504424778761, 'f1': 0.9904200442151806, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.928436911487759, 'recall': 0.9499036608863198, 'f1': 0.939047619047619, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9604743083003953, 'recall': 0.9662027833001988, 'f1': 0.9633300297324084, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.28, 'recall': 0.4375, 'f1': 0.34146341463414637, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3958333333333333, 'recall': 0.6333333333333333, 'f1': 0.4871794871794872, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9568627450980393, 'recall': 0.961892247043364, 'f1': 0.9593709043250329, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9896449704142012, 'f1': 0.9874538745387453, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9330855018587361, 'recall': 0.9672447013487476, 'f1': 0.9498580889309367, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9475920679886686, 'recall': 0.9639769452449568, 'f1': 0.9557142857142857, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9496774193548387, 'recall': 0.9671484888304862, 'f1': 0.9583333333333334, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.42857142857142855, 'f1': 0.375, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9283018867924528, 'recall': 0.9479768786127167, 'f1': 0.9380362249761677, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9662698412698413, 'recall': 0.9681908548707754, 'f1': 0.9672293942403178, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.19230769230769232, 'recall': 0.3125, 'f1': 0.2380952380952381, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.7, 'f1': 0.56, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9608865710560626, 'recall': 0.9684625492772667, 'f1': 0.9646596858638743, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823529411764705, 'recall': 0.9881656804733728, 'f1': 0.9852507374631269, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.953757225433526, 'f1': 0.9455587392550143, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9477756286266924, 'recall': 0.974155069582505, 'f1': 0.9607843137254902, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45454545454545453, 'recall': 0.3125, 'f1': 0.3703703703703703, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.358974358974359, 'recall': 0.4666666666666667, 'f1': 0.40579710144927544, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9509803921568627, 'recall': 0.978386167146974, 'f1': 0.9644886363636364, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9561290322580646, 'recall': 0.973718791064389, 'f1': 0.9648437500000001, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9465648854961832, 'recall': 0.9556840077071291, 'f1': 0.9511025886864813, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9665354330708661, 'recall': 0.9761431411530815, 'f1': 0.9713155291790306, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3125, 'recall': 0.3125, 'f1': 0.3125, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.425, 'recall': 0.5666666666666667, 'f1': 0.48571428571428565, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9700854700854701, 'recall': 0.9812680115273775, 'f1': 0.9756446991404012, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622886866059818, 'recall': 0.9724047306176085, 'f1': 0.9673202614379085, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.42857142857142855, 'f1': 0.3157894736842105, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.941398865784499, 'recall': 0.9595375722543352, 'f1': 0.950381679389313, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3888888888888889, 'recall': 0.4375, 'f1': 0.411764705882353, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5128205128205128, 'recall': 0.6666666666666666, 'f1': 0.5797101449275363, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9755747126436781, 'recall': 0.978386167146974, 'f1': 0.976978417266187, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685863874345549, 'recall': 0.9724047306176085, 'f1': 0.9704918032786886, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9264150943396227, 'recall': 0.9460500963391136, 'f1': 0.9361296472831266, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9508840864440079, 'recall': 0.9622266401590457, 'f1': 0.9565217391304347, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4375, 'f1': 0.37837837837837834, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9741379310344828, 'recall': 0.9769452449567724, 'f1': 0.9755395683453238, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686274509803922, 'recall': 0.973718791064389, 'f1': 0.9711664482306683, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779411764705882, 'recall': 0.9837278106508875, 'f1': 0.980825958702065, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9551656920077972, 'recall': 0.974155069582505, 'f1': 0.9645669291338583, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5128205128205128, 'recall': 0.6666666666666666, 'f1': 0.5797101449275363, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.97, 'recall': 0.978386167146974, 'f1': 0.9741750358680057, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686684073107049, 'recall': 0.9750328515111695, 'f1': 0.9718402095612311, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.985207100591716, 'recall': 0.985207100591716, 'f1': 0.985207100591716, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9607072691552063, 'recall': 0.9721669980119284, 'f1': 0.966403162055336, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5384615384615384, 'recall': 0.7, 'f1': 0.608695652173913, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9769784172661871, 'recall': 0.978386167146974, 'f1': 0.9776817854571634, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9687906371911573, 'recall': 0.9789750328515112, 'f1': 0.9738562091503269, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.5714285714285714, 'f1': 0.7272727272727273, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9395085066162571, 'recall': 0.9576107899807321, 'f1': 0.9484732824427481, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.976, 'recall': 0.9701789264413518, 'f1': 0.9730807577268196, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3103448275862069, 'recall': 0.5625, 'f1': 0.4, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4166666666666667, 'recall': 0.6666666666666666, 'f1': 0.5128205128205129, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.4, 'f1': 0.4444444444444445, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9568345323741008, 'recall': 0.9582132564841499, 'f1': 0.9575233981281498, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9711286089238845, 'recall': 0.9724047306176085, 'f1': 0.9717662508207485, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9701789264413518, 'recall': 0.9701789264413518, 'f1': 0.9701789264413518, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36, 'recall': 0.5625, 'f1': 0.43902439024390244, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9684813753581661, 'recall': 0.9740634005763689, 'f1': 0.9712643678160918, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.968503937007874, 'recall': 0.9697766097240473, 'f1': 0.96913985554826, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.974155069582505, 'recall': 0.974155069582505, 'f1': 0.974155069582505, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.7, 'f1': 0.5833333333333334, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9674902470741222, 'recall': 0.9776609724047306, 'f1': 0.9725490196078431, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837278106508875, 'recall': 0.9837278106508875, 'f1': 0.9837278106508875, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9644268774703557, 'recall': 0.9701789264413518, 'f1': 0.9672943508424182, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45454545454545453, 'recall': 0.625, 'f1': 0.5263157894736842, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5238095238095238, 'recall': 0.7333333333333333, 'f1': 0.611111111111111, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96987087517934, 'recall': 0.9740634005763689, 'f1': 0.9719626168224298, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9725130890052356, 'recall': 0.9763469119579501, 'f1': 0.9744262295081966, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9485714285714286, 'recall': 0.9595375722543352, 'f1': 0.9540229885057472, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9627450980392157, 'recall': 0.9761431411530815, 'f1': 0.9693978282329714, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.4375, 'f1': 0.45161290322580644, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.53125, 'recall': 0.5666666666666667, 'f1': 0.5483870967741935, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9756446991404012, 'recall': 0.9812680115273775, 'f1': 0.9784482758620688, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9660574412532638, 'recall': 0.9724047306176085, 'f1': 0.9692206941715783, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9486692015209125, 'recall': 0.9614643545279383, 'f1': 0.9550239234449761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9684418145956607, 'recall': 0.9761431411530815, 'f1': 0.9722772277227723, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.6666666666666666, 'f1': 0.6153846153846153, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.8, 'f1': 0.8000000000000002, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.962890625, 'recall': 0.9801192842942346, 'f1': 0.9714285714285714, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35, 'recall': 0.4375, 'f1': 0.38888888888888884, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5555555555555556, 'recall': 0.6666666666666666, 'f1': 0.606060606060606, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.8, 'f1': 0.888888888888889, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9756446991404012, 'recall': 0.9812680115273775, 'f1': 0.9784482758620688, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96875, 'recall': 0.9776609724047306, 'f1': 0.9731850882930019, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9420560747663551, 'recall': 0.9710982658959537, 'f1': 0.9563567362428842, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9576923076923077, 'recall': 0.9900596421471173, 'f1': 0.9736070381231671, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.375, 'f1': 0.38709677419354843, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5454545454545454, 'recall': 0.6, 'f1': 0.5714285714285713, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.4, 'f1': 0.3076923076923077, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9713055954088953, 'recall': 0.9755043227665706, 'f1': 0.9734004313443565, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9635890767230169, 'recall': 0.973718791064389, 'f1': 0.9686274509803922, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1': 0.6153846153846153, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9636711281070746, 'recall': 0.9710982658959537, 'f1': 0.9673704414587332, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9724950884086444, 'recall': 0.9840954274353877, 'f1': 0.9782608695652174, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6428571428571429, 'recall': 0.5625, 'f1': 0.6000000000000001, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.7333333333333333, 'f1': 0.6984126984126984, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9683908045977011, 'recall': 0.9711815561959655, 'f1': 0.9697841726618706, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9673629242819843, 'recall': 0.973718791064389, 'f1': 0.9705304518664047, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5294117647058824, 'recall': 0.5625, 'f1': 0.5454545454545455, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.7333333333333333, 'f1': 0.6984126984126984, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9712230215827338, 'recall': 0.9726224783861671, 'f1': 0.9719222462203023, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9699738903394256, 'recall': 0.9763469119579501, 'f1': 0.9731499672560576, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.625, 'f1': 0.625, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6875, 'recall': 0.7333333333333333, 'f1': 0.7096774193548386, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9726205997392438, 'recall': 0.9802890932982917, 'f1': 0.9764397905759162, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2900] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542857142857143, 'recall': 0.9653179190751445, 'f1': 0.9597701149425287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9611650485436893, 'recall': 0.9840954274353877, 'f1': 0.9724950884086444, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.375, 'f1': 0.4615384615384615, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6551724137931034, 'recall': 0.6333333333333333, 'f1': 0.6440677966101694, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9698275862068966, 'recall': 0.9726224783861671, 'f1': 0.9712230215827338, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661898569570871, 'recall': 0.9763469119579501, 'f1': 0.9712418300653595, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9523809523809523, 'recall': 0.9633911368015414, 'f1': 0.9578544061302681, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9722772277227723, 'recall': 0.9761431411530815, 'f1': 0.9742063492063492, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45, 'recall': 0.5625, 'f1': 0.5, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5675675675675675, 'recall': 0.7, 'f1': 0.626865671641791, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727403156384505, 'recall': 0.9769452449567724, 'f1': 0.9748382458662833, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3100] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9723865877712031, 'recall': 0.9801192842942346, 'f1': 0.9762376237623762, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5384615384615384, 'recall': 0.7, 'f1': 0.608695652173913, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9712643678160919, 'recall': 0.9740634005763689, 'f1': 0.9726618705035971, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9700520833333334, 'recall': 0.9789750328515112, 'f1': 0.9744931327665142, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9524714828897338, 'recall': 0.9653179190751445, 'f1': 0.9588516746411484, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9704142011834319, 'recall': 0.9781312127236581, 'f1': 0.9742574257425742, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5945945945945946, 'recall': 0.7333333333333333, 'f1': 0.6567164179104478, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9688311688311688, 'recall': 0.9802890932982917, 'f1': 0.9745264532984976, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9508506616257089, 'recall': 0.9691714836223507, 'f1': 0.9599236641221374, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9743589743589743, 'recall': 0.9821073558648111, 'f1': 0.9782178217821782, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4090909090909091, 'recall': 0.5625, 'f1': 0.47368421052631576, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6285714285714286, 'recall': 0.7333333333333333, 'f1': 0.6769230769230768, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9713055954088953, 'recall': 0.9755043227665706, 'f1': 0.9734004313443565, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9580952380952381, 'recall': 0.9691714836223507, 'f1': 0.96360153256705, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9630350194552529, 'recall': 0.9840954274353877, 'f1': 0.9734513274336284, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7272727272727273, 'recall': 0.5, 'f1': 0.5925925925925926, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7, 'recall': 0.7, 'f1': 0.7, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9662337662337662, 'recall': 0.9776609724047306, 'f1': 0.9719137818419333, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9619047619047619, 'recall': 0.9730250481695568, 'f1': 0.9674329501915709, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.970703125, 'recall': 0.9880715705765407, 'f1': 0.9793103448275862, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.7, 'f1': 0.7368421052631577, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.5625, 'f1': 0.45, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5238095238095238, 'recall': 0.7333333333333333, 'f1': 0.611111111111111, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778357235984355, 'recall': 0.985545335085414, 'f1': 0.9816753926701572, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601518026565465, 'recall': 0.9749518304431599, 'f1': 0.9674952198852773, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669902912621359, 'recall': 0.9900596421471173, 'f1': 0.9783889980353634, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6176470588235294, 'recall': 0.7, 'f1': 0.65625, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3800] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-3900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9488636363636364, 'recall': 0.9653179190751445, 'f1': 0.9570200573065903, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9591439688715954, 'recall': 0.9801192842942346, 'f1': 0.9695181907571288, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.5, 'f1': 0.5333333333333333, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5833333333333334, 'recall': 0.7, 'f1': 0.6363636363636365, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9765013054830287, 'recall': 0.9829172141918529, 'f1': 0.9796987557301899, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9545454545454546, 'recall': 0.9710982658959537, 'f1': 0.9627507163323782, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9631067961165048, 'recall': 0.9860834990059643, 'f1': 0.9744597249508842, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6363636363636364, 'recall': 0.7, 'f1': 0.6666666666666666, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9713168187744459, 'recall': 0.9789750328515112, 'f1': 0.975130890052356, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400749063670412, 'recall': 0.9672447013487476, 'f1': 0.9534662867996201, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9667318982387475, 'recall': 0.9821073558648111, 'f1': 0.9743589743589743, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.8, 'f1': 0.7272727272727272, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9741750358680057, 'recall': 0.978386167146974, 'f1': 0.9762760603882099, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544592030360531, 'recall': 0.9691714836223507, 'f1': 0.9617590822179732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9744094488188977, 'recall': 0.9840954274353877, 'f1': 0.9792284866468843, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5833333333333334, 'recall': 0.7, 'f1': 0.6363636363636365, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9741750358680057, 'recall': 0.978386167146974, 'f1': 0.9762760603882099, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9725490196078431, 'recall': 0.9776609724047306, 'f1': 0.9750982961992136, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9417293233082706, 'recall': 0.9653179190751445, 'f1': 0.9533777354900096, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5526315789473685, 'recall': 0.7, 'f1': 0.6176470588235295, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9770444763271162, 'recall': 0.9812680115273775, 'f1': 0.9791516894320633, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9739243807040417, 'recall': 0.9816031537450722, 'f1': 0.9777486910994765, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000 (score: 0.9780853517877739).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9728453364817001, 'recall': 0.9780415430267062, 'f1': 0.9754365196803788, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9140271493212669, 'recall': 0.923217550274223, 'f1': 0.9185993633469759, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9485436893203884, 'recall': 0.9476236663433559, 'f1': 0.9480834546336729, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.44, 'recall': 0.5238095238095238, 'f1': 0.4782608695652174, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4895833333333333, 'recall': 0.5949367088607594, 'f1': 0.537142857142857, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9767441860465116, 'recall': 0.9767441860465116, 'f1': 0.9767441860465116, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.72, 'recall': 0.5454545454545454, 'f1': 0.6206896551724138, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9772079772079773, 'recall': 0.9816828849456211, 'f1': 0.9794403198172473, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9683333333333334, 'recall': 0.9753777280358142, 'f1': 0.9718427655422359, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9994292237442922, 'recall': 1.0, 'f1': 0.9997145304025121, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6428571428571429, 'recall': 0.6428571428571429, 'f1': 0.6428571428571429, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601518026565465, 'recall': 0.9749518304431599, 'f1': 0.9674952198852773, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669902912621359, 'recall': 0.9900596421471173, 'f1': 0.9783889980353634, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6176470588235294, 'recall': 0.7, 'f1': 0.65625, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1': 0.9696969696969697, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5714285714285714, 'recall': 0.8, 'f1': 0.6666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975609756097561, 'recall': 0.9798270893371758, 'f1': 0.9777138749101366, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9739583333333334, 'recall': 0.9829172141918529, 'f1': 0.9784172661870504, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.5714285714285714, 'f1': 0.6666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-PER+O\",\n",
      "    \"2\": \"I-PER+i_TITREH\",\n",
      "    \"3\": \"I-ACT+O\",\n",
      "    \"4\": \"I-DESC+O\",\n",
      "    \"5\": \"I-DESC+i_ACT\",\n",
      "    \"6\": \"I-DESC+i_TITREP\",\n",
      "    \"7\": \"I-SPAT+O\",\n",
      "    \"8\": \"I-SPAT+i_LOC\",\n",
      "    \"9\": \"I-SPAT+i_CARDINAL\",\n",
      "    \"10\": \"I-SPAT+i_FT\",\n",
      "    \"11\": \"I-TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT+O\": 3,\n",
      "    \"I-DESC+O\": 4,\n",
      "    \"I-DESC+i_ACT\": 5,\n",
      "    \"I-DESC+i_TITREP\": 6,\n",
      "    \"I-PER+O\": 1,\n",
      "    \"I-PER+i_TITREH\": 2,\n",
      "    \"I-SPAT+O\": 7,\n",
      "    \"I-SPAT+i_CARDINAL\": 9,\n",
      "    \"I-SPAT+i_FT\": 10,\n",
      "    \"I-SPAT+i_LOC\": 8,\n",
      "    \"I-TITRE+O\": 11,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner/snapshots/9f8b2203b6a2daba1ad279ac2adb822518caa167/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([12, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([12]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110040588\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1700' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1700/5000 09:31 < 18:30, 2.97 it/s, Epoch 4/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332257</td>\n",
       "      <td>0.947262</td>\n",
       "      <td>0.946713</td>\n",
       "      <td>0.946987</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>0.938058</td>\n",
       "      <td>0.924948</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.959156</td>\n",
       "      <td>0.939333</td>\n",
       "      <td>0.949141</td>\n",
       "      <td>0.969836</td>\n",
       "      <td>0.932322</td>\n",
       "      <td>0.938620</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.956616</td>\n",
       "      <td>0.940959</td>\n",
       "      <td>0.950075</td>\n",
       "      <td>0.945495</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>{'precision': 0.9381443298969072, 'recall': 0.9423076923076923, 'f1': 0.9402214022140221, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8665480427046264, 'recall': 0.9383429672447013, 'f1': 0.9010175763182239, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8665480427046264, 'recall': 0.9681908548707754, 'f1': 0.9145539906103287, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9233983286908078, 'recall': 0.9553314121037464, 'f1': 0.9390934844192635, 'number': 694}</td>\n",
       "      <td>{'precision': 0.935031847133758, 'recall': 0.9645203679369251, 'f1': 0.9495472186287194, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9868421052631579, 'recall': 0.995575221238938, 'f1': 0.9911894273127753, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.936043</td>\n",
       "      <td>0.953663</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.948486</td>\n",
       "      <td>0.915323</td>\n",
       "      <td>0.953281</td>\n",
       "      <td>0.933916</td>\n",
       "      <td>0.954071</td>\n",
       "      <td>0.945406</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.946036</td>\n",
       "      <td>0.971326</td>\n",
       "      <td>0.928285</td>\n",
       "      <td>0.950367</td>\n",
       "      <td>0.939196</td>\n",
       "      <td>0.962699</td>\n",
       "      <td>0.935307</td>\n",
       "      <td>0.953428</td>\n",
       "      <td>0.944280</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>{'precision': 0.9489795918367347, 'recall': 0.9630177514792899, 'f1': 0.9559471365638766, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9402697495183044, 'f1': 0.9138576779026217, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9701789264413518, 'f1': 0.9277566539923954, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.26666666666666666, 'f1': 0.2758620689655172, 'number': 30}</td>\n",
       "      <td>{'precision': 0.6296296296296297, 'recall': 0.5151515151515151, 'f1': 0.5666666666666667, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9278779472954231, 'recall': 0.9639769452449568, 'f1': 0.9455830388692581, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9208542713567839, 'recall': 0.9632063074901446, 'f1': 0.9415542710340399, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202282</td>\n",
       "      <td>0.959526</td>\n",
       "      <td>0.961193</td>\n",
       "      <td>0.960359</td>\n",
       "      <td>0.957795</td>\n",
       "      <td>0.941843</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.951143</td>\n",
       "      <td>0.961643</td>\n",
       "      <td>0.960403</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.957191</td>\n",
       "      <td>0.972815</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.957709</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.967229</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.964978</td>\n",
       "      <td>0.962289</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9265536723163842, 'recall': 0.9479768786127167, 'f1': 0.9371428571428572, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.26666666666666666, 'f1': 0.2962962962962963, 'number': 30}</td>\n",
       "      <td>{'precision': 0.875, 'recall': 0.8484848484848485, 'f1': 0.8615384615384615, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9381153305203939, 'recall': 0.9610951008645533, 'f1': 0.9494661921708185, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9406451612903226, 'recall': 0.9579500657030223, 'f1': 0.9492187500000001, 'number': 761}</td>\n",
       "      <td>{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168566</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.960035</td>\n",
       "      <td>0.955607</td>\n",
       "      <td>0.950596</td>\n",
       "      <td>0.939846</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.949610</td>\n",
       "      <td>0.955809</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.959545</td>\n",
       "      <td>0.976043</td>\n",
       "      <td>0.949651</td>\n",
       "      <td>0.958297</td>\n",
       "      <td>0.953954</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.966095</td>\n",
       "      <td>0.963761</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>{'precision': 0.9579100145137881, 'recall': 0.9763313609467456, 'f1': 0.967032967032967, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9258555133079848, 'recall': 0.9383429672447013, 'f1': 0.9320574162679425, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9383429672447013, 'recall': 0.9681908548707754, 'f1': 0.9530332681017614, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.17647058823529413, 'recall': 0.2, 'f1': 0.18750000000000003, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9601706970128022, 'recall': 0.9726224783861671, 'f1': 0.9663564781675018, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9503916449086162, 'recall': 0.9566360052562418, 'f1': 0.9535036018336608, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.955237</td>\n",
       "      <td>0.964089</td>\n",
       "      <td>0.959643</td>\n",
       "      <td>0.952085</td>\n",
       "      <td>0.942960</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.952999</td>\n",
       "      <td>0.956927</td>\n",
       "      <td>0.948481</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.952887</td>\n",
       "      <td>0.964002</td>\n",
       "      <td>0.945376</td>\n",
       "      <td>0.960646</td>\n",
       "      <td>0.952950</td>\n",
       "      <td>0.960464</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.965723</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.971450</td>\n",
       "      <td>{'precision': 0.9707602339181286, 'recall': 0.9822485207100592, 'f1': 0.9764705882352941, 'number': 676}</td>\n",
       "      <td>{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9513618677042801, 'recall': 0.9721669980119284, 'f1': 0.9616519174041297, 'number': 503}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.1875, 'f1': 0.17647058823529413, 'number': 16}</td>\n",
       "      <td>{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7878787878787878, 'recall': 0.7878787878787878, 'f1': 0.7878787878787878, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9422535211267605, 'recall': 0.9639769452449568, 'f1': 0.9529914529914529, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9360613810741688, 'recall': 0.961892247043364, 'f1': 0.9488010369410239, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.155111</td>\n",
       "      <td>0.959759</td>\n",
       "      <td>0.966985</td>\n",
       "      <td>0.963358</td>\n",
       "      <td>0.951837</td>\n",
       "      <td>0.943532</td>\n",
       "      <td>0.964829</td>\n",
       "      <td>0.954062</td>\n",
       "      <td>0.955189</td>\n",
       "      <td>0.965287</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.964643</td>\n",
       "      <td>0.970829</td>\n",
       "      <td>0.952989</td>\n",
       "      <td>0.964464</td>\n",
       "      <td>0.958692</td>\n",
       "      <td>0.963009</td>\n",
       "      <td>0.963744</td>\n",
       "      <td>0.970566</td>\n",
       "      <td>0.967143</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>{'precision': 0.9750367107195301, 'recall': 0.9822485207100592, 'f1': 0.978629329403095, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9143389199255121, 'recall': 0.9460500963391136, 'f1': 0.9299242424242424, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9278937381404174, 'recall': 0.9721669980119284, 'f1': 0.949514563106796, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.125, 'f1': 0.15384615384615385, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3055555555555556, 'recall': 0.36666666666666664, 'f1': 0.3333333333333333, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9573863636363636, 'recall': 0.9711815561959655, 'f1': 0.9642346208869814, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.145521</td>\n",
       "      <td>0.948791</td>\n",
       "      <td>0.965827</td>\n",
       "      <td>0.957233</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.936605</td>\n",
       "      <td>0.961680</td>\n",
       "      <td>0.948977</td>\n",
       "      <td>0.960650</td>\n",
       "      <td>0.954335</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.973188</td>\n",
       "      <td>0.944332</td>\n",
       "      <td>0.961527</td>\n",
       "      <td>0.952852</td>\n",
       "      <td>0.966919</td>\n",
       "      <td>0.964047</td>\n",
       "      <td>0.969076</td>\n",
       "      <td>0.966555</td>\n",
       "      <td>0.971450</td>\n",
       "      <td>{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9025735294117647, 'recall': 0.9460500963391136, 'f1': 0.9238005644402634, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9383429672447013, 'recall': 0.9681908548707754, 'f1': 0.9530332681017614, 'number': 503}</td>\n",
       "      <td>{'precision': 0.16, 'recall': 0.25, 'f1': 0.19512195121951217, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2542372881355932, 'recall': 0.5, 'f1': 0.33707865168539325, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9514285714285714, 'recall': 0.9596541786743515, 'f1': 0.9555236728837877, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9481193255512321, 'recall': 0.9605781865965834, 'f1': 0.954308093994778, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.142744</td>\n",
       "      <td>0.962611</td>\n",
       "      <td>0.969302</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.956306</td>\n",
       "      <td>0.958506</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.964258</td>\n",
       "      <td>0.961768</td>\n",
       "      <td>0.959603</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.962791</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.958988</td>\n",
       "      <td>0.968282</td>\n",
       "      <td>0.963612</td>\n",
       "      <td>0.966671</td>\n",
       "      <td>0.971004</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>0.972088</td>\n",
       "      <td>0.978401</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9780439121756487, 'recall': 0.974155069582505, 'f1': 0.9760956175298805, 'number': 503}</td>\n",
       "      <td>{'precision': 0.25925925925925924, 'recall': 0.4375, 'f1': 0.3255813953488372, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9645669291338582, 'recall': 0.9658344283837057, 'f1': 0.9652002626395274, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.137683</td>\n",
       "      <td>0.959668</td>\n",
       "      <td>0.971619</td>\n",
       "      <td>0.965607</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.965859</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.950131</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.969836</td>\n",
       "      <td>0.955150</td>\n",
       "      <td>0.969457</td>\n",
       "      <td>0.962250</td>\n",
       "      <td>0.967602</td>\n",
       "      <td>0.967468</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.978277</td>\n",
       "      <td>{'precision': 0.9911373707533235, 'recall': 0.992603550295858, 'f1': 0.9918699186991871, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9645669291338582, 'recall': 0.974155069582505, 'f1': 0.9693372898120672, 'number': 503}</td>\n",
       "      <td>{'precision': 0.32, 'recall': 0.5, 'f1': 0.39024390243902435, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.6666666666666666, 'f1': 0.5333333333333333, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.4, 'f1': 0.26666666666666666, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9572649572649573, 'recall': 0.968299711815562, 'f1': 0.9627507163323783, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9456662354463131, 'recall': 0.9605781865965834, 'f1': 0.953063885267275, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.148119</td>\n",
       "      <td>0.962410</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>0.966849</td>\n",
       "      <td>0.953327</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.963446</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>0.961082</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.966180</td>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.959605</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.964651</td>\n",
       "      <td>0.964188</td>\n",
       "      <td>0.971025</td>\n",
       "      <td>0.973920</td>\n",
       "      <td>0.972470</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9281663516068053, 'recall': 0.9460500963391136, 'f1': 0.9370229007633587, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9679358717434869, 'recall': 0.9602385685884692, 'f1': 0.9640718562874252, 'number': 503}</td>\n",
       "      <td>{'precision': 0.26666666666666666, 'recall': 0.5, 'f1': 0.3478260869565218, 'number': 16}</td>\n",
       "      <td>{'precision': 0.40816326530612246, 'recall': 0.6666666666666666, 'f1': 0.5063291139240507, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.131784</td>\n",
       "      <td>0.959749</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.966647</td>\n",
       "      <td>0.961768</td>\n",
       "      <td>0.960499</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.965265</td>\n",
       "      <td>0.966485</td>\n",
       "      <td>0.959157</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.964877</td>\n",
       "      <td>0.977284</td>\n",
       "      <td>0.959907</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.965094</td>\n",
       "      <td>0.971884</td>\n",
       "      <td>0.968946</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.972722</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647058823529412, 'recall': 0.9781312127236581, 'f1': 0.9713721618953604, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4090909090909091, 'recall': 0.6, 'f1': 0.4864864864864865, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.8, 'f1': 0.5333333333333333, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9668109668109668, 'recall': 0.9654178674351584, 'f1': 0.966113914924297, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9561290322580646, 'recall': 0.973718791064389, 'f1': 0.9648437500000001, 'number': 761}</td>\n",
       "      <td>{'precision': 0.992603550295858, 'recall': 0.9896755162241888, 'f1': 0.9911373707533235, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.130723</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.968439</td>\n",
       "      <td>0.960278</td>\n",
       "      <td>0.958854</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.962614</td>\n",
       "      <td>0.965119</td>\n",
       "      <td>0.964238</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.961224</td>\n",
       "      <td>0.968282</td>\n",
       "      <td>0.964740</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>0.972873</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.974140</td>\n",
       "      <td>0.979394</td>\n",
       "      <td>{'precision': 0.9837758112094396, 'recall': 0.9866863905325444, 'f1': 0.9852289512555391, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9702380952380952, 'recall': 0.9721669980119284, 'f1': 0.971201588877855, 'number': 503}</td>\n",
       "      <td>{'precision': 0.37037037037037035, 'recall': 0.625, 'f1': 0.4651162790697674, 'number': 16}</td>\n",
       "      <td>{'precision': 0.43478260869565216, 'recall': 0.6666666666666666, 'f1': 0.5263157894736841, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.4, 'f1': 0.4444444444444445, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9609826589595376, 'recall': 0.9582132564841499, 'f1': 0.9595959595959597, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9926253687315634, 'recall': 0.9926253687315634, 'f1': 0.9926253687315634, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.148726</td>\n",
       "      <td>0.966734</td>\n",
       "      <td>0.967854</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>0.967602</td>\n",
       "      <td>0.955463</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.961940</td>\n",
       "      <td>0.971698</td>\n",
       "      <td>0.967850</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.965586</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>0.960864</td>\n",
       "      <td>0.966226</td>\n",
       "      <td>0.963538</td>\n",
       "      <td>0.977098</td>\n",
       "      <td>0.965556</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.968425</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9328358208955224, 'recall': 0.9633911368015414, 'f1': 0.9478672985781991, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9391634980988594, 'recall': 0.9821073558648111, 'f1': 0.9601554907677357, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.375, 'f1': 0.4615384615384615, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5862068965517241, 'recall': 0.5666666666666667, 'f1': 0.576271186440678, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9598278335724534, 'recall': 0.9639769452449568, 'f1': 0.9618979151689433, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9592641261498029, 'recall': 0.9592641261498029, 'f1': 0.9592641261498029, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.968160</td>\n",
       "      <td>0.959409</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.964220</td>\n",
       "      <td>0.963381</td>\n",
       "      <td>0.961716</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.966501</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.960454</td>\n",
       "      <td>0.970044</td>\n",
       "      <td>0.965225</td>\n",
       "      <td>0.968595</td>\n",
       "      <td>0.973655</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.975646</td>\n",
       "      <td>0.979022</td>\n",
       "      <td>{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9271028037383178, 'recall': 0.9556840077071291, 'f1': 0.9411764705882353, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9644268774703557, 'recall': 0.9701789264413518, 'f1': 0.9672943508424182, 'number': 503}</td>\n",
       "      <td>{'precision': 0.27586206896551724, 'recall': 0.5, 'f1': 0.35555555555555557, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.145237</td>\n",
       "      <td>0.962134</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>0.966710</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>0.956004</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.962731</td>\n",
       "      <td>0.966112</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.964581</td>\n",
       "      <td>0.975794</td>\n",
       "      <td>0.956849</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.963546</td>\n",
       "      <td>0.970953</td>\n",
       "      <td>0.963469</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>0.968113</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9212007504690432, 'recall': 0.9460500963391136, 'f1': 0.9334600760456274, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9378640776699029, 'recall': 0.9602385685884692, 'f1': 0.9489194499017682, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.5, 'f1': 0.47058823529411764, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5806451612903226, 'recall': 0.6, 'f1': 0.5901639344262295, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9549295774647887, 'recall': 0.9769452449567724, 'f1': 0.9658119658119657, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9523809523809523, 'recall': 0.9724047306176085, 'f1': 0.9622886866059818, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.142302</td>\n",
       "      <td>0.957441</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.962637</td>\n",
       "      <td>0.949126</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>0.969215</td>\n",
       "      <td>0.957209</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.963233</td>\n",
       "      <td>0.978774</td>\n",
       "      <td>0.952670</td>\n",
       "      <td>0.969457</td>\n",
       "      <td>0.960990</td>\n",
       "      <td>0.973995</td>\n",
       "      <td>0.965989</td>\n",
       "      <td>0.973547</td>\n",
       "      <td>0.969753</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.922077922077922, 'recall': 0.9576107899807321, 'f1': 0.9395085066162571, 'number': 519}</td>\n",
       "      <td>{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}</td>\n",
       "      <td>{'precision': 0.29411764705882354, 'recall': 0.5, 'f1': 0.37037037037037035, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.18181818181818182, 'recall': 0.4, 'f1': 0.25000000000000006, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.157458</td>\n",
       "      <td>0.958607</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>0.965497</td>\n",
       "      <td>0.957051</td>\n",
       "      <td>0.950439</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.958355</td>\n",
       "      <td>0.960775</td>\n",
       "      <td>0.960448</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.965860</td>\n",
       "      <td>0.973312</td>\n",
       "      <td>0.954835</td>\n",
       "      <td>0.968576</td>\n",
       "      <td>0.961656</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.967825</td>\n",
       "      <td>0.975037</td>\n",
       "      <td>0.971418</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>{'precision': 0.9765739385065886, 'recall': 0.9866863905325444, 'f1': 0.9816041206769685, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9230769230769231, 'recall': 0.9479768786127167, 'f1': 0.935361216730038, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9528487229862476, 'recall': 0.9642147117296223, 'f1': 0.958498023715415, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2916666666666667, 'recall': 0.4375, 'f1': 0.35000000000000003, 'number': 16}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}</td>\n",
       "      <td>{'precision': 0.9626972740315638, 'recall': 0.9668587896253602, 'f1': 0.9647735442127965, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}</td>\n",
       "      <td>{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9381443298969072, 'recall': 0.9423076923076923, 'f1': 0.9402214022140221, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8665480427046264, 'recall': 0.9383429672447013, 'f1': 0.9010175763182239, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8665480427046264, 'recall': 0.9681908548707754, 'f1': 0.9145539906103287, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9233983286908078, 'recall': 0.9553314121037464, 'f1': 0.9390934844192635, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935031847133758, 'recall': 0.9645203679369251, 'f1': 0.9495472186287194, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9868421052631579, 'recall': 0.995575221238938, 'f1': 0.9911894273127753, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9489795918367347, 'recall': 0.9630177514792899, 'f1': 0.9559471365638766, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9402697495183044, 'f1': 0.9138576779026217, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9701789264413518, 'f1': 0.9277566539923954, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.26666666666666666, 'f1': 0.2758620689655172, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6296296296296297, 'recall': 0.5151515151515151, 'f1': 0.5666666666666667, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9278779472954231, 'recall': 0.9639769452449568, 'f1': 0.9455830388692581, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9208542713567839, 'recall': 0.9632063074901446, 'f1': 0.9415542710340399, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9265536723163842, 'recall': 0.9479768786127167, 'f1': 0.9371428571428572, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.26666666666666666, 'f1': 0.2962962962962963, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.8484848484848485, 'f1': 0.8615384615384615, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9381153305203939, 'recall': 0.9610951008645533, 'f1': 0.9494661921708185, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9406451612903226, 'recall': 0.9579500657030223, 'f1': 0.9492187500000001, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986822840409956, 'recall': 0.9941002949852508, 'f1': 0.9904481998530492, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-100] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9579100145137881, 'recall': 0.9763313609467456, 'f1': 0.967032967032967, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9258555133079848, 'recall': 0.9383429672447013, 'f1': 0.9320574162679425, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9383429672447013, 'recall': 0.9681908548707754, 'f1': 0.9530332681017614, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.17647058823529413, 'recall': 0.2, 'f1': 0.18750000000000003, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601706970128022, 'recall': 0.9726224783861671, 'f1': 0.9663564781675018, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9503916449086162, 'recall': 0.9566360052562418, 'f1': 0.9535036018336608, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897360703812317, 'recall': 0.995575221238938, 'f1': 0.9926470588235294, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9707602339181286, 'recall': 0.9822485207100592, 'f1': 0.9764705882352941, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9513618677042801, 'recall': 0.9721669980119284, 'f1': 0.9616519174041297, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.1875, 'f1': 0.17647058823529413, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7878787878787878, 'recall': 0.7878787878787878, 'f1': 0.7878787878787878, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9422535211267605, 'recall': 0.9639769452449568, 'f1': 0.9529914529914529, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9360613810741688, 'recall': 0.961892247043364, 'f1': 0.9488010369410239, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750367107195301, 'recall': 0.9822485207100592, 'f1': 0.978629329403095, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9143389199255121, 'recall': 0.9460500963391136, 'f1': 0.9299242424242424, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9278937381404174, 'recall': 0.9721669980119284, 'f1': 0.949514563106796, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.125, 'f1': 0.15384615384615385, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3055555555555556, 'recall': 0.36666666666666664, 'f1': 0.3333333333333333, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8378378378378378, 'recall': 0.9393939393939394, 'f1': 0.8857142857142858, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9573863636363636, 'recall': 0.9711815561959655, 'f1': 0.9642346208869814, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9584415584415584, 'recall': 0.9697766097240473, 'f1': 0.9640757674722404, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9025735294117647, 'recall': 0.9460500963391136, 'f1': 0.9238005644402634, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9383429672447013, 'recall': 0.9681908548707754, 'f1': 0.9530332681017614, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16, 'recall': 0.25, 'f1': 0.19512195121951217, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.2542372881355932, 'recall': 0.5, 'f1': 0.33707865168539325, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9514285714285714, 'recall': 0.9596541786743515, 'f1': 0.9555236728837877, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9481193255512321, 'recall': 0.9605781865965834, 'f1': 0.954308093994778, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926470588235294, 'recall': 0.995575221238938, 'f1': 0.9941089837997055, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9412878787878788, 'recall': 0.9576107899807321, 'f1': 0.9493791786055396, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780439121756487, 'recall': 0.974155069582505, 'f1': 0.9760956175298805, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25925925925925924, 'recall': 0.4375, 'f1': 0.3255813953488372, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.4, 'f1': 0.3636363636363636, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9645669291338582, 'recall': 0.9658344283837057, 'f1': 0.9652002626395274, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926362297496318, 'recall': 0.9941002949852508, 'f1': 0.9933677229182019, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911373707533235, 'recall': 0.992603550295858, 'f1': 0.9918699186991871, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9645669291338582, 'recall': 0.974155069582505, 'f1': 0.9693372898120672, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.32, 'recall': 0.5, 'f1': 0.39024390243902435, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.6666666666666666, 'f1': 0.5333333333333333, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9142857142857143, 'recall': 0.9696969696969697, 'f1': 0.9411764705882354, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.4, 'f1': 0.26666666666666666, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9572649572649573, 'recall': 0.968299711815562, 'f1': 0.9627507163323783, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456662354463131, 'recall': 0.9605781865965834, 'f1': 0.953063885267275, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852507374631269, 'recall': 0.9881656804733728, 'f1': 0.9867060561299853, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9281663516068053, 'recall': 0.9460500963391136, 'f1': 0.9370229007633587, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9679358717434869, 'recall': 0.9602385685884692, 'f1': 0.9640718562874252, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.26666666666666666, 'recall': 0.5, 'f1': 0.3478260869565218, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.40816326530612246, 'recall': 0.6666666666666666, 'f1': 0.5063291139240507, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.4, 'f1': 0.4000000000000001, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9698558322411533, 'recall': 0.9724047306176085, 'f1': 0.9711286089238845, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-800] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647058823529412, 'recall': 0.9781312127236581, 'f1': 0.9713721618953604, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.4090909090909091, 'recall': 0.6, 'f1': 0.4864864864864865, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.8, 'f1': 0.5333333333333333, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9668109668109668, 'recall': 0.9654178674351584, 'f1': 0.966113914924297, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9561290322580646, 'recall': 0.973718791064389, 'f1': 0.9648437500000001, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.992603550295858, 'recall': 0.9896755162241888, 'f1': 0.9911373707533235, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837758112094396, 'recall': 0.9866863905325444, 'f1': 0.9852289512555391, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9702380952380952, 'recall': 0.9721669980119284, 'f1': 0.971201588877855, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37037037037037035, 'recall': 0.625, 'f1': 0.4651162790697674, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.43478260869565216, 'recall': 0.6666666666666666, 'f1': 0.5263157894736841, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.4, 'f1': 0.4444444444444445, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609826589595376, 'recall': 0.9582132564841499, 'f1': 0.9595959595959597, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926253687315634, 'recall': 0.9926253687315634, 'f1': 0.9926253687315634, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9328358208955224, 'recall': 0.9633911368015414, 'f1': 0.9478672985781991, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9391634980988594, 'recall': 0.9821073558648111, 'f1': 0.9601554907677357, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.375, 'f1': 0.4615384615384615, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5862068965517241, 'recall': 0.5666666666666667, 'f1': 0.576271186440678, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9598278335724534, 'recall': 0.9639769452449568, 'f1': 0.9618979151689433, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9592641261498029, 'recall': 0.9592641261498029, 'f1': 0.9592641261498029, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911634756995582, 'recall': 0.9926253687315634, 'f1': 0.9918938835666913, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.2857142857142857, 'f1': 0.4444444444444445, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867060561299852, 'recall': 0.9881656804733728, 'f1': 0.9874353288987435, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9271028037383178, 'recall': 0.9556840077071291, 'f1': 0.9411764705882353, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9644268774703557, 'recall': 0.9701789264413518, 'f1': 0.9672943508424182, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.27586206896551724, 'recall': 0.5, 'f1': 0.35555555555555557, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.6, 'f1': 0.6, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9627507163323782, 'recall': 0.968299711815562, 'f1': 0.9655172413793104, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9659239842726082, 'recall': 0.9684625492772667, 'f1': 0.9671916010498688, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911894273127754, 'recall': 0.995575221238938, 'f1': 0.9933774834437086, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881656804733728, 'recall': 0.9881656804733728, 'f1': 0.9881656804733728, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9212007504690432, 'recall': 0.9460500963391136, 'f1': 0.9334600760456274, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9378640776699029, 'recall': 0.9602385685884692, 'f1': 0.9489194499017682, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.5, 'f1': 0.47058823529411764, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5806451612903226, 'recall': 0.6, 'f1': 0.5901639344262295, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9549295774647887, 'recall': 0.9769452449567724, 'f1': 0.9658119658119657, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9523809523809523, 'recall': 0.9724047306176085, 'f1': 0.9622886866059818, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897209985315712, 'recall': 0.9941002949852508, 'f1': 0.9919058130978661, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.922077922077922, 'recall': 0.9576107899807321, 'f1': 0.9395085066162571, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38095238095238093, 'recall': 0.5, 'f1': 0.4324324324324324, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.29411764705882354, 'recall': 0.5, 'f1': 0.37037037037037035, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18181818181818182, 'recall': 0.4, 'f1': 0.25000000000000006, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9697766097240473, 'f1': 0.9653368214519294, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9897058823529412, 'recall': 0.9926253687315634, 'f1': 0.9911634756995582, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9765739385065886, 'recall': 0.9866863905325444, 'f1': 0.9816041206769685, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9230769230769231, 'recall': 0.9479768786127167, 'f1': 0.935361216730038, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9528487229862476, 'recall': 0.9642147117296223, 'f1': 0.958498023715415, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2916666666666667, 'recall': 0.4375, 'f1': 0.35000000000000003, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9626972740315638, 'recall': 0.9668587896253602, 'f1': 0.9647735442127965, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661016949152542, 'recall': 0.973718791064389, 'f1': 0.9698952879581151, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9911764705882353, 'recall': 0.9941002949852508, 'f1': 0.9926362297496317, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1600] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1200 (score: 0.9684392563769997).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-1700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9786729857819905, 'recall': 0.9804154302670623, 'f1': 0.9795434331455677, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8995555555555556, 'recall': 0.9250457038391224, 'f1': 0.9121225777377197, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9691848906560636, 'recall': 0.9456838021338506, 'f1': 0.9572901325478645, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.31092436974789917, 'recall': 0.5873015873015873, 'f1': 0.4065934065934066, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4566929133858268, 'recall': 0.7341772151898734, 'f1': 0.5631067961165048, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9772727272727273, 'recall': 1.0, 'f1': 0.9885057471264368, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6875, 'recall': 0.3333333333333333, 'f1': 0.4489795918367347, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.969054441260745, 'recall': 0.9679450486548369, 'f1': 0.9684994272623139, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9715719063545151, 'recall': 0.9753777280358142, 'f1': 0.9734710974588104, 'number': 1787}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9982857142857143, 'recall': 0.9977155910908052, 'f1': 0.9980005712653528, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.2857142857142857, 'f1': 0.4210526315789473, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837758112094396, 'recall': 0.9866863905325444, 'f1': 0.9852289512555391, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9702380952380952, 'recall': 0.9721669980119284, 'f1': 0.971201588877855, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37037037037037035, 'recall': 0.625, 'f1': 0.4651162790697674, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.43478260869565216, 'recall': 0.6666666666666666, 'f1': 0.5263157894736841, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8611111111111112, 'recall': 0.9393939393939394, 'f1': 0.8985507246376813, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.4, 'f1': 0.4444444444444445, 'number': 5}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609826589595376, 'recall': 0.9582132564841499, 'f1': 0.9595959595959597, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9672774869109948, 'recall': 0.9710906701708278, 'f1': 0.9691803278688523, 'number': 761}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9926253687315634, 'recall': 0.9926253687315634, 'f1': 0.9926253687315634, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:13:27.984950\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from hierarchicalNER.util_IO import _convert_tokenizer\n",
    "\n",
    "if RUN_CAMEMBERT_IO:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IO labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29431951",
   "metadata": {},
   "source": [
    "Best model : /work/stual/res_ICDAR/method_3/tmp/311-camembert-ner-hierarchical-loss-io/checkpoint-2200 (score: 0.9761595145210229)\n",
    "Run time : 14:34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46aea",
   "metadata": {},
   "source": [
    "## 312 - Train & eval : IOB2 Ref dataset with CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a8e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"camembert_ner\"\n",
    "MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "LABEL = \"iob2\"\n",
    "FOLDER = \"312-camembert-ner-hierarchical-loss-iob2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17156e4a",
   "metadata": {},
   "source": [
    "### 312.1 Load IOB2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "120918dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_1_prepared_dataset_ref_iob2_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-310-experiment_1_metrics'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_1_prepared_dataset_ref_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-310-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f86ae2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens               labels\n",
      "0  Duffau-Pauillac            I-b_PER+O\n",
      "1                (            I-i_PER+O\n",
      "2              Chs            I-i_PER+O\n",
      "3                )            I-i_PER+O\n",
      "4                ,                  O+O\n",
      "5          Enghien       I-b_SPAT+b_LOC\n",
      "6                ,           I-i_SPAT+O\n",
      "7               16  I-i_SPAT+b_CARDINAL\n",
      "8                .                  O+O\n",
      "9                *                  O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa6008",
   "metadata": {},
   "source": [
    "### 312.2 Fine-tuning with IOB2 labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5465fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree positions of all the leaves{'O+O': (0, 0, 0), 'I-b_PER+O': (1, 0, 0), 'I-i_PER+O': (1, 0, 1), 'I-b_PER+b_TITREH': (1, 1, 0), 'I-i_PER+b_TITREH': (1, 1, 1), 'I-i_PER+i_TITREH': (1, 1, 2), 'I-b_ACT+O': (2, 0, 0), 'I-i_ACT+O': (2, 0, 1), 'I-b_DESC+O': (3, 0, 0), 'I-i_DESC+O': (3, 0, 1), 'I-b_DESC+b_ACT': (3, 1, 0), 'I-i_DESC+b_ACT': (3, 1, 1), 'I-i_DESC+i_ACT': (3, 1, 2), 'I-b_DESC+b_TITREP': (3, 2, 0), 'I-i_DESC+b_TITREP': (3, 2, 1), 'I-i_DESC+i_TITREP': (3, 2, 2), 'I-b_SPAT+O': (4, 0, 0), 'I-i_SPAT+O': (4, 0, 1), 'I-b_SPAT+b_LOC': (4, 1, 0), 'I-i_SPAT+b_LOC': (4, 1, 1), 'I-i_SPAT+i_LOC': (4, 1, 2), 'I-b_SPAT+b_CARDINAL': (4, 2, 0), 'I-i_SPAT+b_CARDINAL': (4, 2, 1), 'I-i_SPAT+i_CARDINAL': (4, 2, 2), 'I-b_SPAT+b_FT': (4, 3, 0), 'I-i_SPAT+b_FT': (4, 3, 1), 'I-i_SPAT+i_FT': (4, 3, 2), 'I-b_TITRE+O': (5, 0, 0), 'I-i_TITRE+O': (5, 0, 1)} #1\n",
      "Num of classes : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IOB2 import init_model, train_eval_loop, _convert_tokenizer\n",
    "import json\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "            \n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "792bd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning model for IOB2 labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT_IOB2:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IOB2 labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48370946",
   "metadata": {},
   "source": [
    "Best model : /work/stual/res_ICDAR/method_3/tmp/312-camembert-ner-hierarchical-loss-iob2/checkpoint-1300 (score: 0.9712999437253799)\n",
    "Run time :07:37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47472b8",
   "metadata": {},
   "source": [
    "## 313 - Train & eval : IO Ref dataset with Pretrained CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b30d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"pretrained_camembert_ner\"\n",
    "MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "LABEL = \"io\"\n",
    "FOLDER = \"313-pretrained-camembert-ner-hierarchical-loss-io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30025437",
   "metadata": {},
   "source": [
    "### 313.1 Load IO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "836b0fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_1_prepared_dataset_ref_io_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-310-experiment_1_metrics'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_1_prepared_dataset_ref_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-310-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be74410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens             labels\n",
      "0  Duffau-Pauillac            I-PER+O\n",
      "1                (            I-PER+O\n",
      "2              Chs            I-PER+O\n",
      "3                )            I-PER+O\n",
      "4                ,                O+O\n",
      "5          Enghien       I-SPAT+i_LOC\n",
      "6                ,           I-SPAT+O\n",
      "7               16  I-SPAT+i_CARDINAL\n",
      "8                .                O+O\n",
      "9                *                O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ce6d9",
   "metadata": {},
   "source": [
    "### 313.2 Fine-tuning with IO labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3558110b",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IO import init_model, train_eval_loop, _convert_tokenizer\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e46e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning pretrained model for IO labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_PTRN_CAMEMBERT_IO:\n",
    "    print(_convert_tokenizer.name_or_path)\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "        \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning pretrained model for IO labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "252d09e4",
   "metadata": {},
   "source": [
    "Best model : /work/stual/res_ICDAR/method_3/tmp/313-pretrained-camembert-ner-hierarchical-loss-io/checkpoint-3100 (score: 0.977341607735604)\n",
    "Run time : 07:17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae315b",
   "metadata": {},
   "source": [
    "## 314 - Train & eval : IOB2 Ref dataset with Pretrained CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b01d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"pretrained_camembert_ner\"\n",
    "MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "LABEL = \"iob2\"\n",
    "FOLDER = \"314-pretrained-camembert-ner-hierarchical-loss-iob2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019414f",
   "metadata": {},
   "source": [
    "### 314.1 Load IOB2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "130daa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_1_prepared_dataset_ref_iob2_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-310-experiment_1_metrics'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_1_prepared_dataset_ref_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-310-experiment_1_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e125d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens               labels\n",
      "0  Duffau-Pauillac            I-b_PER+O\n",
      "1                (            I-i_PER+O\n",
      "2              Chs            I-i_PER+O\n",
      "3                )            I-i_PER+O\n",
      "4                ,                  O+O\n",
      "5          Enghien       I-b_SPAT+b_LOC\n",
      "6                ,           I-i_SPAT+O\n",
      "7               16  I-i_SPAT+b_CARDINAL\n",
      "8                .                  O+O\n",
      "9                *                  O+O\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a30951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IOB2 import init_model, train_eval_loop, _convert_tokenizer\n",
    "import json\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            \n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "            \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9096720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning pretrained model for IOB2 labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_PTRN_CAMEMBERT_IOB2:\n",
    "    print(_convert_tokenizer.name_or_path)\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning pretrained model for IOB2 labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "175ca00a",
   "metadata": {},
   "source": [
    "Best model : /work/stual/res_ICDAR/method_3/tmp/314-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000 (score: 0.9739776951672862)\n",
    "Run time : 07:32"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
