{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294705ff-9e89-499f-a41f-9494362be5f9",
   "metadata": {
    "id": "2552858d-7386-4e9a-8b0e-c338b920f783"
   },
   "source": [
    "# 320 - M3 Experiment #1 - Hierarchical NER with Pero OCR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536176a",
   "metadata": {},
   "source": [
    "Requirements : \n",
    "* Create datasets in `m2_joint-labelling_for_ner` : `M2_200-prepare_datasets_joint_labelling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e498466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" #Numéro GPU\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e9f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flD_9oT8LmDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flD_9oT8LmDB",
    "outputId": "63a92e5f-d414-46cc-db86-b46981e42594"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZvwNIzqBwDs",
   "metadata": {
    "id": "cZvwNIzqBwDs",
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "Set the BASE path.\n",
    "If run on Google Colab, will also mout Google Drive to the moutpoint given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LWJVak2mB6bI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWJVak2mB6bI",
    "outputId": "dbb54104-560b-480c-d4b0-74a0787e2024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lrde/home2/stual/stage_DAS/m3_hierarchical_ner', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages']\n",
      "/lrde/home2/stual/stage_DAS/m3_hierarchical_ner\n",
      "/work/stual/dataset_ICDAR\n",
      "/work/stual/res_ICDAR/method_3\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive to BASE\n",
    "  base = mountpoint / \"MyDrive/article_icdar_2023\" # Adapt this to your situation\n",
    "  sys.path.append(str(base)) # Add BASE to Python Path\n",
    "  BASE = Path(base).resolve() # Make BASE absolute\n",
    "  DATASETS =  BASE / \"dataset\"\n",
    "else:\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve() # If not on GColab, BASE will be the directory of this notebook\n",
    "  DATASETS = Path('/work/stual/dataset_ICDAR')\n",
    "  DATA_BASE = Path('/work/stual/res_ICDAR/method_2')\n",
    "  OUT_BASE = Path('/work/stual/res_ICDAR/method_3')\n",
    "\n",
    "print(sys.path)\n",
    "print(BASE)\n",
    "print(DATASETS)\n",
    "print(OUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hxHdPTBlCCFO",
   "metadata": {
    "id": "hxHdPTBlCCFO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d554600",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CAMEMBERT_IO = False\n",
    "RUN_CAMEMBERT_IOB2 = False\n",
    "#Can't run together because of convert_tokenizer_\n",
    "RUN_PTRN_CAMEMBERT_IO = False\n",
    "RUN_PTRN_CAMEMBERT_IOB2 = True\n",
    "\n",
    "# Number of times a model will be trained & evaluated on each a dataset\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {
    "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed"
   },
   "source": [
    "## CamemBERT - Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {
    "id": "91140aa5-b377-47c1-bd44-844cd9365ec3"
   },
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32396c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "\n",
    "#Print examples from datasets\n",
    "def loadExample(INPUT_DIR,set_length:int,i:int,subset:str):\n",
    "    set_ = load_from_disk(INPUT_DIR / f\"huggingface_{set_length}\")\n",
    "    data = {\"tokens\": set_[subset][i][\"tokens\"],\n",
    "            \"labels\": set_[subset][i][\"ner_tags\"]}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacc1d2",
   "metadata": {},
   "source": [
    "## Hierarchical NER : Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76a0e1",
   "metadata": {},
   "source": [
    "### Tree with IO Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc90872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             EN                                                                                        \n",
      " ┌──────────────┬───────────────────────┬────────────────────┼────────────────────────────────────────┬───────────────────────────────────────────┐      \n",
      " O            I-PER                   I-ACT                I-DESC                                   I-SPAT                                     I-TITRE \n",
      " │      ┌───────┴──────────┐            │        ┌───────────┼───────────────┐            ┌───────────┼───────────────┬───────────────┐           │      \n",
      "O+O  I-PER+O         I-PER+i_TITREH  I-ACT+O  I-DESC+O  I-DESC+i_ACT  I-DESC+i_TITREP  I-SPAT+O  I-SPAT+i_LOC  I-SPAT+i_CARDINA  I-SPAT+i_FT  I-TITRE+O\n",
      "                                                                                                                      L                                \n",
      "\n",
      "(-100.0\n",
      "  (1.0 1.0)\n",
      "  (1.0 1.0 1.0)\n",
      "  (1.0 1.0)\n",
      "  (1.0 1.0 1.0 1.0)\n",
      "  (1.0 1.0 1.0 1.0 1.0)\n",
      "  (1.0 1.0))\n"
     ]
    }
   ],
   "source": [
    "from hierarchicalNER.trees import Ltree, Wtree\n",
    "Ltree.pretty_print(unicodelines=True, nodedist=2)\n",
    "print(Wtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c78841",
   "metadata": {},
   "source": [
    "### Tree with IOB2 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0689a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e9c889",
   "metadata": {},
   "source": [
    "## 321 - Train & eval : IO Ref dataset with CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e2004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"camembert_ner\"\n",
    "MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "LABEL = \"io\"\n",
    "FOLDER = \"321-camembert-ner-hierarchical-loss-io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882da225",
   "metadata": {},
   "source": [
    "### 321.1 Load IO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_2_prepared_dataset_pero_ocr_io_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-320-experiment_2_metrics'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_2_prepared_dataset_pero_ocr_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-320-experiment_2_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6040ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens             labels\n",
      "0  Duffau-Pauillac            I-PER+O\n",
      "1                (            I-PER+O\n",
      "2              Chs            I-PER+O\n",
      "3                )            I-PER+O\n",
      "4                ,                O+O\n",
      "5          Enghien       I-SPAT+i_LOC\n",
      "6                ,           I-SPAT+O\n",
      "7               16  I-SPAT+i_CARDINAL\n",
      "8                .                O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4aa5b",
   "metadata": {},
   "source": [
    "### 321.2 Fine-tuning with IO labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:34:56.291847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 09:34:57.337400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-03 09:34:57.337513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-03 09:34:57.337523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree positions of all the leaves{'O+O': (0, 0), 'I-PER+O': (1, 0), 'I-PER+i_TITREH': (1, 1), 'I-ACT+O': (2, 0), 'I-DESC+O': (3, 0), 'I-DESC+i_ACT': (3, 1), 'I-DESC+i_TITREP': (3, 2), 'I-SPAT+O': (4, 0), 'I-SPAT+i_LOC': (4, 1), 'I-SPAT+i_CARDINAL': (4, 2), 'I-SPAT+i_FT': (4, 3), 'I-TITRE+O': (5, 0)} #1\n",
      "Num of classes : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "import json\n",
    "from hierarchicalNER.util_IO import init_model, train_eval_loop\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6131ba8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05387e39-dd69-491e-9517-57490356e5e9",
    "outputId": "a894e899-0646-4260-f12f-7468adfbb5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning model for IO labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from hierarchicalNER.util_IO import _convert_tokenizer\n",
    "\n",
    "if RUN_CAMEMBERT_IO:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IO labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9dcb2a8",
   "metadata": {},
   "source": [
    "Best model : \n",
    "Run time : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46aea",
   "metadata": {},
   "source": [
    "## 322 - Train & eval : IOB2 Ref dataset with CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a8e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"camembert_ner\"\n",
    "MODEL = \"Jean-Baptiste/camembert-ner\"\n",
    "LABEL = \"iob2\"\n",
    "FOLDER = \"322-camembert-ner-hierarchical-loss-iob2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17156e4a",
   "metadata": {},
   "source": [
    "### 322.1 Load IOB2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "120918dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_2_prepared_dataset_pero_ocr_iob2_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-320-experiment_2_metrics'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_2_prepared_dataset_pero_ocr_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-320-experiment_2_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86ae2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens               labels\n",
      "0  Duffau-Pauillac            I-b_PER+O\n",
      "1                (            I-i_PER+O\n",
      "2              Chs            I-i_PER+O\n",
      "3                )            I-i_PER+O\n",
      "4                ,                  O+O\n",
      "5          Enghien       I-b_SPAT+b_LOC\n",
      "6                ,           I-i_SPAT+O\n",
      "7               16  I-i_SPAT+b_CARDINAL\n",
      "8                .                  O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa6008",
   "metadata": {},
   "source": [
    "### 322.2 Fine-tuning with IOB2 labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2845620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree positions of all the leaves{'O+O': (0, 0, 0), 'I-b_PER+O': (1, 0, 0), 'I-i_PER+O': (1, 0, 1), 'I-b_PER+b_TITREH': (1, 1, 0), 'I-i_PER+b_TITREH': (1, 1, 1), 'I-i_PER+i_TITREH': (1, 1, 2), 'I-b_ACT+O': (2, 0, 0), 'I-i_ACT+O': (2, 0, 1), 'I-b_DESC+O': (3, 0, 0), 'I-i_DESC+O': (3, 0, 1), 'I-b_DESC+b_ACT': (3, 1, 0), 'I-i_DESC+b_ACT': (3, 1, 1), 'I-i_DESC+i_ACT': (3, 1, 2), 'I-b_DESC+b_TITREP': (3, 2, 0), 'I-i_DESC+b_TITREP': (3, 2, 1), 'I-i_DESC+i_TITREP': (3, 2, 2), 'I-b_SPAT+O': (4, 0, 0), 'I-i_SPAT+O': (4, 0, 1), 'I-b_SPAT+b_LOC': (4, 1, 0), 'I-i_SPAT+b_LOC': (4, 1, 1), 'I-i_SPAT+i_LOC': (4, 1, 2), 'I-b_SPAT+b_CARDINAL': (4, 2, 0), 'I-i_SPAT+b_CARDINAL': (4, 2, 1), 'I-i_SPAT+i_CARDINAL': (4, 2, 2), 'I-b_SPAT+b_FT': (4, 3, 0), 'I-i_SPAT+b_FT': (4, 3, 1), 'I-i_SPAT+i_FT': (4, 3, 2), 'I-b_TITRE+O': (5, 0, 0), 'I-i_TITRE+O': (5, 0, 1)} #1\n",
      "Num of classes : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /lrde/home2/stual/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IOB2 import init_model, train_eval_loop, _convert_tokenizer\n",
    "import json\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            \n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792bd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning model for IOB2 labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_CAMEMBERT_IOB2:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "else:\n",
    "    print(\"Skipped finetuning model for IOB2 labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef54a021",
   "metadata": {},
   "source": [
    "Best model : \n",
    "Run time : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47472b8",
   "metadata": {},
   "source": [
    "## 323 - Train & eval : IO Ref dataset with Pretrained CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b30d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"pretrained_camembert_ner\"\n",
    "MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "LABEL = \"io\"\n",
    "FOLDER = \"323-pretrained-camembert-ner-hierarchical-loss-io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30025437",
   "metadata": {},
   "source": [
    "### 323.1 Load IO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "836b0fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
    "outputId": "5749eaf4-a3d1-40fd-b2d4-fd45a27eb16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_2_prepared_dataset_pero_ocr_io_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-320-experiment_2_metrics'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_2_prepared_dataset_pero_ocr_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-320-experiment_2_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be74410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens             labels\n",
      "0  Duffau-Pauillac            I-PER+O\n",
      "1                (            I-PER+O\n",
      "2              Chs            I-PER+O\n",
      "3                )            I-PER+O\n",
      "4                ,                O+O\n",
      "5          Enghien       I-SPAT+i_LOC\n",
      "6                ,           I-SPAT+O\n",
      "7               16  I-SPAT+i_CARDINAL\n",
      "8                .                O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ce6d9",
   "metadata": {},
   "source": [
    "### 323.2 Fine-tuning with IO labels - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3558110b",
   "metadata": {
    "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IO import init_model, train_eval_loop, _convert_tokenizer\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e46e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped finetuning pretrained model for IO labels\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_PTRN_CAMEMBERT_IO:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning pretrained model for IO labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a780bb3a",
   "metadata": {},
   "source": [
    "Best model : \n",
    "Run time : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae315b",
   "metadata": {},
   "source": [
    "## 324 - Train & eval : IOB2 Ref dataset with Pretrained CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b01d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"pretrained_camembert_ner\"\n",
    "MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n",
    "LABEL = \"iob2\"\n",
    "FOLDER = \"324-pretrained-camembert-ner-hierarchical-loss-iob2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019414f",
   "metadata": {},
   "source": [
    "### 324.1 Load IOB2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "130daa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/work/stual/res_ICDAR/method_2/m2-experiment_2_prepared_dataset_pero_ocr_iob2_pretrained_camembert_ner'),\n",
       " PosixPath('/work/stual/res_ICDAR/method_3/m3-320-experiment_2_metrics'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import logger\n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#TRAINSETS_SIZES = [47,95,190,380,760,1521,3042,6084] #To train on the 7 datasets\n",
    "TRAINSETS_SIZES = [6084] #To train only on the biggest dataset\n",
    "\n",
    "# INPUT / OUTPUT DIRS\n",
    "INPUT_DIR = DATA_BASE / f\"m2-experiment_2_prepared_dataset_pero_ocr_{LABEL}_{MODEL_NAME}\"\n",
    "METRICS_OUTPUT_DIR = OUT_BASE / \"m3-320-experiment_2_metrics\"\n",
    "INPUT_DIR, METRICS_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e125d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokens               labels\n",
      "0  Duffau-Pauillac            I-b_PER+O\n",
      "1                (            I-i_PER+O\n",
      "2              Chs            I-i_PER+O\n",
      "3                )            I-i_PER+O\n",
      "4                ,                  O+O\n",
      "5          Enghien       I-b_SPAT+b_LOC\n",
      "6                ,           I-i_SPAT+O\n",
      "7               16  I-i_SPAT+b_CARDINAL\n",
      "8                .                  O+O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadExample(INPUT_DIR,TRAINSETS_SIZES[-1],10,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a30951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from hierarchicalNER.util_IOB2 import init_model, train_eval_loop, _convert_tokenizer\n",
    "import json\n",
    "\n",
    "def train_bert(metrics_output_directory):\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        output_dir = metrics_output_directory / f\"run_{run}\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        #Fine-tuning on the biggest dataset\n",
    "        for trainset_size in TRAINSETS_SIZES:\n",
    "            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {output_dir}\")\n",
    "            \n",
    "            model, tokenizer, training_args = init_model(MODEL, local_config,run)\n",
    "            logger.info(f\"{model} #{run}, will save in {output_dir}\")\n",
    "\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            \n",
    "            train = train_dev_test[\"train\"]\n",
    "            dev = train_dev_test[\"dev\"]\n",
    "            test = train_dev_test[\"test\"]\n",
    "            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n",
    "                                      training_args, # Idem\n",
    "                                      tokenizer,\n",
    "                                      train,dev,test)\n",
    "\n",
    "            # Save the dev and test metrics\n",
    "            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n",
    "            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9096720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110053661\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/5000 08:38 < 12:58, 3.86 it/s, Epoch 5/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Precision-l1l2</th>\n",
       "      <th>Recall-l1l2</th>\n",
       "      <th>F1-l1l2</th>\n",
       "      <th>Accuracy-l1l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663207</td>\n",
       "      <td>0.940189</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.932041</td>\n",
       "      <td>0.930904</td>\n",
       "      <td>0.922798</td>\n",
       "      <td>0.934908</td>\n",
       "      <td>0.928814</td>\n",
       "      <td>0.944824</td>\n",
       "      <td>0.939083</td>\n",
       "      <td>0.913449</td>\n",
       "      <td>0.926088</td>\n",
       "      <td>0.963554</td>\n",
       "      <td>0.929693</td>\n",
       "      <td>0.925885</td>\n",
       "      <td>0.927785</td>\n",
       "      <td>0.949127</td>\n",
       "      <td>0.931891</td>\n",
       "      <td>0.926475</td>\n",
       "      <td>0.929175</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.925448</td>\n",
       "      <td>0.927626</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>{'precision': 0.9484536082474226, 'recall': 0.9526627218934911, 'f1': 0.9505535055350554, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8956043956043956, 'recall': 0.9421965317919075, 'f1': 0.9183098591549297, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8956043956043956, 'recall': 0.9721669980119284, 'f1': 0.9323164918970448, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9191489361702128, 'recall': 0.9337175792507204, 'f1': 0.9263759828448892, 'number': 694}</td>\n",
       "      <td>{'precision': 0.924380704041721, 'recall': 0.9304461942257218, 'f1': 0.9274035317200785, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9553314121037464, 'recall': 0.9778761061946902, 'f1': 0.9664723032069971, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.385018</td>\n",
       "      <td>0.943787</td>\n",
       "      <td>0.937599</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>0.936851</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.936483</td>\n",
       "      <td>0.927235</td>\n",
       "      <td>0.945457</td>\n",
       "      <td>0.942818</td>\n",
       "      <td>0.922104</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.940037</td>\n",
       "      <td>0.940037</td>\n",
       "      <td>0.940037</td>\n",
       "      <td>0.955454</td>\n",
       "      <td>0.939085</td>\n",
       "      <td>0.936356</td>\n",
       "      <td>0.937718</td>\n",
       "      <td>0.937358</td>\n",
       "      <td>0.928781</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.929462</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>{'precision': 0.9384164222873901, 'recall': 0.9467455621301775, 'f1': 0.9425625920471281, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8923357664233577, 'recall': 0.9421965317919075, 'f1': 0.9165885660731022, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8923357664233577, 'recall': 0.9721669980119284, 'f1': 0.9305423406279734, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9199438202247191, 'recall': 0.9438040345821326, 'f1': 0.9317211948790898, 'number': 694}</td>\n",
       "      <td>{'precision': 0.926923076923077, 'recall': 0.9488188976377953, 'f1': 0.9377431906614787, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9608127721335269, 'recall': 0.976401179941003, 'f1': 0.9685442574981712, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289530</td>\n",
       "      <td>0.951657</td>\n",
       "      <td>0.947999</td>\n",
       "      <td>0.949824</td>\n",
       "      <td>0.945077</td>\n",
       "      <td>0.923547</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.937161</td>\n",
       "      <td>0.954948</td>\n",
       "      <td>0.931534</td>\n",
       "      <td>0.942077</td>\n",
       "      <td>0.936776</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>0.955523</td>\n",
       "      <td>0.960149</td>\n",
       "      <td>0.957830</td>\n",
       "      <td>0.967223</td>\n",
       "      <td>0.938378</td>\n",
       "      <td>0.951468</td>\n",
       "      <td>0.944877</td>\n",
       "      <td>0.945457</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>0.947168</td>\n",
       "      <td>0.936992</td>\n",
       "      <td>0.963427</td>\n",
       "      <td>{'precision': 0.9502196193265008, 'recall': 0.9600591715976331, 'f1': 0.9551140544518028, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9297912713472486, 'recall': 0.9441233140655106, 'f1': 0.936902485659656, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9297912713472486, 'recall': 0.974155069582505, 'f1': 0.9514563106796117, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.18181818181818182, 'recall': 0.26666666666666666, 'f1': 0.21621621621621623, 'number': 30}</td>\n",
       "      <td>{'precision': 0.32608695652173914, 'recall': 0.45454545454545453, 'f1': 0.379746835443038, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9392655367231638, 'recall': 0.9582132564841499, 'f1': 0.9486447931526392, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9392764857881137, 'recall': 0.9540682414698163, 'f1': 0.9466145833333334, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9696531791907514, 'recall': 0.9896755162241888, 'f1': 0.9795620437956204, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.228326</td>\n",
       "      <td>0.952856</td>\n",
       "      <td>0.950486</td>\n",
       "      <td>0.951669</td>\n",
       "      <td>0.951405</td>\n",
       "      <td>0.932786</td>\n",
       "      <td>0.954331</td>\n",
       "      <td>0.943435</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>0.935974</td>\n",
       "      <td>0.944075</td>\n",
       "      <td>0.940007</td>\n",
       "      <td>0.971526</td>\n",
       "      <td>0.961396</td>\n",
       "      <td>0.964618</td>\n",
       "      <td>0.963004</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.943472</td>\n",
       "      <td>0.955536</td>\n",
       "      <td>0.949466</td>\n",
       "      <td>0.952037</td>\n",
       "      <td>0.934180</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.941930</td>\n",
       "      <td>0.966021</td>\n",
       "      <td>{'precision': 0.9648093841642229, 'recall': 0.9733727810650887, 'f1': 0.9690721649484536, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9193245778611632, 'recall': 0.9441233140655106, 'f1': 0.9315589353612168, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9193245778611632, 'recall': 0.974155069582505, 'f1': 0.9459459459459459, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.23333333333333334, 'recall': 0.23333333333333334, 'f1': 0.23333333333333334, 'number': 30}</td>\n",
       "      <td>{'precision': 0.3137254901960784, 'recall': 0.48484848484848486, 'f1': 0.380952380952381, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9417613636363636, 'recall': 0.9553314121037464, 'f1': 0.9484978540772532, 'number': 694}</td>\n",
       "      <td>{'precision': 0.943078913324709, 'recall': 0.9566929133858267, 'f1': 0.9498371335504886, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.222095</td>\n",
       "      <td>0.955059</td>\n",
       "      <td>0.956138</td>\n",
       "      <td>0.955598</td>\n",
       "      <td>0.953430</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.948871</td>\n",
       "      <td>0.962668</td>\n",
       "      <td>0.928525</td>\n",
       "      <td>0.942743</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.966853</td>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.943888</td>\n",
       "      <td>0.958152</td>\n",
       "      <td>0.950966</td>\n",
       "      <td>0.953936</td>\n",
       "      <td>0.934063</td>\n",
       "      <td>0.952157</td>\n",
       "      <td>0.943023</td>\n",
       "      <td>0.966021</td>\n",
       "      <td>{'precision': 0.9649122807017544, 'recall': 0.9763313609467456, 'f1': 0.9705882352941176, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9319470699432892, 'recall': 0.9499036608863198, 'f1': 0.9408396946564885, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9319470699432892, 'recall': 0.9801192842942346, 'f1': 0.9554263565891473, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.32, 'recall': 0.26666666666666666, 'f1': 0.2909090909090909, 'number': 30}</td>\n",
       "      <td>{'precision': 0.3018867924528302, 'recall': 0.48484848484848486, 'f1': 0.37209302325581395, 'number': 33}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.5, 'f1': 0.42857142857142855, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9394366197183098, 'recall': 0.9610951008645533, 'f1': 0.9501424501424501, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9284802043422733, 'recall': 0.9540682414698163, 'f1': 0.9411003236245955, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.200205</td>\n",
       "      <td>0.952788</td>\n",
       "      <td>0.958173</td>\n",
       "      <td>0.955473</td>\n",
       "      <td>0.954062</td>\n",
       "      <td>0.939877</td>\n",
       "      <td>0.960105</td>\n",
       "      <td>0.949883</td>\n",
       "      <td>0.961782</td>\n",
       "      <td>0.940711</td>\n",
       "      <td>0.950732</td>\n",
       "      <td>0.945695</td>\n",
       "      <td>0.972918</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.961266</td>\n",
       "      <td>0.957699</td>\n",
       "      <td>0.972285</td>\n",
       "      <td>0.943920</td>\n",
       "      <td>0.958733</td>\n",
       "      <td>0.951269</td>\n",
       "      <td>0.954568</td>\n",
       "      <td>0.940242</td>\n",
       "      <td>0.955973</td>\n",
       "      <td>0.948042</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>{'precision': 0.9631268436578171, 'recall': 0.9659763313609467, 'f1': 0.9645494830132939, 'number': 676}</td>\n",
       "      <td>{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}</td>\n",
       "      <td>{'precision': 0.924812030075188, 'recall': 0.9781312127236581, 'f1': 0.9507246376811596, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2903225806451613, 'recall': 0.3, 'f1': 0.29508196721311475, 'number': 30}</td>\n",
       "      <td>{'precision': 0.48, 'recall': 0.7272727272727273, 'f1': 0.5783132530120482, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9574468085106383, 'recall': 0.9726224783861671, 'f1': 0.9649749821300929, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795021961932651, 'recall': 0.9867256637168141, 'f1': 0.9831006612784717, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.183775</td>\n",
       "      <td>0.954269</td>\n",
       "      <td>0.957721</td>\n",
       "      <td>0.955992</td>\n",
       "      <td>0.954568</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.959055</td>\n",
       "      <td>0.949584</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.933987</td>\n",
       "      <td>0.951398</td>\n",
       "      <td>0.942612</td>\n",
       "      <td>0.973045</td>\n",
       "      <td>0.954478</td>\n",
       "      <td>0.960521</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>0.940975</td>\n",
       "      <td>0.959024</td>\n",
       "      <td>0.949914</td>\n",
       "      <td>0.955075</td>\n",
       "      <td>0.937518</td>\n",
       "      <td>0.955679</td>\n",
       "      <td>0.946512</td>\n",
       "      <td>0.968362</td>\n",
       "      <td>{'precision': 0.9632892804698973, 'recall': 0.9704142011834319, 'f1': 0.9668386145910095, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9152542372881356, 'recall': 0.9364161849710982, 'f1': 0.9257142857142857, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9344894026974951, 'recall': 0.9642147117296223, 'f1': 0.9491193737769079, 'number': 503}</td>\n",
       "      <td>{'precision': 0.08333333333333333, 'recall': 0.0625, 'f1': 0.07142857142857144, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2619047619047619, 'recall': 0.36666666666666664, 'f1': 0.3055555555555555, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5813953488372093, 'recall': 0.7575757575757576, 'f1': 0.6578947368421053, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9332477535301669, 'recall': 0.9540682414698163, 'f1': 0.9435431537962362, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9767441860465116, 'recall': 0.9911504424778761, 'f1': 0.9838945827232797, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.165503</td>\n",
       "      <td>0.959469</td>\n",
       "      <td>0.963373</td>\n",
       "      <td>0.961417</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.944874</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.953718</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.949040</td>\n",
       "      <td>0.954727</td>\n",
       "      <td>0.951875</td>\n",
       "      <td>0.973678</td>\n",
       "      <td>0.965172</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.967682</td>\n",
       "      <td>0.977221</td>\n",
       "      <td>0.953656</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>0.958207</td>\n",
       "      <td>0.959884</td>\n",
       "      <td>0.946698</td>\n",
       "      <td>0.959202</td>\n",
       "      <td>0.952909</td>\n",
       "      <td>0.970261</td>\n",
       "      <td>{'precision': 0.973568281938326, 'recall': 0.9807692307692307, 'f1': 0.9771554900515844, 'number': 676}</td>\n",
       "      <td>{'precision': 0.917910447761194, 'recall': 0.9479768786127167, 'f1': 0.9327014218009477, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9352380952380952, 'recall': 0.9761431411530815, 'f1': 0.9552529182879377, 'number': 503}</td>\n",
       "      <td>{'precision': 0.09090909090909091, 'recall': 0.0625, 'f1': 0.07407407407407407, 'number': 16}</td>\n",
       "      <td>{'precision': 0.30303030303030304, 'recall': 0.3333333333333333, 'f1': 0.31746031746031744, 'number': 30}</td>\n",
       "      <td>{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9544159544159544, 'recall': 0.9654178674351584, 'f1': 0.9598853868194842, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9406451612903226, 'recall': 0.9566929133858267, 'f1': 0.9486011711125569, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.176233</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.966539</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.961655</td>\n",
       "      <td>0.951546</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.960208</td>\n",
       "      <td>0.968869</td>\n",
       "      <td>0.955688</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.958859</td>\n",
       "      <td>0.975829</td>\n",
       "      <td>0.966321</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.969371</td>\n",
       "      <td>0.978613</td>\n",
       "      <td>0.957961</td>\n",
       "      <td>0.966870</td>\n",
       "      <td>0.962395</td>\n",
       "      <td>0.962668</td>\n",
       "      <td>0.953360</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.972349</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9325842696629213, 'recall': 0.9595375722543352, 'f1': 0.9458689458689458, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9408396946564885, 'recall': 0.9801192842942346, 'f1': 0.9600778967867575, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3125, 'f1': 0.38461538461538464, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38235294117647056, 'recall': 0.43333333333333335, 'f1': 0.40625, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}</td>\n",
       "      <td>{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9446589446589446, 'recall': 0.963254593175853, 'f1': 0.9538661468486029, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.159163</td>\n",
       "      <td>0.962294</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.962946</td>\n",
       "      <td>0.960896</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.953790</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.951058</td>\n",
       "      <td>0.957390</td>\n",
       "      <td>0.954214</td>\n",
       "      <td>0.975323</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.955632</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.959780</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.946805</td>\n",
       "      <td>0.961256</td>\n",
       "      <td>0.953976</td>\n",
       "      <td>0.971147</td>\n",
       "      <td>{'precision': 0.9764359351988218, 'recall': 0.9807692307692307, 'f1': 0.9785977859778597, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9116022099447514, 'recall': 0.953757225433526, 'f1': 0.9322033898305084, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9371428571428572, 'recall': 0.9781312127236581, 'f1': 0.9571984435797665, 'number': 503}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.1875, 'f1': 0.17647058823529413, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35294117647058826, 'recall': 0.4, 'f1': 0.37500000000000006, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7941176470588235, 'recall': 0.8181818181818182, 'f1': 0.8059701492537314, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9449929478138223, 'recall': 0.9654178674351584, 'f1': 0.955096222380613, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9544863459037711, 'recall': 0.963254593175853, 'f1': 0.9588504245591117, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.163907</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.961820</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.952257</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.957724</td>\n",
       "      <td>0.965705</td>\n",
       "      <td>0.946124</td>\n",
       "      <td>0.958722</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.973551</td>\n",
       "      <td>0.960444</td>\n",
       "      <td>0.967598</td>\n",
       "      <td>0.964007</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.951849</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.958745</td>\n",
       "      <td>0.949551</td>\n",
       "      <td>0.961256</td>\n",
       "      <td>0.955368</td>\n",
       "      <td>0.969628</td>\n",
       "      <td>{'precision': 0.9690721649484536, 'recall': 0.9733727810650887, 'f1': 0.9712177121771217, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9330855018587361, 'recall': 0.9672447013487476, 'f1': 0.9498580889309367, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}</td>\n",
       "      <td>{'precision': 0.36, 'recall': 0.5625, 'f1': 0.43902439024390244, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5135135135135135, 'recall': 0.6333333333333333, 'f1': 0.5671641791044775, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9527220630372493, 'recall': 0.9582132564841499, 'f1': 0.9554597701149425, 'number': 694}</td>\n",
       "      <td>{'precision': 0.937984496124031, 'recall': 0.952755905511811, 'f1': 0.9453125, 'number': 762}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.165150</td>\n",
       "      <td>0.961176</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.964748</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.950904</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>0.953765</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>0.957560</td>\n",
       "      <td>0.974690</td>\n",
       "      <td>0.965888</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.968042</td>\n",
       "      <td>0.978993</td>\n",
       "      <td>0.955760</td>\n",
       "      <td>0.966870</td>\n",
       "      <td>0.961283</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.952160</td>\n",
       "      <td>0.963898</td>\n",
       "      <td>0.957993</td>\n",
       "      <td>0.970893</td>\n",
       "      <td>{'precision': 0.9735294117647059, 'recall': 0.9792899408284024, 'f1': 0.9764011799410028, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9571150097465887, 'recall': 0.9761431411530815, 'f1': 0.9665354330708661, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4444444444444444, 'recall': 0.5, 'f1': 0.47058823529411764, 'number': 16}</td>\n",
       "      <td>{'precision': 0.41025641025641024, 'recall': 0.5333333333333333, 'f1': 0.463768115942029, 'number': 30}</td>\n",
       "      <td>{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9494163424124513, 'recall': 0.9606299212598425, 'f1': 0.9549902152641879, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.159504</td>\n",
       "      <td>0.961608</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.964966</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>0.950515</td>\n",
       "      <td>0.967979</td>\n",
       "      <td>0.959168</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.950462</td>\n",
       "      <td>0.958056</td>\n",
       "      <td>0.954244</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>0.965594</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.978993</td>\n",
       "      <td>0.956022</td>\n",
       "      <td>0.966579</td>\n",
       "      <td>0.961272</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.950492</td>\n",
       "      <td>0.963604</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.973614</td>\n",
       "      <td>{'precision': 0.9780058651026393, 'recall': 0.9866863905325444, 'f1': 0.9823269513991164, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.1875, 'f1': 0.23076923076923075, 'number': 16}</td>\n",
       "      <td>{'precision': 0.43333333333333335, 'recall': 0.43333333333333335, 'f1': 0.43333333333333335, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.948936170212766, 'recall': 0.9639769452449568, 'f1': 0.956397426733381, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9407216494845361, 'recall': 0.958005249343832, 'f1': 0.9492847854356307, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.183562</td>\n",
       "      <td>0.958837</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.963904</td>\n",
       "      <td>0.953809</td>\n",
       "      <td>0.954969</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.961689</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>0.948953</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.957096</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>0.965619</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.969202</td>\n",
       "      <td>0.974184</td>\n",
       "      <td>0.953728</td>\n",
       "      <td>0.970357</td>\n",
       "      <td>0.961971</td>\n",
       "      <td>0.954695</td>\n",
       "      <td>0.952312</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.959662</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9307116104868914, 'recall': 0.9576107899807321, 'f1': 0.9439696106362773, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9625984251968503, 'recall': 0.9721669980119284, 'f1': 0.9673590504451038, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3076923076923077, 'recall': 0.5, 'f1': 0.380952380952381, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9600570613409415, 'recall': 0.9697406340057637, 'f1': 0.9648745519713262, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9752186588921283, 'recall': 0.9867256637168141, 'f1': 0.9809384164222874, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.174589</td>\n",
       "      <td>0.965378</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.968098</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.954592</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.962789</td>\n",
       "      <td>0.969628</td>\n",
       "      <td>0.961975</td>\n",
       "      <td>0.960053</td>\n",
       "      <td>0.961013</td>\n",
       "      <td>0.978107</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.969944</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.961350</td>\n",
       "      <td>0.968614</td>\n",
       "      <td>0.964968</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>0.957812</td>\n",
       "      <td>0.966246</td>\n",
       "      <td>0.962011</td>\n",
       "      <td>0.973867</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9911242603550295, 'f1': 0.9867452135493372, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9338374291115312, 'recall': 0.9518304431599229, 'f1': 0.9427480916030534, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9371428571428572, 'recall': 0.9781312127236581, 'f1': 0.9571984435797665, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.125, 'f1': 0.2, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.4666666666666667, 'f1': 0.4827586206896552, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9587482219061166, 'recall': 0.9711815561959655, 'f1': 0.964924838940587, 'number': 694}</td>\n",
       "      <td>{'precision': 0.95822454308094, 'recall': 0.963254593175853, 'f1': 0.9607329842931936, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.157428</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.967880</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.960683</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.957728</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>0.969641</td>\n",
       "      <td>0.975419</td>\n",
       "      <td>0.972521</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>0.962313</td>\n",
       "      <td>0.972101</td>\n",
       "      <td>0.967182</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>0.959385</td>\n",
       "      <td>0.970649</td>\n",
       "      <td>0.964984</td>\n",
       "      <td>0.978170</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9545454545454546, 'recall': 0.9710982658959537, 'f1': 0.9627507163323782, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9631067961165048, 'recall': 0.9860834990059643, 'f1': 0.9744597249508842, 'number': 503}</td>\n",
       "      <td>{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}</td>\n",
       "      <td>{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9602836879432625, 'recall': 0.9755043227665706, 'f1': 0.9678341672623302, 'number': 694}</td>\n",
       "      <td>{'precision': 0.953307392996109, 'recall': 0.9645669291338582, 'f1': 0.9589041095890412, 'number': 762}</td>\n",
       "      <td>{'precision': 0.981021897810219, 'recall': 0.9911504424778761, 'f1': 0.9860601614086574, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.170313</td>\n",
       "      <td>0.961348</td>\n",
       "      <td>0.967217</td>\n",
       "      <td>0.964274</td>\n",
       "      <td>0.960896</td>\n",
       "      <td>0.954053</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.961999</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.955086</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.958886</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>0.965172</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.967682</td>\n",
       "      <td>0.974690</td>\n",
       "      <td>0.957147</td>\n",
       "      <td>0.967161</td>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.954506</td>\n",
       "      <td>0.966833</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.972918</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.943289224952741, 'recall': 0.9614643545279383, 'f1': 0.9522900763358778, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5555555555555556, 'recall': 0.625, 'f1': 0.5882352941176471, 'number': 16}</td>\n",
       "      <td>{'precision': 0.41304347826086957, 'recall': 0.6333333333333333, 'f1': 0.5, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9601139601139601, 'recall': 0.9711815561959655, 'f1': 0.9656160458452723, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.158142</td>\n",
       "      <td>0.958268</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.964510</td>\n",
       "      <td>0.966085</td>\n",
       "      <td>0.952087</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.960998</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>0.950033</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.956004</td>\n",
       "      <td>0.979625</td>\n",
       "      <td>0.964906</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.981144</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.970357</td>\n",
       "      <td>0.962387</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.951184</td>\n",
       "      <td>0.966539</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>0.976968</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9378531073446328, 'recall': 0.9595375722543352, 'f1': 0.9485714285714286, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9460500963391136, 'recall': 0.9761431411530815, 'f1': 0.9608610567514677, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5833333333333334, 'recall': 0.4375, 'f1': 0.5, 'number': 16}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5333333333333333, 'f1': 0.47058823529411764, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9533239038189534, 'recall': 0.9711815561959655, 'f1': 0.9621698786581013, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9432989690721649, 'recall': 0.9606299212598425, 'f1': 0.951885565669701, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.152606</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.969478</td>\n",
       "      <td>0.963271</td>\n",
       "      <td>0.965452</td>\n",
       "      <td>0.946639</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.961950</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.952571</td>\n",
       "      <td>0.968904</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.966464</td>\n",
       "      <td>0.949510</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>0.957660</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9380863039399625, 'recall': 0.9633911368015414, 'f1': 0.9505703422053231, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9515503875968992, 'recall': 0.9761431411530815, 'f1': 0.9636898920510304, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5294117647058824, 'recall': 0.5625, 'f1': 0.5454545454545455, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3137254901960784, 'recall': 0.5333333333333333, 'f1': 0.3950617283950617, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9354838709677419, 'recall': 0.8787878787878788, 'f1': 0.90625, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.5, 'f1': 0.37499999999999994, 'number': 6}</td>\n",
       "      <td>{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9458064516129032, 'recall': 0.9619422572178478, 'f1': 0.9538061158100195, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.152097</td>\n",
       "      <td>0.966006</td>\n",
       "      <td>0.970156</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>0.968109</td>\n",
       "      <td>0.952602</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.961518</td>\n",
       "      <td>0.975070</td>\n",
       "      <td>0.958859</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.968136</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.981777</td>\n",
       "      <td>0.961106</td>\n",
       "      <td>0.969486</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.968869</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.966833</td>\n",
       "      <td>0.961050</td>\n",
       "      <td>0.976778</td>\n",
       "      <td>{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}</td>\n",
       "      <td>{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9572815533980582, 'recall': 0.9801192842942346, 'f1': 0.9685658153241651, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 16}</td>\n",
       "      <td>{'precision': 0.40476190476190477, 'recall': 0.5666666666666667, 'f1': 0.4722222222222222, 'number': 30}</td>\n",
       "      <td>{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9588068181818182, 'recall': 0.9726224783861671, 'f1': 0.9656652360515022, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9556135770234987, 'recall': 0.9606299212598425, 'f1': 0.9581151832460733, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/stage_DAS/m3_hierarchical_ner/hierarchicalNER/util_IOB2.py:205: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9484536082474226, 'recall': 0.9526627218934911, 'f1': 0.9505535055350554, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8956043956043956, 'recall': 0.9421965317919075, 'f1': 0.9183098591549297, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8956043956043956, 'recall': 0.9721669980119284, 'f1': 0.9323164918970448, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9191489361702128, 'recall': 0.9337175792507204, 'f1': 0.9263759828448892, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924380704041721, 'recall': 0.9304461942257218, 'f1': 0.9274035317200785, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9553314121037464, 'recall': 0.9778761061946902, 'f1': 0.9664723032069971, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9384164222873901, 'recall': 0.9467455621301775, 'f1': 0.9425625920471281, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8923357664233577, 'recall': 0.9421965317919075, 'f1': 0.9165885660731022, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8923357664233577, 'recall': 0.9721669980119284, 'f1': 0.9305423406279734, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9199438202247191, 'recall': 0.9438040345821326, 'f1': 0.9317211948790898, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.926923076923077, 'recall': 0.9488188976377953, 'f1': 0.9377431906614787, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608127721335269, 'recall': 0.976401179941003, 'f1': 0.9685442574981712, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9502196193265008, 'recall': 0.9600591715976331, 'f1': 0.9551140544518028, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9297912713472486, 'recall': 0.9441233140655106, 'f1': 0.936902485659656, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9297912713472486, 'recall': 0.974155069582505, 'f1': 0.9514563106796117, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18181818181818182, 'recall': 0.26666666666666666, 'f1': 0.21621621621621623, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.32608695652173914, 'recall': 0.45454545454545453, 'f1': 0.379746835443038, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9392655367231638, 'recall': 0.9582132564841499, 'f1': 0.9486447931526392, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9392764857881137, 'recall': 0.9540682414698163, 'f1': 0.9466145833333334, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9696531791907514, 'recall': 0.9896755162241888, 'f1': 0.9795620437956204, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9648093841642229, 'recall': 0.9733727810650887, 'f1': 0.9690721649484536, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9193245778611632, 'recall': 0.9441233140655106, 'f1': 0.9315589353612168, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9193245778611632, 'recall': 0.974155069582505, 'f1': 0.9459459459459459, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23333333333333334, 'recall': 0.23333333333333334, 'f1': 0.23333333333333334, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3137254901960784, 'recall': 0.48484848484848486, 'f1': 0.380952380952381, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9417613636363636, 'recall': 0.9553314121037464, 'f1': 0.9484978540772532, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.943078913324709, 'recall': 0.9566929133858267, 'f1': 0.9498371335504886, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9649122807017544, 'recall': 0.9763313609467456, 'f1': 0.9705882352941176, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9319470699432892, 'recall': 0.9499036608863198, 'f1': 0.9408396946564885, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9319470699432892, 'recall': 0.9801192842942346, 'f1': 0.9554263565891473, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.32, 'recall': 0.26666666666666666, 'f1': 0.2909090909090909, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3018867924528302, 'recall': 0.48484848484848486, 'f1': 0.37209302325581395, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.5, 'f1': 0.42857142857142855, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9394366197183098, 'recall': 0.9610951008645533, 'f1': 0.9501424501424501, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9284802043422733, 'recall': 0.9540682414698163, 'f1': 0.9411003236245955, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852724594992637, 'recall': 0.9867256637168141, 'f1': 0.9859985261606484, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9631268436578171, 'recall': 0.9659763313609467, 'f1': 0.9645494830132939, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924812030075188, 'recall': 0.9781312127236581, 'f1': 0.9507246376811596, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2903225806451613, 'recall': 0.3, 'f1': 0.29508196721311475, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.48, 'recall': 0.7272727272727273, 'f1': 0.5783132530120482, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9574468085106383, 'recall': 0.9726224783861671, 'f1': 0.9649749821300929, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795021961932651, 'recall': 0.9867256637168141, 'f1': 0.9831006612784717, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9632892804698973, 'recall': 0.9704142011834319, 'f1': 0.9668386145910095, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9152542372881356, 'recall': 0.9364161849710982, 'f1': 0.9257142857142857, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9344894026974951, 'recall': 0.9642147117296223, 'f1': 0.9491193737769079, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.08333333333333333, 'recall': 0.0625, 'f1': 0.07142857142857144, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2619047619047619, 'recall': 0.36666666666666664, 'f1': 0.3055555555555555, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5813953488372093, 'recall': 0.7575757575757576, 'f1': 0.6578947368421053, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9332477535301669, 'recall': 0.9540682414698163, 'f1': 0.9435431537962362, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9767441860465116, 'recall': 0.9911504424778761, 'f1': 0.9838945827232797, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.973568281938326, 'recall': 0.9807692307692307, 'f1': 0.9771554900515844, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.917910447761194, 'recall': 0.9479768786127167, 'f1': 0.9327014218009477, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9352380952380952, 'recall': 0.9761431411530815, 'f1': 0.9552529182879377, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.09090909090909091, 'recall': 0.0625, 'f1': 0.07407407407407407, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.30303030303030304, 'recall': 0.3333333333333333, 'f1': 0.31746031746031744, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544159544159544, 'recall': 0.9654178674351584, 'f1': 0.9598853868194842, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9406451612903226, 'recall': 0.9566929133858267, 'f1': 0.9486011711125569, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9325842696629213, 'recall': 0.9595375722543352, 'f1': 0.9458689458689458, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9408396946564885, 'recall': 0.9801192842942346, 'f1': 0.9600778967867575, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3125, 'f1': 0.38461538461538464, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38235294117647056, 'recall': 0.43333333333333335, 'f1': 0.40625, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9446589446589446, 'recall': 0.963254593175853, 'f1': 0.9538661468486029, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764359351988218, 'recall': 0.9807692307692307, 'f1': 0.9785977859778597, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9116022099447514, 'recall': 0.953757225433526, 'f1': 0.9322033898305084, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9371428571428572, 'recall': 0.9781312127236581, 'f1': 0.9571984435797665, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.1875, 'f1': 0.17647058823529413, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35294117647058826, 'recall': 0.4, 'f1': 0.37500000000000006, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7941176470588235, 'recall': 0.8181818181818182, 'f1': 0.8059701492537314, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9449929478138223, 'recall': 0.9654178674351584, 'f1': 0.955096222380613, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544863459037711, 'recall': 0.963254593175853, 'f1': 0.9588504245591117, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9690721649484536, 'recall': 0.9733727810650887, 'f1': 0.9712177121771217, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9330855018587361, 'recall': 0.9672447013487476, 'f1': 0.9498580889309367, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36, 'recall': 0.5625, 'f1': 0.43902439024390244, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5135135135135135, 'recall': 0.6333333333333333, 'f1': 0.5671641791044775, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527220630372493, 'recall': 0.9582132564841499, 'f1': 0.9554597701149425, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.937984496124031, 'recall': 0.952755905511811, 'f1': 0.9453125, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9735294117647059, 'recall': 0.9792899408284024, 'f1': 0.9764011799410028, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9397363465160076, 'recall': 0.9614643545279383, 'f1': 0.9504761904761905, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9571150097465887, 'recall': 0.9761431411530815, 'f1': 0.9665354330708661, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4444444444444444, 'recall': 0.5, 'f1': 0.47058823529411764, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.41025641025641024, 'recall': 0.5333333333333333, 'f1': 0.463768115942029, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9494163424124513, 'recall': 0.9606299212598425, 'f1': 0.9549902152641879, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780058651026393, 'recall': 0.9866863905325444, 'f1': 0.9823269513991164, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9343339587242027, 'recall': 0.9595375722543352, 'f1': 0.9467680608365019, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9464627151051626, 'recall': 0.9840954274353877, 'f1': 0.9649122807017545, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.1875, 'f1': 0.23076923076923075, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.43333333333333335, 'recall': 0.43333333333333335, 'f1': 0.43333333333333335, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1': 0.955223880597015, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.948936170212766, 'recall': 0.9639769452449568, 'f1': 0.956397426733381, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9407216494845361, 'recall': 0.958005249343832, 'f1': 0.9492847854356307, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9307116104868914, 'recall': 0.9576107899807321, 'f1': 0.9439696106362773, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9625984251968503, 'recall': 0.9721669980119284, 'f1': 0.9673590504451038, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3076923076923077, 'recall': 0.5, 'f1': 0.380952380952381, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9600570613409415, 'recall': 0.9697406340057637, 'f1': 0.9648745519713262, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9752186588921283, 'recall': 0.9867256637168141, 'f1': 0.9809384164222874, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9911242603550295, 'f1': 0.9867452135493372, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9338374291115312, 'recall': 0.9518304431599229, 'f1': 0.9427480916030534, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9371428571428572, 'recall': 0.9781312127236581, 'f1': 0.9571984435797665, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.125, 'f1': 0.2, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.4666666666666667, 'f1': 0.4827586206896552, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9587482219061166, 'recall': 0.9711815561959655, 'f1': 0.964924838940587, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.95822454308094, 'recall': 0.963254593175853, 'f1': 0.9607329842931936, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9545454545454546, 'recall': 0.9710982658959537, 'f1': 0.9627507163323782, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9631067961165048, 'recall': 0.9860834990059643, 'f1': 0.9744597249508842, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6153846153846154, 'recall': 0.5, 'f1': 0.5517241379310345, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9602836879432625, 'recall': 0.9755043227665706, 'f1': 0.9678341672623302, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953307392996109, 'recall': 0.9645669291338582, 'f1': 0.9589041095890412, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.981021897810219, 'recall': 0.9911504424778761, 'f1': 0.9860601614086574, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943289224952741, 'recall': 0.9614643545279383, 'f1': 0.9522900763358778, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5555555555555556, 'recall': 0.625, 'f1': 0.5882352941176471, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.41304347826086957, 'recall': 0.6333333333333333, 'f1': 0.5, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601139601139601, 'recall': 0.9711815561959655, 'f1': 0.9656160458452723, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9378531073446328, 'recall': 0.9595375722543352, 'f1': 0.9485714285714286, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9460500963391136, 'recall': 0.9761431411530815, 'f1': 0.9608610567514677, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5833333333333334, 'recall': 0.4375, 'f1': 0.5, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5333333333333333, 'f1': 0.47058823529411764, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9533239038189534, 'recall': 0.9711815561959655, 'f1': 0.9621698786581013, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9432989690721649, 'recall': 0.9606299212598425, 'f1': 0.951885565669701, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.979381443298969, 'recall': 0.9837278106508875, 'f1': 0.981549815498155, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9380863039399625, 'recall': 0.9633911368015414, 'f1': 0.9505703422053231, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9515503875968992, 'recall': 0.9761431411530815, 'f1': 0.9636898920510304, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5294117647058824, 'recall': 0.5625, 'f1': 0.5454545454545455, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3137254901960784, 'recall': 0.5333333333333333, 'f1': 0.3950617283950617, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9354838709677419, 'recall': 0.8787878787878788, 'f1': 0.90625, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.5, 'f1': 0.37499999999999994, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9458064516129032, 'recall': 0.9619422572178478, 'f1': 0.9538061158100195, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9572815533980582, 'recall': 0.9801192842942346, 'f1': 0.9685658153241651, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.40476190476190477, 'recall': 0.5666666666666667, 'f1': 0.4722222222222222, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9588068181818182, 'recall': 0.9726224783861671, 'f1': 0.9656652360515022, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9556135770234987, 'recall': 0.9606299212598425, 'f1': 0.9581151832460733, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500 (score: 0.9680982978243716).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.951764705882353, 'recall': 0.9602373887240356, 'f1': 0.9559822747415067, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8485370051635112, 'recall': 0.9012797074954296, 'f1': 0.874113475177305, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8745454545454545, 'recall': 0.933074684772066, 'f1': 0.9028625058657906, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3870967741935484, 'recall': 0.38095238095238093, 'f1': 0.384, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25862068965517243, 'recall': 0.379746835443038, 'f1': 0.3076923076923077, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8444444444444444, 'recall': 0.8837209302325582, 'f1': 0.8636363636363636, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5428571428571428, 'recall': 0.5757575757575758, 'f1': 0.5588235294117646, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9365881032547699, 'recall': 0.9553520320549513, 'f1': 0.9458770189855484, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9349015317286652, 'recall': 0.9558165548098434, 'f1': 0.9452433628318584, 'number': 1788}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9873271889400922, 'recall': 0.9788692175899486, 'f1': 0.9830800114711786, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.42857142857142855, 'f1': 0.375, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9911242603550295, 'f1': 0.9867452135493372, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9338374291115312, 'recall': 0.9518304431599229, 'f1': 0.9427480916030534, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9371428571428572, 'recall': 0.9781312127236581, 'f1': 0.9571984435797665, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.125, 'f1': 0.2, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.4666666666666667, 'f1': 0.4827586206896552, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9587482219061166, 'recall': 0.9711815561959655, 'f1': 0.964924838940587, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.95822454308094, 'recall': 0.963254593175853, 'f1': 0.9607329842931936, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-b_PER+O\",\n",
      "    \"2\": \"I-i_PER+O\",\n",
      "    \"3\": \"I-b_PER+b_TITREH\",\n",
      "    \"4\": \"I-i_PER+b_TITREH\",\n",
      "    \"5\": \"I-i_PER+i_TITREH\",\n",
      "    \"6\": \"I-b_ACT+O\",\n",
      "    \"7\": \"I-i_ACT+O\",\n",
      "    \"8\": \"I-b_DESC+O\",\n",
      "    \"9\": \"I-i_DESC+O\",\n",
      "    \"10\": \"I-b_DESC+b_ACT\",\n",
      "    \"11\": \"I-i_DESC+b_ACT\",\n",
      "    \"12\": \"I-i_DESC+i_ACT\",\n",
      "    \"13\": \"I-b_DESC+b_TITREP\",\n",
      "    \"14\": \"I-i_DESC+b_TITREP\",\n",
      "    \"15\": \"I-i_DESC+i_TITREP\",\n",
      "    \"16\": \"I-b_SPAT+O\",\n",
      "    \"17\": \"I-i_SPAT+O\",\n",
      "    \"18\": \"I-b_SPAT+b_LOC\",\n",
      "    \"19\": \"I-i_SPAT+b_LOC\",\n",
      "    \"20\": \"I-i_SPAT+i_LOC\",\n",
      "    \"21\": \"I-b_SPAT+b_CARDINAL\",\n",
      "    \"22\": \"I-i_SPAT+b_CARDINAL\",\n",
      "    \"23\": \"I-i_SPAT+i_CARDINAL\",\n",
      "    \"24\": \"I-b_SPAT+b_FT\",\n",
      "    \"25\": \"I-i_SPAT+b_FT\",\n",
      "    \"26\": \"I-i_SPAT+i_FT\",\n",
      "    \"27\": \"I-b_TITRE+O\",\n",
      "    \"28\": \"I-i_TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-b_ACT+O\": 6,\n",
      "    \"I-b_DESC+O\": 8,\n",
      "    \"I-b_DESC+b_ACT\": 10,\n",
      "    \"I-b_DESC+b_TITREP\": 13,\n",
      "    \"I-b_PER+O\": 1,\n",
      "    \"I-b_PER+b_TITREH\": 3,\n",
      "    \"I-b_SPAT+O\": 16,\n",
      "    \"I-b_SPAT+b_CARDINAL\": 21,\n",
      "    \"I-b_SPAT+b_FT\": 24,\n",
      "    \"I-b_SPAT+b_LOC\": 18,\n",
      "    \"I-b_TITRE+O\": 27,\n",
      "    \"I-i_ACT+O\": 7,\n",
      "    \"I-i_DESC+O\": 9,\n",
      "    \"I-i_DESC+b_ACT\": 11,\n",
      "    \"I-i_DESC+b_TITREP\": 14,\n",
      "    \"I-i_DESC+i_ACT\": 12,\n",
      "    \"I-i_DESC+i_TITREP\": 15,\n",
      "    \"I-i_PER+O\": 2,\n",
      "    \"I-i_PER+b_TITREH\": 4,\n",
      "    \"I-i_PER+i_TITREH\": 5,\n",
      "    \"I-i_SPAT+O\": 17,\n",
      "    \"I-i_SPAT+b_CARDINAL\": 22,\n",
      "    \"I-i_SPAT+b_FT\": 25,\n",
      "    \"I-i_SPAT+b_LOC\": 19,\n",
      "    \"I-i_SPAT+i_CARDINAL\": 23,\n",
      "    \"I-i_SPAT+i_FT\": 26,\n",
      "    \"I-i_SPAT+i_LOC\": 20,\n",
      "    \"I-i_TITRE+O\": 28,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110053661\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2400' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2400/5000 10:29 < 11:22, 3.81 it/s, Epoch 6/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Precision-l1l2</th>\n",
       "      <th>Recall-l1l2</th>\n",
       "      <th>F1-l1l2</th>\n",
       "      <th>Accuracy-l1l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.658431</td>\n",
       "      <td>0.949172</td>\n",
       "      <td>0.933077</td>\n",
       "      <td>0.941056</td>\n",
       "      <td>0.934953</td>\n",
       "      <td>0.917957</td>\n",
       "      <td>0.933858</td>\n",
       "      <td>0.925839</td>\n",
       "      <td>0.945330</td>\n",
       "      <td>0.950272</td>\n",
       "      <td>0.928762</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.940052</td>\n",
       "      <td>0.934451</td>\n",
       "      <td>0.937243</td>\n",
       "      <td>0.952544</td>\n",
       "      <td>0.939865</td>\n",
       "      <td>0.931125</td>\n",
       "      <td>0.935474</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.931885</td>\n",
       "      <td>0.931611</td>\n",
       "      <td>0.931748</td>\n",
       "      <td>0.956340</td>\n",
       "      <td>{'precision': 0.935672514619883, 'recall': 0.9467455621301775, 'f1': 0.9411764705882353, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8923933209647495, 'recall': 0.9267822736030829, 'f1': 0.9092627599243858, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8923933209647495, 'recall': 0.9562624254473161, 'f1': 0.9232245681381958, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9202797202797203, 'recall': 0.9481268011527377, 'f1': 0.9339957416607523, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9456662354463131, 'recall': 0.9593175853018373, 'f1': 0.9524429967426711, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9553956834532374, 'recall': 0.9793510324483776, 'f1': 0.9672250546249092, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>0.950262</td>\n",
       "      <td>0.941669</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.942546</td>\n",
       "      <td>0.912933</td>\n",
       "      <td>0.941207</td>\n",
       "      <td>0.926854</td>\n",
       "      <td>0.950266</td>\n",
       "      <td>0.951403</td>\n",
       "      <td>0.925433</td>\n",
       "      <td>0.938238</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>0.947878</td>\n",
       "      <td>0.948231</td>\n",
       "      <td>0.948054</td>\n",
       "      <td>0.960643</td>\n",
       "      <td>0.940649</td>\n",
       "      <td>0.944202</td>\n",
       "      <td>0.942422</td>\n",
       "      <td>0.943305</td>\n",
       "      <td>0.929343</td>\n",
       "      <td>0.934253</td>\n",
       "      <td>0.931792</td>\n",
       "      <td>0.958998</td>\n",
       "      <td>{'precision': 0.9213973799126638, 'recall': 0.9363905325443787, 'f1': 0.9288334556126193, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8896925858951176, 'recall': 0.9479768786127167, 'f1': 0.917910447761194, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8896925858951176, 'recall': 0.9781312127236581, 'f1': 0.9318181818181819, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.05, 'recall': 0.03333333333333333, 'f1': 0.04, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9474431818181818, 'recall': 0.9610951008645533, 'f1': 0.9542203147353361, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9393548387096774, 'recall': 0.9553805774278216, 'f1': 0.9472999349381913, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9664233576642336, 'recall': 0.976401179941003, 'f1': 0.9713866471019809, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269978</td>\n",
       "      <td>0.953689</td>\n",
       "      <td>0.949808</td>\n",
       "      <td>0.951744</td>\n",
       "      <td>0.952797</td>\n",
       "      <td>0.932752</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>0.943161</td>\n",
       "      <td>0.961149</td>\n",
       "      <td>0.931968</td>\n",
       "      <td>0.939414</td>\n",
       "      <td>0.935676</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.955202</td>\n",
       "      <td>0.960894</td>\n",
       "      <td>0.958039</td>\n",
       "      <td>0.973045</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.949724</td>\n",
       "      <td>0.943963</td>\n",
       "      <td>0.953176</td>\n",
       "      <td>0.932409</td>\n",
       "      <td>0.947461</td>\n",
       "      <td>0.939875</td>\n",
       "      <td>0.966654</td>\n",
       "      <td>{'precision': 0.9549418604651163, 'recall': 0.9718934911242604, 'f1': 0.9633431085043989, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9176029962546817, 'recall': 0.9441233140655106, 'f1': 0.9306742640075975, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9176029962546817, 'recall': 0.974155069582505, 'f1': 0.9450337512054002, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.043478260869565216, 'recall': 0.03333333333333333, 'f1': 0.03773584905660378, 'number': 30}</td>\n",
       "      <td>{'precision': 0.23728813559322035, 'recall': 0.42424242424242425, 'f1': 0.30434782608695654, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.16666666666666666, 'f1': 0.25, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9516358463726885, 'recall': 0.9639769452449568, 'f1': 0.9577666428060129, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9440104166666666, 'recall': 0.9514435695538058, 'f1': 0.9477124183006537, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219882</td>\n",
       "      <td>0.960932</td>\n",
       "      <td>0.950938</td>\n",
       "      <td>0.955909</td>\n",
       "      <td>0.953809</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.944473</td>\n",
       "      <td>0.963174</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.942077</td>\n",
       "      <td>0.942705</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.971653</td>\n",
       "      <td>0.947460</td>\n",
       "      <td>0.953793</td>\n",
       "      <td>0.950615</td>\n",
       "      <td>0.954442</td>\n",
       "      <td>0.937953</td>\n",
       "      <td>0.949516</td>\n",
       "      <td>0.943699</td>\n",
       "      <td>0.968742</td>\n",
       "      <td>{'precision': 0.9720588235294118, 'recall': 0.977810650887574, 'f1': 0.9749262536873157, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9261363636363636, 'recall': 0.9421965317919075, 'f1': 0.9340974212034383, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9261363636363636, 'recall': 0.9721669980119284, 'f1': 0.9485935984481086, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.18421052631578946, 'recall': 0.23333333333333334, 'f1': 0.20588235294117646, 'number': 30}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.42424242424242425, 'f1': 0.34146341463414637, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9431009957325747, 'recall': 0.9553314121037464, 'f1': 0.9491768074445239, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9577836411609498, 'recall': 0.952755905511811, 'f1': 0.9552631578947368, 'number': 762}</td>\n",
       "      <td>{'precision': 0.978134110787172, 'recall': 0.9896755162241888, 'f1': 0.9838709677419354, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.203515</td>\n",
       "      <td>0.959221</td>\n",
       "      <td>0.957269</td>\n",
       "      <td>0.958244</td>\n",
       "      <td>0.956846</td>\n",
       "      <td>0.944272</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.963554</td>\n",
       "      <td>0.947438</td>\n",
       "      <td>0.948069</td>\n",
       "      <td>0.947754</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>0.961467</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.963967</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.952615</td>\n",
       "      <td>0.958152</td>\n",
       "      <td>0.955375</td>\n",
       "      <td>0.957099</td>\n",
       "      <td>0.945655</td>\n",
       "      <td>0.955092</td>\n",
       "      <td>0.950350</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>{'precision': 0.9678832116788321, 'recall': 0.9807692307692307, 'f1': 0.9742836149889786, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9300567107750473, 'recall': 0.9479768786127167, 'f1': 0.9389312977099237, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9300567107750473, 'recall': 0.9781312127236581, 'f1': 0.9534883720930233, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.30434782608695654, 'recall': 0.23333333333333334, 'f1': 0.26415094339622636, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5217391304347826, 'recall': 0.7272727272727273, 'f1': 0.6075949367088608, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9529243937232525, 'recall': 0.962536023054755, 'f1': 0.9577060931899642, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9466840052015605, 'recall': 0.9553805774278216, 'f1': 0.9510124101894186, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.194232</td>\n",
       "      <td>0.954095</td>\n",
       "      <td>0.958625</td>\n",
       "      <td>0.956355</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.939753</td>\n",
       "      <td>0.958005</td>\n",
       "      <td>0.948791</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.955393</td>\n",
       "      <td>0.952223</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>0.964246</td>\n",
       "      <td>0.959244</td>\n",
       "      <td>0.973804</td>\n",
       "      <td>0.946961</td>\n",
       "      <td>0.959895</td>\n",
       "      <td>0.953384</td>\n",
       "      <td>0.956846</td>\n",
       "      <td>0.943833</td>\n",
       "      <td>0.956854</td>\n",
       "      <td>0.950299</td>\n",
       "      <td>0.968679</td>\n",
       "      <td>{'precision': 0.9618768328445748, 'recall': 0.9704142011834319, 'f1': 0.9661266568483062, 'number': 676}</td>\n",
       "      <td>{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}</td>\n",
       "      <td>{'precision': 0.924812030075188, 'recall': 0.9781312127236581, 'f1': 0.9507246376811596, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.16, 'recall': 0.13333333333333333, 'f1': 0.14545454545454545, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5813953488372093, 'recall': 0.7575757575757576, 'f1': 0.6578947368421053, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9509043927648578, 'recall': 0.9658792650918635, 'f1': 0.9583333333333334, 'number': 762}</td>\n",
       "      <td>{'precision': 0.978134110787172, 'recall': 0.9896755162241888, 'f1': 0.9838709677419354, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.168263</td>\n",
       "      <td>0.961686</td>\n",
       "      <td>0.964730</td>\n",
       "      <td>0.963205</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>0.955890</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.961378</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>0.949208</td>\n",
       "      <td>0.958056</td>\n",
       "      <td>0.953612</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.965543</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.968053</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.956297</td>\n",
       "      <td>0.966579</td>\n",
       "      <td>0.961411</td>\n",
       "      <td>0.960643</td>\n",
       "      <td>0.952948</td>\n",
       "      <td>0.963017</td>\n",
       "      <td>0.957956</td>\n",
       "      <td>0.970197</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9517374517374517, 'recall': 0.9801192842942346, 'f1': 0.9657198824681684, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3076923076923077, 'recall': 0.25, 'f1': 0.27586206896551724, 'number': 16}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9626972740315638, 'recall': 0.9668587896253602, 'f1': 0.9647735442127965, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9482535575679172, 'recall': 0.9619422572178478, 'f1': 0.9550488599348534, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.152068</td>\n",
       "      <td>0.959262</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.961426</td>\n",
       "      <td>0.958492</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.946711</td>\n",
       "      <td>0.958056</td>\n",
       "      <td>0.952349</td>\n",
       "      <td>0.972032</td>\n",
       "      <td>0.965913</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.968425</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.959504</td>\n",
       "      <td>0.950507</td>\n",
       "      <td>0.963898</td>\n",
       "      <td>0.957155</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9288389513108615, 'recall': 0.9556840077071291, 'f1': 0.9420702754036088, 'number': 519}</td>\n",
       "      <td>{'precision': 0.948076923076923, 'recall': 0.9801192842942346, 'f1': 0.9638318670576735, 'number': 503}</td>\n",
       "      <td>{'precision': 0.21428571428571427, 'recall': 0.1875, 'f1': 0.19999999999999998, 'number': 16}</td>\n",
       "      <td>{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7631578947368421, 'recall': 0.8787878787878788, 'f1': 0.8169014084507042, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.159765</td>\n",
       "      <td>0.958436</td>\n",
       "      <td>0.964504</td>\n",
       "      <td>0.961460</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.948427</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.956816</td>\n",
       "      <td>0.967477</td>\n",
       "      <td>0.941678</td>\n",
       "      <td>0.956724</td>\n",
       "      <td>0.949141</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>0.960385</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.963238</td>\n",
       "      <td>0.976841</td>\n",
       "      <td>0.949828</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>0.956271</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.961550</td>\n",
       "      <td>0.953434</td>\n",
       "      <td>0.970451</td>\n",
       "      <td>{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9097605893186004, 'recall': 0.9518304431599229, 'f1': 0.9303201506591338, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9384615384615385, 'recall': 0.9701789264413518, 'f1': 0.9540566959921799, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2608695652173913, 'recall': 0.375, 'f1': 0.30769230769230765, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35555555555555557, 'recall': 0.5333333333333333, 'f1': 0.42666666666666675, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9640804597701149, 'recall': 0.9668587896253602, 'f1': 0.9654676258992806, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9404915912031048, 'recall': 0.9540682414698163, 'f1': 0.9472312703583062, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.150607</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.967895</td>\n",
       "      <td>0.963972</td>\n",
       "      <td>0.958365</td>\n",
       "      <td>0.949948</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.958106</td>\n",
       "      <td>0.966338</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.956349</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.961581</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.965504</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.951143</td>\n",
       "      <td>0.967451</td>\n",
       "      <td>0.959228</td>\n",
       "      <td>0.958745</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.964778</td>\n",
       "      <td>0.957332</td>\n",
       "      <td>0.969818</td>\n",
       "      <td>{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9269662921348315, 'recall': 0.953757225433526, 'f1': 0.9401709401709402, 'number': 519}</td>\n",
       "      <td>{'precision': 0.953125, 'recall': 0.9701789264413518, 'f1': 0.961576354679803, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3181818181818182, 'recall': 0.4375, 'f1': 0.3684210526315789, 'number': 16}</td>\n",
       "      <td>{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9614285714285714, 'recall': 0.9697406340057637, 'f1': 0.9655667144906743, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9534282018111255, 'recall': 0.9671916010498688, 'f1': 0.9602605863192182, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.144486</td>\n",
       "      <td>0.960494</td>\n",
       "      <td>0.967443</td>\n",
       "      <td>0.963956</td>\n",
       "      <td>0.955454</td>\n",
       "      <td>0.962038</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.966562</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.954110</td>\n",
       "      <td>0.968109</td>\n",
       "      <td>0.963004</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.966221</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.953036</td>\n",
       "      <td>0.967161</td>\n",
       "      <td>0.960046</td>\n",
       "      <td>0.956214</td>\n",
       "      <td>0.955072</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.961062</td>\n",
       "      <td>0.966085</td>\n",
       "      <td>{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9288389513108615, 'recall': 0.9556840077071291, 'f1': 0.9420702754036088, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9721669980119284, 'recall': 0.9721669980119284, 'f1': 0.9721669980119284, 'number': 503}</td>\n",
       "      <td>{'precision': 0.22580645161290322, 'recall': 0.4375, 'f1': 0.2978723404255319, 'number': 16}</td>\n",
       "      <td>{'precision': 0.41304347826086957, 'recall': 0.6333333333333333, 'f1': 0.5, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9666666666666667, 'recall': 0.8787878787878788, 'f1': 0.9206349206349207, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9655667144906743, 'recall': 0.9697406340057637, 'f1': 0.9676491732566499, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.158978</td>\n",
       "      <td>0.959874</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.963980</td>\n",
       "      <td>0.957732</td>\n",
       "      <td>0.949485</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.958127</td>\n",
       "      <td>0.964566</td>\n",
       "      <td>0.946230</td>\n",
       "      <td>0.960719</td>\n",
       "      <td>0.953419</td>\n",
       "      <td>0.969501</td>\n",
       "      <td>0.964074</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.966760</td>\n",
       "      <td>0.978107</td>\n",
       "      <td>0.953242</td>\n",
       "      <td>0.965708</td>\n",
       "      <td>0.959434</td>\n",
       "      <td>0.958365</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.964191</td>\n",
       "      <td>0.956054</td>\n",
       "      <td>0.967034</td>\n",
       "      <td>{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9114391143911439, 'recall': 0.9518304431599229, 'f1': 0.9311969839773798, 'number': 519}</td>\n",
       "      <td>{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}</td>\n",
       "      <td>{'precision': 0.20833333333333334, 'recall': 0.3125, 'f1': 0.25, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.6, 'f1': 0.48, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.152887</td>\n",
       "      <td>0.964238</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.962035</td>\n",
       "      <td>0.958075</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>0.964816</td>\n",
       "      <td>0.968616</td>\n",
       "      <td>0.951155</td>\n",
       "      <td>0.959387</td>\n",
       "      <td>0.955254</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>0.964776</td>\n",
       "      <td>0.969088</td>\n",
       "      <td>0.966927</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.958766</td>\n",
       "      <td>0.966289</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.955033</td>\n",
       "      <td>0.966246</td>\n",
       "      <td>0.960607</td>\n",
       "      <td>0.971463</td>\n",
       "      <td>{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9327102803738317, 'recall': 0.9614643545279383, 'f1': 0.9468690702087287, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9592233009708738, 'recall': 0.9821073558648111, 'f1': 0.9705304518664047, 'number': 503}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3125, 'f1': 0.2777777777777778, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4473684210526316, 'recall': 0.5666666666666667, 'f1': 0.5, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8787878787878788, 'recall': 0.8787878787878788, 'f1': 0.8787878787878788, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9557867360208062, 'recall': 0.9645669291338582, 'f1': 0.9601567602873938, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9780058651026393, 'recall': 0.9837758112094396, 'f1': 0.9808823529411764, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.159173</td>\n",
       "      <td>0.963845</td>\n",
       "      <td>0.970382</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.959377</td>\n",
       "      <td>0.958549</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>0.966591</td>\n",
       "      <td>0.955116</td>\n",
       "      <td>0.963382</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>0.969248</td>\n",
       "      <td>0.974302</td>\n",
       "      <td>0.971768</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.959207</td>\n",
       "      <td>0.970357</td>\n",
       "      <td>0.964750</td>\n",
       "      <td>0.960137</td>\n",
       "      <td>0.957039</td>\n",
       "      <td>0.967714</td>\n",
       "      <td>0.962347</td>\n",
       "      <td>0.970893</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9329608938547486, 'recall': 0.9653179190751445, 'f1': 0.9488636363636364, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 16}</td>\n",
       "      <td>{'precision': 0.46511627906976744, 'recall': 0.6666666666666666, 'f1': 0.547945205479452, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9640804597701149, 'recall': 0.9668587896253602, 'f1': 0.9654676258992806, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9557291666666666, 'recall': 0.963254593175853, 'f1': 0.9594771241830065, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>0.962905</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.965618</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.947207</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.958506</td>\n",
       "      <td>0.972792</td>\n",
       "      <td>0.954907</td>\n",
       "      <td>0.958722</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.976209</td>\n",
       "      <td>0.963045</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.977221</td>\n",
       "      <td>0.953309</td>\n",
       "      <td>0.967161</td>\n",
       "      <td>0.960185</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.950564</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.957763</td>\n",
       "      <td>0.974500</td>\n",
       "      <td>{'precision': 0.975, 'recall': 0.9807692307692307, 'f1': 0.9778761061946902, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9272388059701493, 'recall': 0.9576107899807321, 'f1': 0.9421800947867298, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9372623574144486, 'recall': 0.9801192842942346, 'f1': 0.9582118561710398, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.25, 'f1': 0.3076923076923077, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}</td>\n",
       "      <td>{'precision': 0.948051948051948, 'recall': 0.958005249343832, 'f1': 0.9530026109660574, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.176770</td>\n",
       "      <td>0.963129</td>\n",
       "      <td>0.968573</td>\n",
       "      <td>0.965844</td>\n",
       "      <td>0.956087</td>\n",
       "      <td>0.960042</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.965553</td>\n",
       "      <td>0.964313</td>\n",
       "      <td>0.948953</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.957096</td>\n",
       "      <td>0.971147</td>\n",
       "      <td>0.963455</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>0.955849</td>\n",
       "      <td>0.968904</td>\n",
       "      <td>0.962332</td>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.955137</td>\n",
       "      <td>0.968594</td>\n",
       "      <td>0.961819</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>{'precision': 0.9736070381231672, 'recall': 0.9822485207100592, 'f1': 0.9779086892488954, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9722222222222222, 'recall': 0.974155069582505, 'f1': 0.9731876861966237, 'number': 503}</td>\n",
       "      <td>{'precision': 0.37037037037037035, 'recall': 0.625, 'f1': 0.4651162790697674, 'number': 16}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9520103761348897, 'recall': 0.963254593175853, 'f1': 0.9575994781474233, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.190637</td>\n",
       "      <td>0.963996</td>\n",
       "      <td>0.968573</td>\n",
       "      <td>0.966279</td>\n",
       "      <td>0.950772</td>\n",
       "      <td>0.960540</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.965805</td>\n",
       "      <td>0.958112</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>0.967223</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.969382</td>\n",
       "      <td>0.976715</td>\n",
       "      <td>0.959436</td>\n",
       "      <td>0.969195</td>\n",
       "      <td>0.964291</td>\n",
       "      <td>0.951658</td>\n",
       "      <td>0.957064</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>0.962650</td>\n",
       "      <td>0.962668</td>\n",
       "      <td>{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9309701492537313, 'recall': 0.9614643545279383, 'f1': 0.9459715639810427, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9607843137254902, 'recall': 0.974155069582505, 'f1': 0.9674234945705825, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34615384615384615, 'recall': 0.5625, 'f1': 0.4285714285714286, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4358974358974359, 'recall': 0.5666666666666667, 'f1': 0.4927536231884058, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}</td>\n",
       "      <td>{'precision': 0.953185955786736, 'recall': 0.9619422572178478, 'f1': 0.9575440888308295, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>0.961048</td>\n",
       "      <td>0.970608</td>\n",
       "      <td>0.965804</td>\n",
       "      <td>0.962794</td>\n",
       "      <td>0.954147</td>\n",
       "      <td>0.972178</td>\n",
       "      <td>0.963079</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>0.947128</td>\n",
       "      <td>0.966045</td>\n",
       "      <td>0.956493</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.962091</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>0.980005</td>\n",
       "      <td>0.952911</td>\n",
       "      <td>0.970357</td>\n",
       "      <td>0.961555</td>\n",
       "      <td>0.963554</td>\n",
       "      <td>0.951051</td>\n",
       "      <td>0.969475</td>\n",
       "      <td>0.960174</td>\n",
       "      <td>0.973361</td>\n",
       "      <td>{'precision': 0.9896602658788775, 'recall': 0.9911242603550295, 'f1': 0.9903917220990391, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9401544401544402, 'recall': 0.9681908548707754, 'f1': 0.9539666993143977, 'number': 503}</td>\n",
       "      <td>{'precision': 0.45454545454545453, 'recall': 0.625, 'f1': 0.5263157894736842, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4523809523809524, 'recall': 0.6333333333333333, 'f1': 0.5277777777777778, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9602272727272727, 'recall': 0.9740634005763689, 'f1': 0.9670958512160228, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9445876288659794, 'recall': 0.9619422572178478, 'f1': 0.953185955786736, 'number': 762}</td>\n",
       "      <td>{'precision': 0.981021897810219, 'recall': 0.9911504424778761, 'f1': 0.9860601614086574, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.966345</td>\n",
       "      <td>0.973773</td>\n",
       "      <td>0.970045</td>\n",
       "      <td>0.963427</td>\n",
       "      <td>0.962176</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.968449</td>\n",
       "      <td>0.970767</td>\n",
       "      <td>0.951444</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.958361</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.967086</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.970495</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>0.966801</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.957441</td>\n",
       "      <td>0.970649</td>\n",
       "      <td>0.963999</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>{'precision': 0.982274741506647, 'recall': 0.9837278106508875, 'f1': 0.9830007390983001, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9511278195488722, 'recall': 0.9749518304431599, 'f1': 0.9628924833491912, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9705882352941176, 'recall': 0.9840954274353877, 'f1': 0.9772951628825272, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.6875, 'f1': 0.5789473684210527, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5121951219512195, 'recall': 0.7, 'f1': 0.5915492957746479, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9629629629629629, 'recall': 0.9740634005763689, 'f1': 0.9684813753581661, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9446589446589446, 'recall': 0.963254593175853, 'f1': 0.9538661468486029, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.162847</td>\n",
       "      <td>0.967132</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.969205</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.962675</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.968701</td>\n",
       "      <td>0.971147</td>\n",
       "      <td>0.958388</td>\n",
       "      <td>0.966045</td>\n",
       "      <td>0.962202</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.969607</td>\n",
       "      <td>0.974302</td>\n",
       "      <td>0.971949</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.962547</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.960790</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.973741</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9453860640301318, 'recall': 0.9672447013487476, 'f1': 0.9561904761904761, 'number': 519}</td>\n",
       "      <td>{'precision': 0.96484375, 'recall': 0.9821073558648111, 'f1': 0.9733990147783251, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5135135135135135, 'recall': 0.6333333333333333, 'f1': 0.5671641791044775, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9571428571428572, 'recall': 0.9671916010498688, 'f1': 0.9621409921671019, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.964584</td>\n",
       "      <td>0.966765</td>\n",
       "      <td>0.965673</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.955510</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.962480</td>\n",
       "      <td>0.971653</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.968113</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.970271</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.959378</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.965199</td>\n",
       "      <td>0.954493</td>\n",
       "      <td>0.966539</td>\n",
       "      <td>0.960478</td>\n",
       "      <td>0.974690</td>\n",
       "      <td>{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4117647058823529, 'recall': 0.4375, 'f1': 0.42424242424242425, 'number': 16}</td>\n",
       "      <td>{'precision': 0.36585365853658536, 'recall': 0.5, 'f1': 0.4225352112676056, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.23076923076923078, 'recall': 0.5, 'f1': 0.3157894736842105, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9657631954350927, 'recall': 0.9755043227665706, 'f1': 0.9706093189964158, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9532467532467532, 'recall': 0.963254593175853, 'f1': 0.9582245430809399, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.176859</td>\n",
       "      <td>0.963212</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.967008</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.959606</td>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.966111</td>\n",
       "      <td>0.968109</td>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.967377</td>\n",
       "      <td>0.959709</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>0.975047</td>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.979119</td>\n",
       "      <td>0.959266</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.965497</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.956321</td>\n",
       "      <td>0.970355</td>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9328358208955224, 'recall': 0.9633911368015414, 'f1': 0.9478672985781991, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9627450980392157, 'recall': 0.9761431411530815, 'f1': 0.9693978282329714, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34615384615384615, 'recall': 0.5625, 'f1': 0.4285714285714286, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4318181818181818, 'recall': 0.6333333333333333, 'f1': 0.5135135135135135, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.960520</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.964306</td>\n",
       "      <td>0.956214</td>\n",
       "      <td>0.956477</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.951380</td>\n",
       "      <td>0.964048</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.963045</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.977221</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.968033</td>\n",
       "      <td>0.960773</td>\n",
       "      <td>0.956720</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.966833</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.967666</td>\n",
       "      <td>{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9219330855018587, 'recall': 0.9556840077071291, 'f1': 0.9385052034058656, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9475728155339805, 'recall': 0.9701789264413518, 'f1': 0.9587426326129667, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 30}</td>\n",
       "      <td>{'precision': 0.96875, 'recall': 0.9393939393939394, 'f1': 0.9538461538461539, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9482535575679172, 'recall': 0.9619422572178478, 'f1': 0.9550488599348534, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.195367</td>\n",
       "      <td>0.960771</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.964881</td>\n",
       "      <td>0.958492</td>\n",
       "      <td>0.957513</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.963755</td>\n",
       "      <td>0.965705</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.956349</td>\n",
       "      <td>0.972792</td>\n",
       "      <td>0.963059</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.966988</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>0.955562</td>\n",
       "      <td>0.968614</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.966833</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.969248</td>\n",
       "      <td>{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9607843137254902, 'recall': 0.974155069582505, 'f1': 0.9674234945705825, 'number': 503}</td>\n",
       "      <td>{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}</td>\n",
       "      <td>{'precision': 0.45, 'recall': 0.6, 'f1': 0.5142857142857143, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935672514619883, 'recall': 0.9467455621301775, 'f1': 0.9411764705882353, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8923933209647495, 'recall': 0.9267822736030829, 'f1': 0.9092627599243858, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8923933209647495, 'recall': 0.9562624254473161, 'f1': 0.9232245681381958, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9202797202797203, 'recall': 0.9481268011527377, 'f1': 0.9339957416607523, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456662354463131, 'recall': 0.9593175853018373, 'f1': 0.9524429967426711, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9553956834532374, 'recall': 0.9793510324483776, 'f1': 0.9672250546249092, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9213973799126638, 'recall': 0.9363905325443787, 'f1': 0.9288334556126193, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8896925858951176, 'recall': 0.9479768786127167, 'f1': 0.917910447761194, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8896925858951176, 'recall': 0.9781312127236581, 'f1': 0.9318181818181819, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.05, 'recall': 0.03333333333333333, 'f1': 0.04, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9474431818181818, 'recall': 0.9610951008645533, 'f1': 0.9542203147353361, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393548387096774, 'recall': 0.9553805774278216, 'f1': 0.9472999349381913, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9664233576642336, 'recall': 0.976401179941003, 'f1': 0.9713866471019809, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9549418604651163, 'recall': 0.9718934911242604, 'f1': 0.9633431085043989, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9176029962546817, 'recall': 0.9441233140655106, 'f1': 0.9306742640075975, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9176029962546817, 'recall': 0.974155069582505, 'f1': 0.9450337512054002, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.043478260869565216, 'recall': 0.03333333333333333, 'f1': 0.03773584905660378, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23728813559322035, 'recall': 0.42424242424242425, 'f1': 0.30434782608695654, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.16666666666666666, 'f1': 0.25, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9516358463726885, 'recall': 0.9639769452449568, 'f1': 0.9577666428060129, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9440104166666666, 'recall': 0.9514435695538058, 'f1': 0.9477124183006537, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720588235294118, 'recall': 0.977810650887574, 'f1': 0.9749262536873157, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9261363636363636, 'recall': 0.9421965317919075, 'f1': 0.9340974212034383, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9261363636363636, 'recall': 0.9721669980119284, 'f1': 0.9485935984481086, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18421052631578946, 'recall': 0.23333333333333334, 'f1': 0.20588235294117646, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.42424242424242425, 'f1': 0.34146341463414637, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431009957325747, 'recall': 0.9553314121037464, 'f1': 0.9491768074445239, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9577836411609498, 'recall': 0.952755905511811, 'f1': 0.9552631578947368, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.978134110787172, 'recall': 0.9896755162241888, 'f1': 0.9838709677419354, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.14285714285714285, 'f1': 0.25, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9678832116788321, 'recall': 0.9807692307692307, 'f1': 0.9742836149889786, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9300567107750473, 'recall': 0.9479768786127167, 'f1': 0.9389312977099237, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9300567107750473, 'recall': 0.9781312127236581, 'f1': 0.9534883720930233, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.30434782608695654, 'recall': 0.23333333333333334, 'f1': 0.26415094339622636, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5217391304347826, 'recall': 0.7272727272727273, 'f1': 0.6075949367088608, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529243937232525, 'recall': 0.962536023054755, 'f1': 0.9577060931899642, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9466840052015605, 'recall': 0.9553805774278216, 'f1': 0.9510124101894186, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9618768328445748, 'recall': 0.9704142011834319, 'f1': 0.9661266568483062, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924812030075188, 'recall': 0.9479768786127167, 'f1': 0.9362511893434823, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924812030075188, 'recall': 0.9781312127236581, 'f1': 0.9507246376811596, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16, 'recall': 0.13333333333333333, 'f1': 0.14545454545454545, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5813953488372093, 'recall': 0.7575757575757576, 'f1': 0.6578947368421053, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.957325746799431, 'recall': 0.9697406340057637, 'f1': 0.9634931997136722, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9509043927648578, 'recall': 0.9658792650918635, 'f1': 0.9583333333333334, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.978134110787172, 'recall': 0.9896755162241888, 'f1': 0.9838709677419354, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9517374517374517, 'recall': 0.9801192842942346, 'f1': 0.9657198824681684, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3076923076923077, 'recall': 0.25, 'f1': 0.27586206896551724, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9626972740315638, 'recall': 0.9668587896253602, 'f1': 0.9647735442127965, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482535575679172, 'recall': 0.9619422572178478, 'f1': 0.9550488599348534, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9288389513108615, 'recall': 0.9556840077071291, 'f1': 0.9420702754036088, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.948076923076923, 'recall': 0.9801192842942346, 'f1': 0.9638318670576735, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.21428571428571427, 'recall': 0.1875, 'f1': 0.19999999999999998, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7631578947368421, 'recall': 0.8787878787878788, 'f1': 0.8169014084507042, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793510324483776, 'recall': 0.9822485207100592, 'f1': 0.9807976366322009, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9097605893186004, 'recall': 0.9518304431599229, 'f1': 0.9303201506591338, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9384615384615385, 'recall': 0.9701789264413518, 'f1': 0.9540566959921799, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2608695652173913, 'recall': 0.375, 'f1': 0.30769230769230765, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35555555555555557, 'recall': 0.5333333333333333, 'f1': 0.42666666666666675, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9640804597701149, 'recall': 0.9668587896253602, 'f1': 0.9654676258992806, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9404915912031048, 'recall': 0.9540682414698163, 'f1': 0.9472312703583062, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9269662921348315, 'recall': 0.953757225433526, 'f1': 0.9401709401709402, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953125, 'recall': 0.9701789264413518, 'f1': 0.961576354679803, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3181818181818182, 'recall': 0.4375, 'f1': 0.3684210526315789, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.375, 'recall': 0.6, 'f1': 0.4615384615384615, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614285714285714, 'recall': 0.9697406340057637, 'f1': 0.9655667144906743, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9534282018111255, 'recall': 0.9671916010498688, 'f1': 0.9602605863192182, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9881831610044313, 'recall': 0.9896449704142012, 'f1': 0.9889135254988912, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9288389513108615, 'recall': 0.9556840077071291, 'f1': 0.9420702754036088, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9721669980119284, 'recall': 0.9721669980119284, 'f1': 0.9721669980119284, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.22580645161290322, 'recall': 0.4375, 'f1': 0.2978723404255319, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.41304347826086957, 'recall': 0.6333333333333333, 'f1': 0.5, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9666666666666667, 'recall': 0.8787878787878788, 'f1': 0.9206349206349207, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9655667144906743, 'recall': 0.9697406340057637, 'f1': 0.9676491732566499, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.976401179941003, 'recall': 0.9792899408284024, 'f1': 0.9778434268833086, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9114391143911439, 'recall': 0.9518304431599229, 'f1': 0.9311969839773798, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944015444015444, 'recall': 0.9721669980119284, 'f1': 0.9578844270323212, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.20833333333333334, 'recall': 0.3125, 'f1': 0.25, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.6, 'f1': 0.48, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9628040057224606, 'recall': 0.9697406340057637, 'f1': 0.9662598707824839, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9327102803738317, 'recall': 0.9614643545279383, 'f1': 0.9468690702087287, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9592233009708738, 'recall': 0.9821073558648111, 'f1': 0.9705304518664047, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3125, 'f1': 0.2777777777777778, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4473684210526316, 'recall': 0.5666666666666667, 'f1': 0.5, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8787878787878788, 'recall': 0.8787878787878788, 'f1': 0.8787878787878788, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557867360208062, 'recall': 0.9645669291338582, 'f1': 0.9601567602873938, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9780058651026393, 'recall': 0.9837758112094396, 'f1': 0.9808823529411764, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9329608938547486, 'recall': 0.9653179190751445, 'f1': 0.9488636363636364, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.46511627906976744, 'recall': 0.6666666666666666, 'f1': 0.547945205479452, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9640804597701149, 'recall': 0.9668587896253602, 'f1': 0.9654676258992806, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9557291666666666, 'recall': 0.963254593175853, 'f1': 0.9594771241830065, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.975, 'recall': 0.9807692307692307, 'f1': 0.9778761061946902, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9272388059701493, 'recall': 0.9576107899807321, 'f1': 0.9421800947867298, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9372623574144486, 'recall': 0.9801192842942346, 'f1': 0.9582118561710398, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.25, 'f1': 0.3076923076923077, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629101283880172, 'recall': 0.9726224783861671, 'f1': 0.967741935483871, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.948051948051948, 'recall': 0.958005249343832, 'f1': 0.9530026109660574, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736070381231672, 'recall': 0.9822485207100592, 'f1': 0.9779086892488954, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9722222222222222, 'recall': 0.974155069582505, 'f1': 0.9731876861966237, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37037037037037035, 'recall': 0.625, 'f1': 0.4651162790697674, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.6, 'f1': 0.5, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9520103761348897, 'recall': 0.963254593175853, 'f1': 0.9575994781474233, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9309701492537313, 'recall': 0.9614643545279383, 'f1': 0.9459715639810427, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9607843137254902, 'recall': 0.974155069582505, 'f1': 0.9674234945705825, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34615384615384615, 'recall': 0.5625, 'f1': 0.4285714285714286, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4358974358974359, 'recall': 0.5666666666666667, 'f1': 0.4927536231884058, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.953185955786736, 'recall': 0.9619422572178478, 'f1': 0.9575440888308295, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896602658788775, 'recall': 0.9911242603550295, 'f1': 0.9903917220990391, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9203703703703704, 'recall': 0.9576107899807321, 'f1': 0.9386213408876298, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9401544401544402, 'recall': 0.9681908548707754, 'f1': 0.9539666993143977, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45454545454545453, 'recall': 0.625, 'f1': 0.5263157894736842, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4523809523809524, 'recall': 0.6333333333333333, 'f1': 0.5277777777777778, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8888888888888888, 'recall': 0.9696969696969697, 'f1': 0.927536231884058, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9602272727272727, 'recall': 0.9740634005763689, 'f1': 0.9670958512160228, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9445876288659794, 'recall': 0.9619422572178478, 'f1': 0.953185955786736, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.981021897810219, 'recall': 0.9911504424778761, 'f1': 0.9860601614086574, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.982274741506647, 'recall': 0.9837278106508875, 'f1': 0.9830007390983001, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9511278195488722, 'recall': 0.9749518304431599, 'f1': 0.9628924833491912, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705882352941176, 'recall': 0.9840954274353877, 'f1': 0.9772951628825272, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6875, 'f1': 0.5789473684210527, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5121951219512195, 'recall': 0.7, 'f1': 0.5915492957746479, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629629629629629, 'recall': 0.9740634005763689, 'f1': 0.9684813753581661, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9446589446589446, 'recall': 0.963254593175853, 'f1': 0.9538661468486029, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9453860640301318, 'recall': 0.9672447013487476, 'f1': 0.9561904761904761, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.96484375, 'recall': 0.9821073558648111, 'f1': 0.9733990147783251, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5135135135135135, 'recall': 0.6333333333333333, 'f1': 0.5671641791044775, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9671428571428572, 'recall': 0.9755043227665706, 'f1': 0.9713055954088954, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9571428571428572, 'recall': 0.9671916010498688, 'f1': 0.9621409921671019, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.2857142857142857, 'f1': 0.36363636363636365, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431818181818182, 'recall': 0.9595375722543352, 'f1': 0.9512893982808023, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608610567514677, 'recall': 0.9761431411530815, 'f1': 0.9684418145956608, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4117647058823529, 'recall': 0.4375, 'f1': 0.42424242424242425, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36585365853658536, 'recall': 0.5, 'f1': 0.4225352112676056, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23076923076923078, 'recall': 0.5, 'f1': 0.3157894736842105, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9657631954350927, 'recall': 0.9755043227665706, 'f1': 0.9706093189964158, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9532467532467532, 'recall': 0.963254593175853, 'f1': 0.9582245430809399, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9328358208955224, 'recall': 0.9633911368015414, 'f1': 0.9478672985781991, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9627450980392157, 'recall': 0.9761431411530815, 'f1': 0.9693978282329714, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34615384615384615, 'recall': 0.5625, 'f1': 0.4285714285714286, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4318181818181818, 'recall': 0.6333333333333333, 'f1': 0.5135135135135135, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9219330855018587, 'recall': 0.9556840077071291, 'f1': 0.9385052034058656, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9475728155339805, 'recall': 0.9701789264413518, 'f1': 0.9587426326129667, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6, 'f1': 0.5454545454545454, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.96875, 'recall': 0.9393939393939394, 'f1': 0.9538461538461539, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9482535575679172, 'recall': 0.9619422572178478, 'f1': 0.9550488599348534, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823269513991163, 'recall': 0.9866863905325444, 'f1': 0.9845018450184502, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9360902255639098, 'recall': 0.9595375722543352, 'f1': 0.9476688867745005, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9607843137254902, 'recall': 0.974155069582505, 'f1': 0.9674234945705825, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45, 'recall': 0.6, 'f1': 0.5142857142857143, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9469598965071151, 'recall': 0.9606299212598425, 'f1': 0.9537459283387623, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900 (score: 0.9700450450450451).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9604486422668241, 'recall': 0.9655786350148368, 'f1': 0.9630068067475585, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8474870017331022, 'recall': 0.8939670932358318, 'f1': 0.8701067615658362, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8972667295004713, 'recall': 0.9233753637245393, 'f1': 0.910133843212237, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.27956989247311825, 'recall': 0.4126984126984127, 'f1': 0.3333333333333333, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.5063291139240507, 'f1': 0.365296803652968, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8695652173913043, 'recall': 0.9302325581395349, 'f1': 0.898876404494382, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5185185185185185, 'recall': 0.42424242424242425, 'f1': 0.4666666666666667, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9331836047164515, 'recall': 0.951345163136806, 'f1': 0.9421768707482993, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9352360043907794, 'recall': 0.9530201342281879, 'f1': 0.9440443213296399, 'number': 1788}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9879310344827587, 'recall': 0.981724728726442, 'f1': 0.9848181036952163, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4666666666666667, 'recall': 0.5, 'f1': 0.4827586206896552, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.982274741506647, 'recall': 0.9837278106508875, 'f1': 0.9830007390983001, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9511278195488722, 'recall': 0.9749518304431599, 'f1': 0.9628924833491912, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705882352941176, 'recall': 0.9840954274353877, 'f1': 0.9772951628825272, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.6875, 'f1': 0.5789473684210527, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5121951219512195, 'recall': 0.7, 'f1': 0.5915492957746479, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629629629629629, 'recall': 0.9740634005763689, 'f1': 0.9684813753581661, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9446589446589446, 'recall': 0.963254593175853, 'f1': 0.9538661468486029, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-b_PER+O\",\n",
      "    \"2\": \"I-i_PER+O\",\n",
      "    \"3\": \"I-b_PER+b_TITREH\",\n",
      "    \"4\": \"I-i_PER+b_TITREH\",\n",
      "    \"5\": \"I-i_PER+i_TITREH\",\n",
      "    \"6\": \"I-b_ACT+O\",\n",
      "    \"7\": \"I-i_ACT+O\",\n",
      "    \"8\": \"I-b_DESC+O\",\n",
      "    \"9\": \"I-i_DESC+O\",\n",
      "    \"10\": \"I-b_DESC+b_ACT\",\n",
      "    \"11\": \"I-i_DESC+b_ACT\",\n",
      "    \"12\": \"I-i_DESC+i_ACT\",\n",
      "    \"13\": \"I-b_DESC+b_TITREP\",\n",
      "    \"14\": \"I-i_DESC+b_TITREP\",\n",
      "    \"15\": \"I-i_DESC+i_TITREP\",\n",
      "    \"16\": \"I-b_SPAT+O\",\n",
      "    \"17\": \"I-i_SPAT+O\",\n",
      "    \"18\": \"I-b_SPAT+b_LOC\",\n",
      "    \"19\": \"I-i_SPAT+b_LOC\",\n",
      "    \"20\": \"I-i_SPAT+i_LOC\",\n",
      "    \"21\": \"I-b_SPAT+b_CARDINAL\",\n",
      "    \"22\": \"I-i_SPAT+b_CARDINAL\",\n",
      "    \"23\": \"I-i_SPAT+i_CARDINAL\",\n",
      "    \"24\": \"I-b_SPAT+b_FT\",\n",
      "    \"25\": \"I-i_SPAT+b_FT\",\n",
      "    \"26\": \"I-i_SPAT+i_FT\",\n",
      "    \"27\": \"I-b_TITRE+O\",\n",
      "    \"28\": \"I-i_TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-b_ACT+O\": 6,\n",
      "    \"I-b_DESC+O\": 8,\n",
      "    \"I-b_DESC+b_ACT\": 10,\n",
      "    \"I-b_DESC+b_TITREP\": 13,\n",
      "    \"I-b_PER+O\": 1,\n",
      "    \"I-b_PER+b_TITREH\": 3,\n",
      "    \"I-b_SPAT+O\": 16,\n",
      "    \"I-b_SPAT+b_CARDINAL\": 21,\n",
      "    \"I-b_SPAT+b_FT\": 24,\n",
      "    \"I-b_SPAT+b_LOC\": 18,\n",
      "    \"I-b_TITRE+O\": 27,\n",
      "    \"I-i_ACT+O\": 7,\n",
      "    \"I-i_DESC+O\": 9,\n",
      "    \"I-i_DESC+b_ACT\": 11,\n",
      "    \"I-i_DESC+b_TITREP\": 14,\n",
      "    \"I-i_DESC+i_ACT\": 12,\n",
      "    \"I-i_DESC+i_TITREP\": 15,\n",
      "    \"I-i_PER+O\": 2,\n",
      "    \"I-i_PER+b_TITREH\": 4,\n",
      "    \"I-i_PER+i_TITREH\": 5,\n",
      "    \"I-i_SPAT+O\": 17,\n",
      "    \"I-i_SPAT+b_CARDINAL\": 22,\n",
      "    \"I-i_SPAT+b_FT\": 25,\n",
      "    \"I-i_SPAT+b_LOC\": 19,\n",
      "    \"I-i_SPAT+i_CARDINAL\": 23,\n",
      "    \"I-i_SPAT+i_FT\": 26,\n",
      "    \"I-i_SPAT+i_LOC\": 20,\n",
      "    \"I-i_TITRE+O\": 28,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110053661\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/5000 06:42 < 15:40, 3.72 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Precision-l1l2</th>\n",
       "      <th>Recall-l1l2</th>\n",
       "      <th>F1-l1l2</th>\n",
       "      <th>Accuracy-l1l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680494</td>\n",
       "      <td>0.932745</td>\n",
       "      <td>0.931268</td>\n",
       "      <td>0.932006</td>\n",
       "      <td>0.933435</td>\n",
       "      <td>0.917394</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.947102</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.926174</td>\n",
       "      <td>0.965578</td>\n",
       "      <td>0.926242</td>\n",
       "      <td>0.930726</td>\n",
       "      <td>0.928479</td>\n",
       "      <td>0.952164</td>\n",
       "      <td>0.919954</td>\n",
       "      <td>0.928509</td>\n",
       "      <td>0.924212</td>\n",
       "      <td>0.934067</td>\n",
       "      <td>0.924424</td>\n",
       "      <td>0.929850</td>\n",
       "      <td>0.927129</td>\n",
       "      <td>0.956340</td>\n",
       "      <td>{'precision': 0.9487554904831625, 'recall': 0.9585798816568047, 'f1': 0.9536423841059604, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8563734290843806, 'recall': 0.9190751445086706, 'f1': 0.8866171003717472, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8563734290843806, 'recall': 0.94831013916501, 'f1': 0.9, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9351198871650211, 'recall': 0.9553314121037464, 'f1': 0.9451176051318602, 'number': 694}</td>\n",
       "      <td>{'precision': 0.920410783055199, 'recall': 0.9409448818897638, 'f1': 0.9305645684620377, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9484978540772532, 'recall': 0.9778761061946902, 'f1': 0.9629629629629629, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.381290</td>\n",
       "      <td>0.939524</td>\n",
       "      <td>0.937825</td>\n",
       "      <td>0.938674</td>\n",
       "      <td>0.938497</td>\n",
       "      <td>0.902278</td>\n",
       "      <td>0.935433</td>\n",
       "      <td>0.918557</td>\n",
       "      <td>0.948114</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.926764</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>0.935568</td>\n",
       "      <td>0.929510</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.925489</td>\n",
       "      <td>0.934903</td>\n",
       "      <td>0.930172</td>\n",
       "      <td>0.938876</td>\n",
       "      <td>0.920267</td>\n",
       "      <td>0.931611</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.957542</td>\n",
       "      <td>{'precision': 0.9277456647398844, 'recall': 0.9497041420118343, 'f1': 0.9385964912280702, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8480565371024735, 'recall': 0.9248554913294798, 'f1': 0.8847926267281107, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8480565371024735, 'recall': 0.9542743538767395, 'f1': 0.8980355472404116, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9256661991584852, 'recall': 0.9510086455331412, 'f1': 0.9381663113006397, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9240506329113924, 'recall': 0.958005249343832, 'f1': 0.9407216494845361, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9678362573099415, 'recall': 0.976401179941003, 'f1': 0.9720998531571218, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275148</td>\n",
       "      <td>0.948549</td>\n",
       "      <td>0.946190</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.926718</td>\n",
       "      <td>0.955906</td>\n",
       "      <td>0.941085</td>\n",
       "      <td>0.960643</td>\n",
       "      <td>0.937790</td>\n",
       "      <td>0.943409</td>\n",
       "      <td>0.940591</td>\n",
       "      <td>0.973678</td>\n",
       "      <td>0.959585</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.961724</td>\n",
       "      <td>0.972032</td>\n",
       "      <td>0.936608</td>\n",
       "      <td>0.953211</td>\n",
       "      <td>0.944837</td>\n",
       "      <td>0.950899</td>\n",
       "      <td>0.931530</td>\n",
       "      <td>0.950396</td>\n",
       "      <td>0.940869</td>\n",
       "      <td>0.967160</td>\n",
       "      <td>{'precision': 0.9661266568483063, 'recall': 0.9704142011834319, 'f1': 0.9682656826568266, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8925925925925926, 'recall': 0.928709055876686, 'f1': 0.9102927289896129, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8925925925925926, 'recall': 0.9582504970178927, 'f1': 0.9242569511025887, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.19047619047619047, 'recall': 0.26666666666666666, 'f1': 0.2222222222222222, 'number': 30}</td>\n",
       "      <td>{'precision': 0.28888888888888886, 'recall': 0.3939393939393939, 'f1': 0.3333333333333333, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9588068181818182, 'recall': 0.9726224783861671, 'f1': 0.9656652360515022, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9456662354463131, 'recall': 0.9593175853018373, 'f1': 0.9524429967426711, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9752906976744186, 'recall': 0.9896755162241888, 'f1': 0.9824304538799414, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224336</td>\n",
       "      <td>0.951027</td>\n",
       "      <td>0.952747</td>\n",
       "      <td>0.951886</td>\n",
       "      <td>0.953936</td>\n",
       "      <td>0.935038</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.947150</td>\n",
       "      <td>0.965705</td>\n",
       "      <td>0.931669</td>\n",
       "      <td>0.944075</td>\n",
       "      <td>0.937831</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.957502</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.961232</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.935246</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.945993</td>\n",
       "      <td>0.954442</td>\n",
       "      <td>0.933563</td>\n",
       "      <td>0.952744</td>\n",
       "      <td>0.943056</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9121495327102803, 'recall': 0.9402697495183044, 'f1': 0.9259962049335864, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9121495327102803, 'recall': 0.9701789264413518, 'f1': 0.9402697495183044, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.225, 'recall': 0.3, 'f1': 0.2571428571428572, 'number': 30}</td>\n",
       "      <td>{'precision': 0.3269230769230769, 'recall': 0.5151515151515151, 'f1': 0.4, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9487179487179487, 'recall': 0.9596541786743515, 'f1': 0.9541547277936963, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9367741935483871, 'recall': 0.952755905511811, 'f1': 0.94469746258946, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9853372434017595, 'recall': 0.9911504424778761, 'f1': 0.9882352941176471, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.199209</td>\n",
       "      <td>0.951318</td>\n",
       "      <td>0.954330</td>\n",
       "      <td>0.952822</td>\n",
       "      <td>0.953430</td>\n",
       "      <td>0.931969</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>0.944041</td>\n",
       "      <td>0.962035</td>\n",
       "      <td>0.930401</td>\n",
       "      <td>0.943409</td>\n",
       "      <td>0.936860</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.953574</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.958696</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>0.937215</td>\n",
       "      <td>0.954374</td>\n",
       "      <td>0.945716</td>\n",
       "      <td>0.953809</td>\n",
       "      <td>0.931282</td>\n",
       "      <td>0.950690</td>\n",
       "      <td>0.940886</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>{'precision': 0.9676945668135095, 'recall': 0.9748520710059172, 'f1': 0.9712601326455416, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9027522935779817, 'recall': 0.9479768786127167, 'f1': 0.924812030075188, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9027522935779817, 'recall': 0.9781312127236581, 'f1': 0.9389312977099237, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.13636363636363635, 'recall': 0.1, 'f1': 0.11538461538461538, 'number': 30}</td>\n",
       "      <td>{'precision': 0.30357142857142855, 'recall': 0.5151515151515151, 'f1': 0.38202247191011235, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9448373408769448, 'recall': 0.962536023054755, 'f1': 0.953604568165596, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9368556701030928, 'recall': 0.9540682414698163, 'f1': 0.9453836150845253, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.182430</td>\n",
       "      <td>0.952873</td>\n",
       "      <td>0.959982</td>\n",
       "      <td>0.956414</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.950998</td>\n",
       "      <td>0.965578</td>\n",
       "      <td>0.945287</td>\n",
       "      <td>0.954727</td>\n",
       "      <td>0.949983</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.954746</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.960577</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>0.944349</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.952916</td>\n",
       "      <td>0.957985</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.959202</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>0.969438</td>\n",
       "      <td>{'precision': 0.9661764705882353, 'recall': 0.9718934911242604, 'f1': 0.9690265486725664, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9213483146067416, 'recall': 0.9479768786127167, 'f1': 0.9344729344729344, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2777777777777778, 'recall': 0.3333333333333333, 'f1': 0.303030303030303, 'number': 30}</td>\n",
       "      <td>{'precision': 0.55, 'recall': 0.6666666666666666, 'f1': 0.6027397260273972, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9574468085106383, 'recall': 0.9726224783861671, 'f1': 0.9649749821300929, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9450127877237852, 'recall': 0.9698162729658792, 'f1': 0.9572538860103625, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.158958</td>\n",
       "      <td>0.965345</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.964472</td>\n",
       "      <td>0.963427</td>\n",
       "      <td>0.957358</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.961860</td>\n",
       "      <td>0.971779</td>\n",
       "      <td>0.958556</td>\n",
       "      <td>0.954727</td>\n",
       "      <td>0.956638</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.966468</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.966288</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.958394</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.961171</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.957882</td>\n",
       "      <td>0.961256</td>\n",
       "      <td>0.959566</td>\n",
       "      <td>0.975006</td>\n",
       "      <td>{'precision': 0.9837278106508875, 'recall': 0.9837278106508875, 'f1': 0.9837278106508875, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9392789373814042, 'recall': 0.953757225433526, 'f1': 0.9464627151051626, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9516441005802708, 'recall': 0.9781312127236581, 'f1': 0.9647058823529412, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.1875, 'f1': 0.23076923076923075, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4411764705882353, 'recall': 0.5, 'f1': 0.46875, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7647058823529411, 'recall': 0.7878787878787878, 'f1': 0.7761194029850745, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9612068965517241, 'recall': 0.9639769452449568, 'f1': 0.962589928057554, 'number': 694}</td>\n",
       "      <td>{'precision': 0.954367666232073, 'recall': 0.9606299212598425, 'f1': 0.9574885546108567, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.162488</td>\n",
       "      <td>0.956064</td>\n",
       "      <td>0.964278</td>\n",
       "      <td>0.960153</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.937532</td>\n",
       "      <td>0.961155</td>\n",
       "      <td>0.949196</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.950397</td>\n",
       "      <td>0.956724</td>\n",
       "      <td>0.953550</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.965043</td>\n",
       "      <td>0.977854</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.962511</td>\n",
       "      <td>0.956534</td>\n",
       "      <td>0.958238</td>\n",
       "      <td>0.943146</td>\n",
       "      <td>0.959202</td>\n",
       "      <td>0.951106</td>\n",
       "      <td>0.968173</td>\n",
       "      <td>{'precision': 0.9763313609467456, 'recall': 0.9763313609467456, 'f1': 0.9763313609467456, 'number': 676}</td>\n",
       "      <td>{'precision': 0.896551724137931, 'recall': 0.9518304431599229, 'f1': 0.9233644859813084, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9297912713472486, 'recall': 0.974155069582505, 'f1': 0.9514563106796117, 'number': 503}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.25, 'f1': 0.2, 'number': 16}</td>\n",
       "      <td>{'precision': 0.27450980392156865, 'recall': 0.4666666666666667, 'f1': 0.34567901234567905, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9, 'recall': 0.8181818181818182, 'f1': 0.8571428571428572, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9542203147353362, 'recall': 0.9610951008645533, 'f1': 0.9576453697056713, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9507133592736705, 'recall': 0.9619422572178478, 'f1': 0.9562948467058057, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.150389</td>\n",
       "      <td>0.964342</td>\n",
       "      <td>0.966086</td>\n",
       "      <td>0.965213</td>\n",
       "      <td>0.961276</td>\n",
       "      <td>0.956544</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.963523</td>\n",
       "      <td>0.968616</td>\n",
       "      <td>0.948026</td>\n",
       "      <td>0.959387</td>\n",
       "      <td>0.953673</td>\n",
       "      <td>0.972539</td>\n",
       "      <td>0.968437</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.969877</td>\n",
       "      <td>0.978613</td>\n",
       "      <td>0.957673</td>\n",
       "      <td>0.966579</td>\n",
       "      <td>0.962106</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.965659</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9347014925373134, 'recall': 0.9653179190751445, 'f1': 0.9497630331753555, 'number': 519}</td>\n",
       "      <td>{'precision': 0.962890625, 'recall': 0.9801192842942346, 'f1': 0.9714285714285714, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.6, 'f1': 0.48, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8235294117647058, 'recall': 0.8484848484848485, 'f1': 0.8358208955223881, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9457364341085271, 'recall': 0.9606299212598425, 'f1': 0.9531249999999999, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.147698</td>\n",
       "      <td>0.964246</td>\n",
       "      <td>0.969478</td>\n",
       "      <td>0.966855</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.951081</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.960229</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>0.958306</td>\n",
       "      <td>0.964048</td>\n",
       "      <td>0.961168</td>\n",
       "      <td>0.973551</td>\n",
       "      <td>0.969596</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.971758</td>\n",
       "      <td>0.983169</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.969486</td>\n",
       "      <td>0.963327</td>\n",
       "      <td>0.964692</td>\n",
       "      <td>0.954243</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.960641</td>\n",
       "      <td>0.972096</td>\n",
       "      <td>{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9171270718232044, 'recall': 0.9595375722543352, 'f1': 0.9378531073446328, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9425287356321839, 'recall': 0.9781312127236581, 'f1': 0.9600000000000001, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.375, 'f1': 0.3243243243243243, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9614285714285714, 'recall': 0.9697406340057637, 'f1': 0.9655667144906743, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9622395833333334, 'recall': 0.9698162729658792, 'f1': 0.9660130718954248, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.161034</td>\n",
       "      <td>0.963113</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.965611</td>\n",
       "      <td>0.958618</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.973228</td>\n",
       "      <td>0.969412</td>\n",
       "      <td>0.966464</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.964048</td>\n",
       "      <td>0.956407</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.967383</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.969719</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>0.958070</td>\n",
       "      <td>0.969486</td>\n",
       "      <td>0.963744</td>\n",
       "      <td>0.959377</td>\n",
       "      <td>0.958212</td>\n",
       "      <td>0.969181</td>\n",
       "      <td>0.963666</td>\n",
       "      <td>0.968173</td>\n",
       "      <td>{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}</td>\n",
       "      <td>{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9741035856573705, 'recall': 0.9721669980119284, 'f1': 0.9731343283582091, 'number': 503}</td>\n",
       "      <td>{'precision': 0.27586206896551724, 'recall': 0.5, 'f1': 0.35555555555555557, 'number': 16}</td>\n",
       "      <td>{'precision': 0.47619047619047616, 'recall': 0.6666666666666666, 'f1': 0.5555555555555556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9558441558441558, 'recall': 0.9658792650918635, 'f1': 0.9608355091383811, 'number': 762}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.157367</td>\n",
       "      <td>0.958631</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>0.963912</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.942051</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.953048</td>\n",
       "      <td>0.966211</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.952571</td>\n",
       "      <td>0.968904</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.961276</td>\n",
       "      <td>0.946928</td>\n",
       "      <td>0.963604</td>\n",
       "      <td>0.955193</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>{'precision': 0.9749631811487481, 'recall': 0.9792899408284024, 'f1': 0.9771217712177122, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9556840077071291, 'f1': 0.9332079021636875, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9479768786127167, 'recall': 0.9781312127236581, 'f1': 0.9628180039138944, 'number': 503}</td>\n",
       "      <td>{'precision': 0.16, 'recall': 0.25, 'f1': 0.19512195121951217, 'number': 16}</td>\n",
       "      <td>{'precision': 0.24074074074074073, 'recall': 0.43333333333333335, 'f1': 0.30952380952380953, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9598853868194842, 'recall': 0.9654178674351584, 'f1': 0.9626436781609194, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9608355091383812, 'recall': 0.9658792650918635, 'f1': 0.963350785340314, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.957979</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.963471</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>0.945501</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.955325</td>\n",
       "      <td>0.965958</td>\n",
       "      <td>0.947610</td>\n",
       "      <td>0.963382</td>\n",
       "      <td>0.955431</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>0.961638</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.966271</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.950628</td>\n",
       "      <td>0.968033</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.960390</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.964485</td>\n",
       "      <td>0.955371</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>{'precision': 0.9734904270986745, 'recall': 0.977810650887574, 'f1': 0.9756457564575647, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9424184261036468, 'recall': 0.9761431411530815, 'f1': 0.958984375, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.25, 'f1': 0.22222222222222224, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.9090909090909091, 'f1': 0.8823529411764706, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9601706970128022, 'recall': 0.9726224783861671, 'f1': 0.9663564781675018, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9497422680412371, 'recall': 0.9671916010498688, 'f1': 0.9583875162548764, 'number': 762}</td>\n",
       "      <td>{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.173433</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>0.966193</td>\n",
       "      <td>0.961402</td>\n",
       "      <td>0.956861</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.961609</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.956607</td>\n",
       "      <td>0.968708</td>\n",
       "      <td>0.962620</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.970665</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.965049</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.956749</td>\n",
       "      <td>0.967420</td>\n",
       "      <td>0.962055</td>\n",
       "      <td>0.971526</td>\n",
       "      <td>{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9625984251968503, 'recall': 0.9721669980119284, 'f1': 0.9673590504451038, 'number': 503}</td>\n",
       "      <td>{'precision': 0.4583333333333333, 'recall': 0.6875, 'f1': 0.5499999999999999, 'number': 16}</td>\n",
       "      <td>{'precision': 0.37209302325581395, 'recall': 0.5333333333333333, 'f1': 0.4383561643835616, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9640287769784173, 'recall': 0.9654178674351584, 'f1': 0.964722822174226, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9608865710560626, 'recall': 0.9671916010498688, 'f1': 0.9640287769784173, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.961167</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.964632</td>\n",
       "      <td>0.960137</td>\n",
       "      <td>0.951888</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.958833</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.946920</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.954425</td>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.961894</td>\n",
       "      <td>0.968343</td>\n",
       "      <td>0.965108</td>\n",
       "      <td>0.974943</td>\n",
       "      <td>0.953049</td>\n",
       "      <td>0.967451</td>\n",
       "      <td>0.960196</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.949696</td>\n",
       "      <td>0.964191</td>\n",
       "      <td>0.956889</td>\n",
       "      <td>0.971969</td>\n",
       "      <td>{'precision': 0.9837758112094396, 'recall': 0.9866863905325444, 'f1': 0.9852289512555391, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9199255121042831, 'recall': 0.9518304431599229, 'f1': 0.9356060606060607, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9457364341085271, 'recall': 0.9701789264413518, 'f1': 0.957801766437684, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.375, 'f1': 0.3243243243243243, 'number': 16}</td>\n",
       "      <td>{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9586305278174037, 'recall': 0.968299711815562, 'f1': 0.9634408602150538, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9494818652849741, 'recall': 0.9619422572178478, 'f1': 0.955671447196871, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9487554904831625, 'recall': 0.9585798816568047, 'f1': 0.9536423841059604, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8563734290843806, 'recall': 0.9190751445086706, 'f1': 0.8866171003717472, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8563734290843806, 'recall': 0.94831013916501, 'f1': 0.9, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9351198871650211, 'recall': 0.9553314121037464, 'f1': 0.9451176051318602, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.920410783055199, 'recall': 0.9409448818897638, 'f1': 0.9305645684620377, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9484978540772532, 'recall': 0.9778761061946902, 'f1': 0.9629629629629629, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9277456647398844, 'recall': 0.9497041420118343, 'f1': 0.9385964912280702, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8480565371024735, 'recall': 0.9248554913294798, 'f1': 0.8847926267281107, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8480565371024735, 'recall': 0.9542743538767395, 'f1': 0.8980355472404116, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9256661991584852, 'recall': 0.9510086455331412, 'f1': 0.9381663113006397, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9240506329113924, 'recall': 0.958005249343832, 'f1': 0.9407216494845361, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9678362573099415, 'recall': 0.976401179941003, 'f1': 0.9720998531571218, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661266568483063, 'recall': 0.9704142011834319, 'f1': 0.9682656826568266, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8925925925925926, 'recall': 0.928709055876686, 'f1': 0.9102927289896129, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8925925925925926, 'recall': 0.9582504970178927, 'f1': 0.9242569511025887, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.19047619047619047, 'recall': 0.26666666666666666, 'f1': 0.2222222222222222, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.28888888888888886, 'recall': 0.3939393939393939, 'f1': 0.3333333333333333, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9588068181818182, 'recall': 0.9726224783861671, 'f1': 0.9656652360515022, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456662354463131, 'recall': 0.9593175853018373, 'f1': 0.9524429967426711, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9752906976744186, 'recall': 0.9896755162241888, 'f1': 0.9824304538799414, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808259587020649, 'recall': 0.9837278106508875, 'f1': 0.982274741506647, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9121495327102803, 'recall': 0.9402697495183044, 'f1': 0.9259962049335864, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9121495327102803, 'recall': 0.9701789264413518, 'f1': 0.9402697495183044, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.225, 'recall': 0.3, 'f1': 0.2571428571428572, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3269230769230769, 'recall': 0.5151515151515151, 'f1': 0.4, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9487179487179487, 'recall': 0.9596541786743515, 'f1': 0.9541547277936963, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9367741935483871, 'recall': 0.952755905511811, 'f1': 0.94469746258946, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853372434017595, 'recall': 0.9911504424778761, 'f1': 0.9882352941176471, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9676945668135095, 'recall': 0.9748520710059172, 'f1': 0.9712601326455416, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9027522935779817, 'recall': 0.9479768786127167, 'f1': 0.924812030075188, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9027522935779817, 'recall': 0.9781312127236581, 'f1': 0.9389312977099237, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.13636363636363635, 'recall': 0.1, 'f1': 0.11538461538461538, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.30357142857142855, 'recall': 0.5151515151515151, 'f1': 0.38202247191011235, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9448373408769448, 'recall': 0.962536023054755, 'f1': 0.953604568165596, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9368556701030928, 'recall': 0.9540682414698163, 'f1': 0.9453836150845253, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661764705882353, 'recall': 0.9718934911242604, 'f1': 0.9690265486725664, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9213483146067416, 'recall': 0.9479768786127167, 'f1': 0.9344729344729344, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2777777777777778, 'recall': 0.3333333333333333, 'f1': 0.303030303030303, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.55, 'recall': 0.6666666666666666, 'f1': 0.6027397260273972, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9574468085106383, 'recall': 0.9726224783861671, 'f1': 0.9649749821300929, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9450127877237852, 'recall': 0.9698162729658792, 'f1': 0.9572538860103625, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837278106508875, 'recall': 0.9837278106508875, 'f1': 0.9837278106508875, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9392789373814042, 'recall': 0.953757225433526, 'f1': 0.9464627151051626, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9516441005802708, 'recall': 0.9781312127236581, 'f1': 0.9647058823529412, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.1875, 'f1': 0.23076923076923075, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4411764705882353, 'recall': 0.5, 'f1': 0.46875, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7647058823529411, 'recall': 0.7878787878787878, 'f1': 0.7761194029850745, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9612068965517241, 'recall': 0.9639769452449568, 'f1': 0.962589928057554, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.954367666232073, 'recall': 0.9606299212598425, 'f1': 0.9574885546108567, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882005899705014, 'recall': 0.9882005899705014, 'f1': 0.9882005899705014, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9763313609467456, 'recall': 0.9763313609467456, 'f1': 0.9763313609467456, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.896551724137931, 'recall': 0.9518304431599229, 'f1': 0.9233644859813084, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9297912713472486, 'recall': 0.974155069582505, 'f1': 0.9514563106796117, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.25, 'f1': 0.2, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.27450980392156865, 'recall': 0.4666666666666667, 'f1': 0.34567901234567905, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9, 'recall': 0.8181818181818182, 'f1': 0.8571428571428572, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.5, 'f1': 0.5454545454545454, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9542203147353362, 'recall': 0.9610951008645533, 'f1': 0.9576453697056713, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9507133592736705, 'recall': 0.9619422572178478, 'f1': 0.9562948467058057, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867256637168141, 'recall': 0.9867256637168141, 'f1': 0.9867256637168141, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9347014925373134, 'recall': 0.9653179190751445, 'f1': 0.9497630331753555, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.962890625, 'recall': 0.9801192842942346, 'f1': 0.9714285714285714, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.6, 'f1': 0.48, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8235294117647058, 'recall': 0.8484848484848485, 'f1': 0.8358208955223881, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9457364341085271, 'recall': 0.9606299212598425, 'f1': 0.9531249999999999, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9171270718232044, 'recall': 0.9595375722543352, 'f1': 0.9378531073446328, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9425287356321839, 'recall': 0.9781312127236581, 'f1': 0.9600000000000001, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.375, 'f1': 0.3243243243243243, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614285714285714, 'recall': 0.9697406340057637, 'f1': 0.9655667144906743, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622395833333334, 'recall': 0.9698162729658792, 'f1': 0.9660130718954248, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852289512555391, 'recall': 0.9866863905325444, 'f1': 0.9859571322985957, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.935969868173258, 'recall': 0.9576107899807321, 'f1': 0.9466666666666668, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9741035856573705, 'recall': 0.9721669980119284, 'f1': 0.9731343283582091, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.27586206896551724, 'recall': 0.5, 'f1': 0.35555555555555557, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.47619047619047616, 'recall': 0.6666666666666666, 'f1': 0.5555555555555556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9699570815450643, 'recall': 0.9769452449567724, 'f1': 0.9734386216798276, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9558441558441558, 'recall': 0.9658792650918635, 'f1': 0.9608355091383811, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9749631811487481, 'recall': 0.9792899408284024, 'f1': 0.9771217712177122, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9556840077071291, 'f1': 0.9332079021636875, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9479768786127167, 'recall': 0.9781312127236581, 'f1': 0.9628180039138944, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.16, 'recall': 0.25, 'f1': 0.19512195121951217, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.24074074074074073, 'recall': 0.43333333333333335, 'f1': 0.30952380952380953, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9598853868194842, 'recall': 0.9654178674351584, 'f1': 0.9626436781609194, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608355091383812, 'recall': 0.9658792650918635, 'f1': 0.963350785340314, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9734904270986745, 'recall': 0.977810650887574, 'f1': 0.9756457564575647, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9149722735674677, 'recall': 0.953757225433526, 'f1': 0.9339622641509434, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9424184261036468, 'recall': 0.9761431411530815, 'f1': 0.958984375, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.25, 'f1': 0.22222222222222224, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.4, 'f1': 0.3333333333333333, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8571428571428571, 'recall': 0.9090909090909091, 'f1': 0.8823529411764706, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9601706970128022, 'recall': 0.9726224783861671, 'f1': 0.9663564781675018, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9497422680412371, 'recall': 0.9671916010498688, 'f1': 0.9583875162548764, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823008849557522, 'recall': 0.985207100591716, 'f1': 0.983751846381093, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398496240601504, 'recall': 0.9633911368015414, 'f1': 0.9514747859181732, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9625984251968503, 'recall': 0.9721669980119284, 'f1': 0.9673590504451038, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4583333333333333, 'recall': 0.6875, 'f1': 0.5499999999999999, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.37209302325581395, 'recall': 0.5333333333333333, 'f1': 0.4383561643835616, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8857142857142857, 'recall': 0.9393939393939394, 'f1': 0.9117647058823529, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9640287769784173, 'recall': 0.9654178674351584, 'f1': 0.964722822174226, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9608865710560626, 'recall': 0.9671916010498688, 'f1': 0.9640287769784173, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9837758112094396, 'recall': 0.9866863905325444, 'f1': 0.9852289512555391, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9199255121042831, 'recall': 0.9518304431599229, 'f1': 0.9356060606060607, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9457364341085271, 'recall': 0.9701789264413518, 'f1': 0.957801766437684, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.375, 'f1': 0.3243243243243243, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34210526315789475, 'recall': 0.43333333333333335, 'f1': 0.3823529411764707, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8648648648648649, 'recall': 0.9696969696969697, 'f1': 0.9142857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9586305278174037, 'recall': 0.968299711815562, 'f1': 0.9634408602150538, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9494818652849741, 'recall': 0.9619422572178478, 'f1': 0.955671447196871, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838235294117647, 'recall': 0.9867256637168141, 'f1': 0.9852724594992636, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000 (score: 0.9668545659526493).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9529134785167745, 'recall': 0.9608308605341246, 'f1': 0.9568557919621749, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8478073946689596, 'recall': 0.9012797074954296, 'f1': 0.8737261852015951, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9146919431279621, 'recall': 0.9359844810863239, 'f1': 0.925215723873442, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.19444444444444445, 'recall': 0.3333333333333333, 'f1': 0.24561403508771928, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3770491803278688, 'recall': 0.5822784810126582, 'f1': 0.4577114427860696, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7209302325581395, 'recall': 0.7209302325581395, 'f1': 0.7209302325581395, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5652173913043478, 'recall': 0.3939393939393939, 'f1': 0.4642857142857143, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400791407574901, 'recall': 0.9519175729822553, 'f1': 0.9459613196814562, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9441680486456606, 'recall': 0.9552572706935123, 'f1': 0.9496802891298305, 'number': 1788}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9856897538637664, 'recall': 0.9834380354083381, 'f1': 0.9845626072041166, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9171270718232044, 'recall': 0.9595375722543352, 'f1': 0.9378531073446328, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9425287356321839, 'recall': 0.9781312127236581, 'f1': 0.9600000000000001, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.375, 'f1': 0.3243243243243243, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614285714285714, 'recall': 0.9697406340057637, 'f1': 0.9655667144906743, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9622395833333334, 'recall': 0.9698162729658792, 'f1': 0.9660130718954248, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-b_PER+O\",\n",
      "    \"2\": \"I-i_PER+O\",\n",
      "    \"3\": \"I-b_PER+b_TITREH\",\n",
      "    \"4\": \"I-i_PER+b_TITREH\",\n",
      "    \"5\": \"I-i_PER+i_TITREH\",\n",
      "    \"6\": \"I-b_ACT+O\",\n",
      "    \"7\": \"I-i_ACT+O\",\n",
      "    \"8\": \"I-b_DESC+O\",\n",
      "    \"9\": \"I-i_DESC+O\",\n",
      "    \"10\": \"I-b_DESC+b_ACT\",\n",
      "    \"11\": \"I-i_DESC+b_ACT\",\n",
      "    \"12\": \"I-i_DESC+i_ACT\",\n",
      "    \"13\": \"I-b_DESC+b_TITREP\",\n",
      "    \"14\": \"I-i_DESC+b_TITREP\",\n",
      "    \"15\": \"I-i_DESC+i_TITREP\",\n",
      "    \"16\": \"I-b_SPAT+O\",\n",
      "    \"17\": \"I-i_SPAT+O\",\n",
      "    \"18\": \"I-b_SPAT+b_LOC\",\n",
      "    \"19\": \"I-i_SPAT+b_LOC\",\n",
      "    \"20\": \"I-i_SPAT+i_LOC\",\n",
      "    \"21\": \"I-b_SPAT+b_CARDINAL\",\n",
      "    \"22\": \"I-i_SPAT+b_CARDINAL\",\n",
      "    \"23\": \"I-i_SPAT+i_CARDINAL\",\n",
      "    \"24\": \"I-b_SPAT+b_FT\",\n",
      "    \"25\": \"I-i_SPAT+b_FT\",\n",
      "    \"26\": \"I-i_SPAT+i_FT\",\n",
      "    \"27\": \"I-b_TITRE+O\",\n",
      "    \"28\": \"I-i_TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-b_ACT+O\": 6,\n",
      "    \"I-b_DESC+O\": 8,\n",
      "    \"I-b_DESC+b_ACT\": 10,\n",
      "    \"I-b_DESC+b_TITREP\": 13,\n",
      "    \"I-b_PER+O\": 1,\n",
      "    \"I-b_PER+b_TITREH\": 3,\n",
      "    \"I-b_SPAT+O\": 16,\n",
      "    \"I-b_SPAT+b_CARDINAL\": 21,\n",
      "    \"I-b_SPAT+b_FT\": 24,\n",
      "    \"I-b_SPAT+b_LOC\": 18,\n",
      "    \"I-b_TITRE+O\": 27,\n",
      "    \"I-i_ACT+O\": 7,\n",
      "    \"I-i_DESC+O\": 9,\n",
      "    \"I-i_DESC+b_ACT\": 11,\n",
      "    \"I-i_DESC+b_TITREP\": 14,\n",
      "    \"I-i_DESC+i_ACT\": 12,\n",
      "    \"I-i_DESC+i_TITREP\": 15,\n",
      "    \"I-i_PER+O\": 2,\n",
      "    \"I-i_PER+b_TITREH\": 4,\n",
      "    \"I-i_PER+i_TITREH\": 5,\n",
      "    \"I-i_SPAT+O\": 17,\n",
      "    \"I-i_SPAT+b_CARDINAL\": 22,\n",
      "    \"I-i_SPAT+b_FT\": 25,\n",
      "    \"I-i_SPAT+b_LOC\": 19,\n",
      "    \"I-i_SPAT+i_CARDINAL\": 23,\n",
      "    \"I-i_SPAT+i_FT\": 26,\n",
      "    \"I-i_SPAT+i_LOC\": 20,\n",
      "    \"I-i_TITRE+O\": 28,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110053661\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/5000 11:12 < 11:13, 3.71 it/s, Epoch 6/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Precision-l1l2</th>\n",
       "      <th>Recall-l1l2</th>\n",
       "      <th>F1-l1l2</th>\n",
       "      <th>Accuracy-l1l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.937216</td>\n",
       "      <td>0.931494</td>\n",
       "      <td>0.934346</td>\n",
       "      <td>0.932928</td>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.937008</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>0.946343</td>\n",
       "      <td>0.943460</td>\n",
       "      <td>0.922104</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>0.965578</td>\n",
       "      <td>0.927455</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.927973</td>\n",
       "      <td>0.950519</td>\n",
       "      <td>0.925282</td>\n",
       "      <td>0.928509</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.933561</td>\n",
       "      <td>0.928530</td>\n",
       "      <td>0.930437</td>\n",
       "      <td>0.929482</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>{'precision': 0.9376811594202898, 'recall': 0.9571005917159763, 'f1': 0.9472913616398242, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8768382352941176, 'recall': 0.9190751445086706, 'f1': 0.8974600188146755, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8768382352941176, 'recall': 0.94831013916501, 'f1': 0.9111747851002864, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9283707865168539, 'recall': 0.952449567723343, 'f1': 0.9402560455192034, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9279279279279279, 'recall': 0.9461942257217848, 'f1': 0.9369720597790772, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9609261939218524, 'recall': 0.9793510324483776, 'f1': 0.9700511322132943, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.375581</td>\n",
       "      <td>0.949795</td>\n",
       "      <td>0.940990</td>\n",
       "      <td>0.945372</td>\n",
       "      <td>0.940521</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.940157</td>\n",
       "      <td>0.927499</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.929427</td>\n",
       "      <td>0.938803</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>0.941438</td>\n",
       "      <td>0.945996</td>\n",
       "      <td>0.943712</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.941587</td>\n",
       "      <td>0.940767</td>\n",
       "      <td>0.940774</td>\n",
       "      <td>0.929425</td>\n",
       "      <td>0.935427</td>\n",
       "      <td>0.932417</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>{'precision': 0.9297218155197657, 'recall': 0.9393491124260355, 'f1': 0.9345106696100073, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8745519713261649, 'recall': 0.9402697495183044, 'f1': 0.9062209842154133, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8745519713261649, 'recall': 0.9701789264413518, 'f1': 0.9198868991517437, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.03333333333333333, 'f1': 0.05555555555555555, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9394366197183098, 'recall': 0.9610951008645533, 'f1': 0.9501424501424501, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9723435225618632, 'recall': 0.9852507374631269, 'f1': 0.9787545787545788, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288887</td>\n",
       "      <td>0.944998</td>\n",
       "      <td>0.943929</td>\n",
       "      <td>0.944463</td>\n",
       "      <td>0.945836</td>\n",
       "      <td>0.918878</td>\n",
       "      <td>0.945407</td>\n",
       "      <td>0.931953</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.933599</td>\n",
       "      <td>0.936085</td>\n",
       "      <td>0.934840</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.951852</td>\n",
       "      <td>0.957169</td>\n",
       "      <td>0.954503</td>\n",
       "      <td>0.967603</td>\n",
       "      <td>0.931922</td>\n",
       "      <td>0.946818</td>\n",
       "      <td>0.939311</td>\n",
       "      <td>0.945963</td>\n",
       "      <td>0.925274</td>\n",
       "      <td>0.941297</td>\n",
       "      <td>0.933217</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>{'precision': 0.950509461426492, 'recall': 0.9659763313609467, 'f1': 0.9581804842259721, 'number': 676}</td>\n",
       "      <td>{'precision': 0.897003745318352, 'recall': 0.9229287090558767, 'f1': 0.9097815764482432, 'number': 519}</td>\n",
       "      <td>{'precision': 0.897003745318352, 'recall': 0.952286282306163, 'f1': 0.9238187078109932, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2413793103448276, 'recall': 0.23333333333333334, 'f1': 0.23728813559322037, 'number': 30}</td>\n",
       "      <td>{'precision': 0.3404255319148936, 'recall': 0.48484848484848486, 'f1': 0.39999999999999997, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9323943661971831, 'recall': 0.9538904899135446, 'f1': 0.9430199430199431, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9266409266409267, 'recall': 0.9448818897637795, 'f1': 0.935672514619883, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.220102</td>\n",
       "      <td>0.951269</td>\n",
       "      <td>0.948903</td>\n",
       "      <td>0.950085</td>\n",
       "      <td>0.955581</td>\n",
       "      <td>0.933880</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>0.945021</td>\n",
       "      <td>0.964819</td>\n",
       "      <td>0.938870</td>\n",
       "      <td>0.940746</td>\n",
       "      <td>0.939807</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.957005</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.959316</td>\n",
       "      <td>0.975070</td>\n",
       "      <td>0.940384</td>\n",
       "      <td>0.953502</td>\n",
       "      <td>0.946898</td>\n",
       "      <td>0.956214</td>\n",
       "      <td>0.936053</td>\n",
       "      <td>0.949516</td>\n",
       "      <td>0.942736</td>\n",
       "      <td>0.968742</td>\n",
       "      <td>{'precision': 0.9705882352941176, 'recall': 0.9763313609467456, 'f1': 0.9734513274336284, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9158878504672897, 'recall': 0.9441233140655106, 'f1': 0.9297912713472486, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9158878504672897, 'recall': 0.974155069582505, 'f1': 0.9441233140655105, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.23076923076923078, 'recall': 0.3, 'f1': 0.2608695652173913, 'number': 30}</td>\n",
       "      <td>{'precision': 0.3488372093023256, 'recall': 0.45454545454545453, 'f1': 0.39473684210526316, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9512195121951219, 'recall': 0.9553314121037464, 'f1': 0.9532710280373832, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9427828348504551, 'recall': 0.9514435695538058, 'f1': 0.9470934030045722, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.214356</td>\n",
       "      <td>0.952617</td>\n",
       "      <td>0.954556</td>\n",
       "      <td>0.953586</td>\n",
       "      <td>0.953936</td>\n",
       "      <td>0.932273</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>0.942916</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.940318</td>\n",
       "      <td>0.944075</td>\n",
       "      <td>0.942193</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.953102</td>\n",
       "      <td>0.961266</td>\n",
       "      <td>0.957167</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.942004</td>\n",
       "      <td>0.953502</td>\n",
       "      <td>0.947718</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>0.935782</td>\n",
       "      <td>0.949516</td>\n",
       "      <td>0.942599</td>\n",
       "      <td>0.967287</td>\n",
       "      <td>{'precision': 0.9661764705882353, 'recall': 0.9718934911242604, 'f1': 0.9690265486725664, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9143389199255121, 'recall': 0.9460500963391136, 'f1': 0.9299242424242424, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9143389199255121, 'recall': 0.9761431411530815, 'f1': 0.9442307692307692, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.13333333333333333, 'f1': 0.14814814814814814, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5238095238095238, 'recall': 0.6666666666666666, 'f1': 0.5866666666666667, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9392655367231638, 'recall': 0.9582132564841499, 'f1': 0.9486447931526392, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9341085271317829, 'recall': 0.9488188976377953, 'f1': 0.94140625, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.186943</td>\n",
       "      <td>0.956237</td>\n",
       "      <td>0.958399</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>0.938849</td>\n",
       "      <td>0.959055</td>\n",
       "      <td>0.948844</td>\n",
       "      <td>0.964692</td>\n",
       "      <td>0.953395</td>\n",
       "      <td>0.953395</td>\n",
       "      <td>0.953395</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.959970</td>\n",
       "      <td>0.964618</td>\n",
       "      <td>0.962289</td>\n",
       "      <td>0.975829</td>\n",
       "      <td>0.949167</td>\n",
       "      <td>0.960477</td>\n",
       "      <td>0.954788</td>\n",
       "      <td>0.957985</td>\n",
       "      <td>0.945186</td>\n",
       "      <td>0.956560</td>\n",
       "      <td>0.950839</td>\n",
       "      <td>0.970324</td>\n",
       "      <td>{'precision': 0.9691629955947136, 'recall': 0.9763313609467456, 'f1': 0.9727339719970524, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9155722326454033, 'recall': 0.9402697495183044, 'f1': 0.9277566539923954, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9155722326454033, 'recall': 0.9701789264413518, 'f1': 0.942084942084942, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.26666666666666666, 'recall': 0.26666666666666666, 'f1': 0.26666666666666666, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5681818181818182, 'recall': 0.7575757575757576, 'f1': 0.6493506493506495, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9558404558404558, 'recall': 0.9668587896253602, 'f1': 0.9613180515759313, 'number': 694}</td>\n",
       "      <td>{'precision': 0.95822454308094, 'recall': 0.963254593175853, 'f1': 0.9607329842931936, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.171542</td>\n",
       "      <td>0.952317</td>\n",
       "      <td>0.961791</td>\n",
       "      <td>0.957030</td>\n",
       "      <td>0.957099</td>\n",
       "      <td>0.946114</td>\n",
       "      <td>0.958530</td>\n",
       "      <td>0.952282</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.938239</td>\n",
       "      <td>0.950732</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.972792</td>\n",
       "      <td>0.955334</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.959585</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.943240</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>0.952066</td>\n",
       "      <td>0.957985</td>\n",
       "      <td>0.942642</td>\n",
       "      <td>0.955092</td>\n",
       "      <td>0.948826</td>\n",
       "      <td>0.969818</td>\n",
       "      <td>{'precision': 0.9822485207100592, 'recall': 0.9822485207100592, 'f1': 0.9822485207100592, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9068901303538175, 'recall': 0.9383429672447013, 'f1': 0.9223484848484848, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9292543021032504, 'recall': 0.9662027833001988, 'f1': 0.9473684210526316, 'number': 503}</td>\n",
       "      <td>{'precision': 0.07142857142857142, 'recall': 0.0625, 'f1': 0.06666666666666667, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35294117647058826, 'recall': 0.4, 'f1': 0.37500000000000006, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9526542324246772, 'recall': 0.9567723342939481, 'f1': 0.9547088425593099, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.145593</td>\n",
       "      <td>0.959450</td>\n",
       "      <td>0.962921</td>\n",
       "      <td>0.961183</td>\n",
       "      <td>0.961149</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.950896</td>\n",
       "      <td>0.968362</td>\n",
       "      <td>0.957888</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.955971</td>\n",
       "      <td>0.976841</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.976841</td>\n",
       "      <td>0.956986</td>\n",
       "      <td>0.963383</td>\n",
       "      <td>0.960174</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.948547</td>\n",
       "      <td>0.957734</td>\n",
       "      <td>0.953118</td>\n",
       "      <td>0.972602</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9246704331450094, 'recall': 0.9460500963391136, 'f1': 0.9352380952380951, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9264150943396227, 'recall': 0.9761431411530815, 'f1': 0.9506292352371734, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2631578947368421, 'recall': 0.3333333333333333, 'f1': 0.29411764705882354, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8181818181818182, 'recall': 0.8181818181818182, 'f1': 0.8181818181818182, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9527896995708155, 'recall': 0.9596541786743515, 'f1': 0.9562096195262024, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9455958549222798, 'recall': 0.958005249343832, 'f1': 0.9517601043024773, 'number': 762}</td>\n",
       "      <td>{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.158033</td>\n",
       "      <td>0.958614</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>0.961655</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.962205</td>\n",
       "      <td>0.955434</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>0.950560</td>\n",
       "      <td>0.960053</td>\n",
       "      <td>0.955283</td>\n",
       "      <td>0.975323</td>\n",
       "      <td>0.961453</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.963775</td>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.952313</td>\n",
       "      <td>0.963383</td>\n",
       "      <td>0.957816</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.949551</td>\n",
       "      <td>0.961256</td>\n",
       "      <td>0.955368</td>\n",
       "      <td>0.972982</td>\n",
       "      <td>{'precision': 0.977810650887574, 'recall': 0.977810650887574, 'f1': 0.977810650887574, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9119850187265918, 'recall': 0.9383429672447013, 'f1': 0.9249762583095916, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9361702127659575, 'recall': 0.9622266401590457, 'f1': 0.9490196078431373, 'number': 503}</td>\n",
       "      <td>{'precision': 0.17647058823529413, 'recall': 0.1875, 'f1': 0.1818181818181818, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.5333333333333333, 'f1': 0.4571428571428572, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.156933</td>\n",
       "      <td>0.963063</td>\n",
       "      <td>0.966765</td>\n",
       "      <td>0.964910</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.952480</td>\n",
       "      <td>0.967983</td>\n",
       "      <td>0.946885</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>0.954080</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.961212</td>\n",
       "      <td>0.969088</td>\n",
       "      <td>0.965134</td>\n",
       "      <td>0.978613</td>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.965998</td>\n",
       "      <td>0.959031</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.944396</td>\n",
       "      <td>0.962137</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>{'precision': 0.9735294117647059, 'recall': 0.9792899408284024, 'f1': 0.9764011799410028, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9162011173184358, 'recall': 0.9479768786127167, 'f1': 0.9318181818181819, 'number': 519}</td>\n",
       "      <td>{'precision': 0.94921875, 'recall': 0.9662027833001988, 'f1': 0.9576354679802955, 'number': 503}</td>\n",
       "      <td>{'precision': 0.24, 'recall': 0.375, 'f1': 0.2926829268292683, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3829787234042553, 'recall': 0.6, 'f1': 0.4675324675324675, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7941176470588235, 'recall': 0.8181818181818182, 'f1': 0.8059701492537314, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9448373408769448, 'recall': 0.962536023054755, 'f1': 0.953604568165596, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9546044098573282, 'recall': 0.9658792650918635, 'f1': 0.9602087410306589, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.147533</td>\n",
       "      <td>0.959883</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.946907</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.955527</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.944661</td>\n",
       "      <td>0.966045</td>\n",
       "      <td>0.955234</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.968617</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.959516</td>\n",
       "      <td>0.961149</td>\n",
       "      <td>0.945915</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.955397</td>\n",
       "      <td>0.970893</td>\n",
       "      <td>{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9032846715328468, 'recall': 0.953757225433526, 'f1': 0.9278350515463917, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9490196078431372, 'recall': 0.9622266401590457, 'f1': 0.9555774925962486, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2894736842105263, 'recall': 0.6875, 'f1': 0.4074074074074074, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3269230769230769, 'recall': 0.5666666666666667, 'f1': 0.41463414634146345, 'number': 30}</td>\n",
       "      <td>{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9598853868194842, 'recall': 0.9654178674351584, 'f1': 0.9626436781609194, 'number': 694}</td>\n",
       "      <td>{'precision': 0.95703125, 'recall': 0.9645669291338582, 'f1': 0.9607843137254901, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>0.963379</td>\n",
       "      <td>0.969478</td>\n",
       "      <td>0.966419</td>\n",
       "      <td>0.956720</td>\n",
       "      <td>0.948400</td>\n",
       "      <td>0.964829</td>\n",
       "      <td>0.956544</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>0.952068</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.967286</td>\n",
       "      <td>0.969088</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.956884</td>\n",
       "      <td>0.967451</td>\n",
       "      <td>0.962139</td>\n",
       "      <td>0.957353</td>\n",
       "      <td>0.950014</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.957484</td>\n",
       "      <td>0.966211</td>\n",
       "      <td>{'precision': 0.9748892171344166, 'recall': 0.9763313609467456, 'f1': 0.975609756097561, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8985507246376812, 'recall': 0.9556840077071291, 'f1': 0.9262371615312792, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9475728155339805, 'recall': 0.9701789264413518, 'f1': 0.9587426326129667, 'number': 503}</td>\n",
       "      <td>{'precision': 0.21621621621621623, 'recall': 0.5, 'f1': 0.3018867924528302, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35294117647058826, 'recall': 0.6, 'f1': 0.4444444444444445, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9354838709677419, 'recall': 0.8787878787878788, 'f1': 0.90625, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9669064748201439, 'recall': 0.968299711815562, 'f1': 0.9676025917926565, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9633986928104575, 'recall': 0.9671916010498688, 'f1': 0.9652914210870989, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.42857142857142855, 'f1': 0.6, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.149151</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>0.966193</td>\n",
       "      <td>0.968109</td>\n",
       "      <td>0.946475</td>\n",
       "      <td>0.965354</td>\n",
       "      <td>0.955821</td>\n",
       "      <td>0.973931</td>\n",
       "      <td>0.951380</td>\n",
       "      <td>0.964048</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.963388</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.966784</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.954937</td>\n",
       "      <td>0.966870</td>\n",
       "      <td>0.960866</td>\n",
       "      <td>0.968616</td>\n",
       "      <td>0.948629</td>\n",
       "      <td>0.964778</td>\n",
       "      <td>0.956636</td>\n",
       "      <td>0.976398</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9214953271028037, 'recall': 0.9499036608863198, 'f1': 0.935483870967742, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9400386847195358, 'recall': 0.9662027833001988, 'f1': 0.9529411764705882, 'number': 503}</td>\n",
       "      <td>{'precision': 0.3888888888888889, 'recall': 0.4375, 'f1': 0.411764705882353, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3617021276595745, 'recall': 0.5666666666666667, 'f1': 0.4415584415584416, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9586894586894587, 'recall': 0.9697406340057637, 'f1': 0.9641833810888253, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.170861</td>\n",
       "      <td>0.956649</td>\n",
       "      <td>0.962921</td>\n",
       "      <td>0.959775</td>\n",
       "      <td>0.956846</td>\n",
       "      <td>0.953766</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>0.958747</td>\n",
       "      <td>0.964566</td>\n",
       "      <td>0.941944</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>0.951565</td>\n",
       "      <td>0.972792</td>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.967598</td>\n",
       "      <td>0.965440</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.949327</td>\n",
       "      <td>0.963673</td>\n",
       "      <td>0.956446</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>0.948525</td>\n",
       "      <td>0.962724</td>\n",
       "      <td>0.955572</td>\n",
       "      <td>0.968679</td>\n",
       "      <td>{'precision': 0.9705882352941176, 'recall': 0.9763313609467456, 'f1': 0.9734513274336284, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9246704331450094, 'recall': 0.9460500963391136, 'f1': 0.9352380952380951, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9622266401590457, 'recall': 0.9622266401590457, 'f1': 0.9622266401590457, 'number': 503}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.4375, 'f1': 0.3181818181818182, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7105263157894737, 'recall': 0.8181818181818182, 'f1': 0.7605633802816901, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9484536082474226, 'recall': 0.9658792650918635, 'f1': 0.9570871261378414, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.154326</td>\n",
       "      <td>0.963996</td>\n",
       "      <td>0.968573</td>\n",
       "      <td>0.966279</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.959523</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.965031</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>0.954967</td>\n",
       "      <td>0.960053</td>\n",
       "      <td>0.957503</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.967335</td>\n",
       "      <td>0.970577</td>\n",
       "      <td>0.968953</td>\n",
       "      <td>0.979625</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>0.967451</td>\n",
       "      <td>0.962974</td>\n",
       "      <td>0.967223</td>\n",
       "      <td>0.957521</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.976715</td>\n",
       "      <td>{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9465648854961832, 'recall': 0.9556840077071291, 'f1': 0.9511025886864813, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5384615384615384, 'recall': 0.4375, 'f1': 0.4827586206896552, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38461538461538464, 'recall': 0.5, 'f1': 0.4347826086956522, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}</td>\n",
       "      <td>{'precision': 0.18181818181818182, 'recall': 0.3333333333333333, 'f1': 0.23529411764705885, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9530638852672751, 'recall': 0.9593175853018373, 'f1': 0.9561805101373447, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.159493</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.967989</td>\n",
       "      <td>0.964186</td>\n",
       "      <td>0.955533</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>0.957728</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.968125</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.970463</td>\n",
       "      <td>0.979499</td>\n",
       "      <td>0.960023</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.965019</td>\n",
       "      <td>0.964692</td>\n",
       "      <td>0.956497</td>\n",
       "      <td>0.968007</td>\n",
       "      <td>0.962217</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>{'precision': 0.9764359351988218, 'recall': 0.9807692307692307, 'f1': 0.9785977859778597, 'number': 676}</td>\n",
       "      <td>{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9609375, 'recall': 0.9781312127236581, 'f1': 0.9694581280788177, 'number': 503}</td>\n",
       "      <td>{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}</td>\n",
       "      <td>{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.3333333333333333, 'f1': 0.25, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9670958512160229, 'recall': 0.9740634005763689, 'f1': 0.9705671213208903, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9583333333333334, 'recall': 0.9658792650918635, 'f1': 0.9620915032679739, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.157437</td>\n",
       "      <td>0.966029</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.964081</td>\n",
       "      <td>0.972178</td>\n",
       "      <td>0.968113</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>0.955659</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>0.958513</td>\n",
       "      <td>0.978107</td>\n",
       "      <td>0.969179</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.970621</td>\n",
       "      <td>0.980385</td>\n",
       "      <td>0.961671</td>\n",
       "      <td>0.969776</td>\n",
       "      <td>0.965707</td>\n",
       "      <td>0.968362</td>\n",
       "      <td>0.960373</td>\n",
       "      <td>0.967420</td>\n",
       "      <td>0.963884</td>\n",
       "      <td>0.976841</td>\n",
       "      <td>{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9724409448818898, 'recall': 0.9821073558648111, 'f1': 0.9772502472799209, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5555555555555556, 'recall': 0.625, 'f1': 0.5882352941176471, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9504563233376793, 'recall': 0.9566929133858267, 'f1': 0.9535644211903205, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.167834</td>\n",
       "      <td>0.963363</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.966186</td>\n",
       "      <td>0.964313</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.964761</td>\n",
       "      <td>0.971526</td>\n",
       "      <td>0.953734</td>\n",
       "      <td>0.960719</td>\n",
       "      <td>0.957214</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.967682</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.968942</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>0.961084</td>\n",
       "      <td>0.968904</td>\n",
       "      <td>0.964978</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.956964</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>0.961437</td>\n",
       "      <td>0.973931</td>\n",
       "      <td>{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9562737642585551, 'recall': 0.9691714836223507, 'f1': 0.9626794258373206, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5625, 'recall': 0.5625, 'f1': 0.5625, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9442282749675746, 'recall': 0.9553805774278216, 'f1': 0.949771689497717, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.153948</td>\n",
       "      <td>0.963901</td>\n",
       "      <td>0.971965</td>\n",
       "      <td>0.967916</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.954053</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.961999</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>0.978993</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.970643</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>0.958680</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.964770</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.953441</td>\n",
       "      <td>0.967714</td>\n",
       "      <td>0.960524</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}</td>\n",
       "      <td>{'precision': 0.943609022556391, 'recall': 0.9672447013487476, 'f1': 0.9552806850618459, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}</td>\n",
       "      <td>{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3695652173913043, 'recall': 0.5666666666666667, 'f1': 0.4473684210526315, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9642857142857143, 'recall': 0.9726224783861671, 'f1': 0.9684361549497849, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.969314</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.958485</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.963987</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.957096</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.961220</td>\n",
       "      <td>0.975449</td>\n",
       "      <td>0.968854</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.981271</td>\n",
       "      <td>0.962259</td>\n",
       "      <td>0.970648</td>\n",
       "      <td>0.966435</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.957873</td>\n",
       "      <td>0.967714</td>\n",
       "      <td>0.962768</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}</td>\n",
       "      <td>{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9647058823529412, 'recall': 0.9781312127236581, 'f1': 0.9713721618953604, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}</td>\n",
       "      <td>{'precision': 0.40476190476190477, 'recall': 0.5666666666666667, 'f1': 0.4722222222222222, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2727272727272727, 'recall': 0.5, 'f1': 0.3529411764705882, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9656160458452722, 'recall': 0.9711815561959655, 'f1': 0.9683908045977012, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9583333333333334, 'recall': 0.9658792650918635, 'f1': 0.9620915032679739, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.157304</td>\n",
       "      <td>0.962805</td>\n",
       "      <td>0.971513</td>\n",
       "      <td>0.967139</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.952528</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.960708</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.959683</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.966321</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.969371</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.963626</td>\n",
       "      <td>0.967603</td>\n",
       "      <td>0.952629</td>\n",
       "      <td>0.968007</td>\n",
       "      <td>0.960256</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}</td>\n",
       "      <td>{'precision': 0.958904109589041, 'recall': 0.974155069582505, 'f1': 0.9664694280078895, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.625, 'f1': 0.5555555555555556, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3617021276595745, 'recall': 0.5666666666666667, 'f1': 0.4415584415584416, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.18181818181818182, 'recall': 0.3333333333333333, 'f1': 0.23529411764705885, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9629629629629629, 'recall': 0.9740634005763689, 'f1': 0.9684813753581661, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.159965</td>\n",
       "      <td>0.967342</td>\n",
       "      <td>0.971060</td>\n",
       "      <td>0.969198</td>\n",
       "      <td>0.966338</td>\n",
       "      <td>0.960540</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.965805</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.957700</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.961194</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.971036</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.962781</td>\n",
       "      <td>0.969776</td>\n",
       "      <td>0.966266</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>0.959290</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>0.963774</td>\n",
       "      <td>0.975386</td>\n",
       "      <td>{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}</td>\n",
       "      <td>{'precision': 0.946969696969697, 'recall': 0.9633911368015414, 'f1': 0.9551098376313275, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9666011787819253, 'recall': 0.9781312127236581, 'f1': 0.9723320158102767, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4146341463414634, 'recall': 0.5666666666666667, 'f1': 0.47887323943661975, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9596354166666666, 'recall': 0.9671916010498688, 'f1': 0.9633986928104575, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.165322</td>\n",
       "      <td>0.964510</td>\n",
       "      <td>0.970834</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.962019</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.969754</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>0.969214</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.971195</td>\n",
       "      <td>0.980385</td>\n",
       "      <td>0.961151</td>\n",
       "      <td>0.970648</td>\n",
       "      <td>0.965876</td>\n",
       "      <td>0.964566</td>\n",
       "      <td>0.959012</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>0.963634</td>\n",
       "      <td>0.972475</td>\n",
       "      <td>{'precision': 0.982274741506647, 'recall': 0.9837278106508875, 'f1': 0.9830007390983001, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}</td>\n",
       "      <td>{'precision': 0.45, 'recall': 0.5625, 'f1': 0.5, 'number': 16}</td>\n",
       "      <td>{'precision': 0.47368421052631576, 'recall': 0.6, 'f1': 0.5294117647058824, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9655667144906743, 'recall': 0.9697406340057637, 'f1': 0.9676491732566499, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9521345407503234, 'recall': 0.9658792650918635, 'f1': 0.9589576547231271, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.163688</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.966045</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.959004</td>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.964509</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.958044</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>0.967407</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.970102</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>0.956484</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.964819</td>\n",
       "      <td>0.955388</td>\n",
       "      <td>0.968007</td>\n",
       "      <td>0.961656</td>\n",
       "      <td>0.973108</td>\n",
       "      <td>{'precision': 0.9807692307692307, 'recall': 0.9807692307692307, 'f1': 0.9807692307692307, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9705304518664047, 'recall': 0.9821073558648111, 'f1': 0.9762845849802371, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.625, 'f1': 0.5555555555555556, 'number': 16}</td>\n",
       "      <td>{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3, 'recall': 0.5, 'f1': 0.37499999999999994, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9641319942611191, 'recall': 0.968299711815562, 'f1': 0.9662113587347233, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9472329472329473, 'recall': 0.9658792650918635, 'f1': 0.9564652371669916, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>0.962839</td>\n",
       "      <td>0.972417</td>\n",
       "      <td>0.967604</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.953261</td>\n",
       "      <td>0.974278</td>\n",
       "      <td>0.963655</td>\n",
       "      <td>0.973551</td>\n",
       "      <td>0.955979</td>\n",
       "      <td>0.968708</td>\n",
       "      <td>0.962302</td>\n",
       "      <td>0.978613</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.975419</td>\n",
       "      <td>0.972702</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>0.957380</td>\n",
       "      <td>0.972682</td>\n",
       "      <td>0.964970</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>0.954454</td>\n",
       "      <td>0.971823</td>\n",
       "      <td>0.963060</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9283088235294118, 'recall': 0.9730250481695568, 'f1': 0.9501411100658512, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9555984555984556, 'recall': 0.9840954274353877, 'f1': 0.9696376101860921, 'number': 503}</td>\n",
       "      <td>{'precision': 0.38461538461538464, 'recall': 0.625, 'f1': 0.4761904761904762, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9597402597402598, 'recall': 0.9698162729658792, 'f1': 0.9647519582245431, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9376811594202898, 'recall': 0.9571005917159763, 'f1': 0.9472913616398242, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8768382352941176, 'recall': 0.9190751445086706, 'f1': 0.8974600188146755, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8768382352941176, 'recall': 0.94831013916501, 'f1': 0.9111747851002864, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9283707865168539, 'recall': 0.952449567723343, 'f1': 0.9402560455192034, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9279279279279279, 'recall': 0.9461942257217848, 'f1': 0.9369720597790772, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609261939218524, 'recall': 0.9793510324483776, 'f1': 0.9700511322132943, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9297218155197657, 'recall': 0.9393491124260355, 'f1': 0.9345106696100073, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8745519713261649, 'recall': 0.9402697495183044, 'f1': 0.9062209842154133, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8745519713261649, 'recall': 0.9701789264413518, 'f1': 0.9198868991517437, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.03333333333333333, 'f1': 0.05555555555555555, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9394366197183098, 'recall': 0.9610951008645533, 'f1': 0.9501424501424501, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9723435225618632, 'recall': 0.9852507374631269, 'f1': 0.9787545787545788, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.950509461426492, 'recall': 0.9659763313609467, 'f1': 0.9581804842259721, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.897003745318352, 'recall': 0.9229287090558767, 'f1': 0.9097815764482432, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.897003745318352, 'recall': 0.952286282306163, 'f1': 0.9238187078109932, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2413793103448276, 'recall': 0.23333333333333334, 'f1': 0.23728813559322037, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3404255319148936, 'recall': 0.48484848484848486, 'f1': 0.39999999999999997, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9323943661971831, 'recall': 0.9538904899135446, 'f1': 0.9430199430199431, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9266409266409267, 'recall': 0.9448818897637795, 'f1': 0.935672514619883, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705882352941176, 'recall': 0.9763313609467456, 'f1': 0.9734513274336284, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9158878504672897, 'recall': 0.9441233140655106, 'f1': 0.9297912713472486, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9158878504672897, 'recall': 0.974155069582505, 'f1': 0.9441233140655105, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23076923076923078, 'recall': 0.3, 'f1': 0.2608695652173913, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3488372093023256, 'recall': 0.45454545454545453, 'f1': 0.39473684210526316, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9512195121951219, 'recall': 0.9553314121037464, 'f1': 0.9532710280373832, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9427828348504551, 'recall': 0.9514435695538058, 'f1': 0.9470934030045722, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9661764705882353, 'recall': 0.9718934911242604, 'f1': 0.9690265486725664, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9143389199255121, 'recall': 0.9460500963391136, 'f1': 0.9299242424242424, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9143389199255121, 'recall': 0.9761431411530815, 'f1': 0.9442307692307692, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.13333333333333333, 'f1': 0.14814814814814814, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5238095238095238, 'recall': 0.6666666666666666, 'f1': 0.5866666666666667, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9392655367231638, 'recall': 0.9582132564841499, 'f1': 0.9486447931526392, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9341085271317829, 'recall': 0.9488188976377953, 'f1': 0.94140625, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9691629955947136, 'recall': 0.9763313609467456, 'f1': 0.9727339719970524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9155722326454033, 'recall': 0.9402697495183044, 'f1': 0.9277566539923954, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9155722326454033, 'recall': 0.9701789264413518, 'f1': 0.942084942084942, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.26666666666666666, 'recall': 0.26666666666666666, 'f1': 0.26666666666666666, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5681818181818182, 'recall': 0.7575757575757576, 'f1': 0.6493506493506495, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9558404558404558, 'recall': 0.9668587896253602, 'f1': 0.9613180515759313, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.95822454308094, 'recall': 0.963254593175853, 'f1': 0.9607329842931936, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.14285714285714285, 'f1': 0.15384615384615383, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9822485207100592, 'recall': 0.9822485207100592, 'f1': 0.9822485207100592, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9068901303538175, 'recall': 0.9383429672447013, 'f1': 0.9223484848484848, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9292543021032504, 'recall': 0.9662027833001988, 'f1': 0.9473684210526316, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.07142857142857142, 'recall': 0.0625, 'f1': 0.06666666666666667, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35294117647058826, 'recall': 0.4, 'f1': 0.37500000000000006, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1': 0.8115942028985507, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9526542324246772, 'recall': 0.9567723342939481, 'f1': 0.9547088425593099, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9246704331450094, 'recall': 0.9460500963391136, 'f1': 0.9352380952380951, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9264150943396227, 'recall': 0.9761431411530815, 'f1': 0.9506292352371734, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2631578947368421, 'recall': 0.3333333333333333, 'f1': 0.29411764705882354, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8181818181818182, 'recall': 0.8181818181818182, 'f1': 0.8181818181818182, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527896995708155, 'recall': 0.9596541786743515, 'f1': 0.9562096195262024, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9455958549222798, 'recall': 0.958005249343832, 'f1': 0.9517601043024773, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.986764705882353, 'recall': 0.9896755162241888, 'f1': 0.9882179675994109, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.977810650887574, 'recall': 0.977810650887574, 'f1': 0.977810650887574, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9119850187265918, 'recall': 0.9383429672447013, 'f1': 0.9249762583095916, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9361702127659575, 'recall': 0.9622266401590457, 'f1': 0.9490196078431373, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.17647058823529413, 'recall': 0.1875, 'f1': 0.1818181818181818, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.5333333333333333, 'f1': 0.4571428571428572, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9735294117647059, 'recall': 0.9792899408284024, 'f1': 0.9764011799410028, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9162011173184358, 'recall': 0.9479768786127167, 'f1': 0.9318181818181819, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.94921875, 'recall': 0.9662027833001988, 'f1': 0.9576354679802955, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.24, 'recall': 0.375, 'f1': 0.2926829268292683, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3829787234042553, 'recall': 0.6, 'f1': 0.4675324675324675, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7941176470588235, 'recall': 0.8181818181818182, 'f1': 0.8059701492537314, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9448373408769448, 'recall': 0.962536023054755, 'f1': 0.953604568165596, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9546044098573282, 'recall': 0.9658792650918635, 'f1': 0.9602087410306589, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9853157121879589, 'recall': 0.9896755162241888, 'f1': 0.9874908020603386, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.14285714285714285, 'f1': 0.16666666666666666, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9794117647058823, 'recall': 0.985207100591716, 'f1': 0.9823008849557522, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9032846715328468, 'recall': 0.953757225433526, 'f1': 0.9278350515463917, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9490196078431372, 'recall': 0.9622266401590457, 'f1': 0.9555774925962486, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2894736842105263, 'recall': 0.6875, 'f1': 0.4074074074074074, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3269230769230769, 'recall': 0.5666666666666667, 'f1': 0.41463414634146345, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.90625, 'recall': 0.8787878787878788, 'f1': 0.8923076923076922, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9598853868194842, 'recall': 0.9654178674351584, 'f1': 0.9626436781609194, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.95703125, 'recall': 0.9645669291338582, 'f1': 0.9607843137254901, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9748892171344166, 'recall': 0.9763313609467456, 'f1': 0.975609756097561, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8985507246376812, 'recall': 0.9556840077071291, 'f1': 0.9262371615312792, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9475728155339805, 'recall': 0.9701789264413518, 'f1': 0.9587426326129667, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.21621621621621623, 'recall': 0.5, 'f1': 0.3018867924528302, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35294117647058826, 'recall': 0.6, 'f1': 0.4444444444444445, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9354838709677419, 'recall': 0.8787878787878788, 'f1': 0.90625, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9669064748201439, 'recall': 0.968299711815562, 'f1': 0.9676025917926565, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633986928104575, 'recall': 0.9671916010498688, 'f1': 0.9652914210870989, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.42857142857142855, 'f1': 0.6, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9214953271028037, 'recall': 0.9499036608863198, 'f1': 0.935483870967742, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9400386847195358, 'recall': 0.9662027833001988, 'f1': 0.9529411764705882, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3888888888888889, 'recall': 0.4375, 'f1': 0.411764705882353, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3617021276595745, 'recall': 0.5666666666666667, 'f1': 0.4415584415584416, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9586894586894587, 'recall': 0.9697406340057637, 'f1': 0.9641833810888253, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.42857142857142855, 'f1': 0.4615384615384615, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705882352941176, 'recall': 0.9763313609467456, 'f1': 0.9734513274336284, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9246704331450094, 'recall': 0.9460500963391136, 'f1': 0.9352380952380951, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9622266401590457, 'recall': 0.9622266401590457, 'f1': 0.9622266401590457, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.4375, 'f1': 0.3181818181818182, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7105263157894737, 'recall': 0.8181818181818182, 'f1': 0.7605633802816901, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642346208869814, 'recall': 0.9711815561959655, 'f1': 0.9676956209619526, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9484536082474226, 'recall': 0.9658792650918635, 'f1': 0.9570871261378414, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823788546255506, 'recall': 0.9867256637168141, 'f1': 0.9845474613686535, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9896449704142012, 'recall': 0.9896449704142012, 'f1': 0.9896449704142012, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9465648854961832, 'recall': 0.9556840077071291, 'f1': 0.9511025886864813, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9569471624266145, 'recall': 0.9721669980119284, 'f1': 0.9644970414201183, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5384615384615384, 'recall': 0.4375, 'f1': 0.4827586206896552, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38461538461538464, 'recall': 0.5, 'f1': 0.4347826086956522, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18181818181818182, 'recall': 0.3333333333333333, 'f1': 0.23529411764705885, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9643366619115549, 'recall': 0.9740634005763689, 'f1': 0.9691756272401433, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530638852672751, 'recall': 0.9593175853018373, 'f1': 0.9561805101373447, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764359351988218, 'recall': 0.9807692307692307, 'f1': 0.9785977859778597, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943502824858757, 'recall': 0.9653179190751445, 'f1': 0.9542857142857143, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9609375, 'recall': 0.9781312127236581, 'f1': 0.9694581280788177, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.967741935483871, 'recall': 0.9090909090909091, 'f1': 0.9374999999999999, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.3333333333333333, 'f1': 0.25, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9670958512160229, 'recall': 0.9740634005763689, 'f1': 0.9705671213208903, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9583333333333334, 'recall': 0.9658792650918635, 'f1': 0.9620915032679739, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9581749049429658, 'recall': 0.9710982658959537, 'f1': 0.9645933014354067, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9724409448818898, 'recall': 0.9821073558648111, 'f1': 0.9772502472799209, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5555555555555556, 'recall': 0.625, 'f1': 0.5882352941176471, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9685264663805436, 'recall': 0.9755043227665706, 'f1': 0.9720028715003589, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9504563233376793, 'recall': 0.9566929133858267, 'f1': 0.9535644211903205, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9562737642585551, 'recall': 0.9691714836223507, 'f1': 0.9626794258373206, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9686274509803922, 'recall': 0.9821073558648111, 'f1': 0.9753208292201382, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5625, 'recall': 0.5625, 'f1': 0.5625, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4722222222222222, 'recall': 0.5666666666666667, 'f1': 0.5151515151515152, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9544807965860598, 'recall': 0.9668587896253602, 'f1': 0.9606299212598425, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9442282749675746, 'recall': 0.9553805774278216, 'f1': 0.949771689497717, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943609022556391, 'recall': 0.9672447013487476, 'f1': 0.9552806850618459, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9610136452241715, 'recall': 0.9801192842942346, 'f1': 0.9704724409448818, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.47368421052631576, 'recall': 0.5625, 'f1': 0.5142857142857142, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3695652173913043, 'recall': 0.5666666666666667, 'f1': 0.4473684210526315, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8823529411764706, 'recall': 0.9090909090909091, 'f1': 0.8955223880597014, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9642857142857143, 'recall': 0.9726224783861671, 'f1': 0.9684361549497849, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471649484536082, 'recall': 0.9645669291338582, 'f1': 0.9557867360208062, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647058823529412, 'recall': 0.9781312127236581, 'f1': 0.9713721618953604, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.40476190476190477, 'recall': 0.5666666666666667, 'f1': 0.4722222222222222, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2727272727272727, 'recall': 0.5, 'f1': 0.3529411764705882, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656160458452722, 'recall': 0.9711815561959655, 'f1': 0.9683908045977012, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9583333333333334, 'recall': 0.9658792650918635, 'f1': 0.9620915032679739, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1900] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778761061946902, 'recall': 0.9807692307692307, 'f1': 0.9793205317577548, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9416195856873822, 'recall': 0.9633911368015414, 'f1': 0.9523809523809523, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.958904109589041, 'recall': 0.974155069582505, 'f1': 0.9664694280078895, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.625, 'f1': 0.5555555555555556, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3617021276595745, 'recall': 0.5666666666666667, 'f1': 0.4415584415584416, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.18181818181818182, 'recall': 0.3333333333333333, 'f1': 0.23529411764705885, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9629629629629629, 'recall': 0.9740634005763689, 'f1': 0.9684813753581661, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9546632124352331, 'recall': 0.9671916010498688, 'f1': 0.9608865710560626, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.42857142857142855, 'f1': 0.42857142857142855, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.983751846381093, 'recall': 0.985207100591716, 'f1': 0.9844789356984479, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.946969696969697, 'recall': 0.9633911368015414, 'f1': 0.9551098376313275, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9666011787819253, 'recall': 0.9781312127236581, 'f1': 0.9723320158102767, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4146341463414634, 'recall': 0.5666666666666667, 'f1': 0.47887323943661975, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9596354166666666, 'recall': 0.9671916010498688, 'f1': 0.9633986928104575, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.982274741506647, 'recall': 0.9837278106508875, 'f1': 0.9830007390983001, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9471698113207547, 'recall': 0.9672447013487476, 'f1': 0.9571020019065777, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9666666666666667, 'recall': 0.9801192842942346, 'f1': 0.9733464955577492, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45, 'recall': 0.5625, 'f1': 0.5, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.47368421052631576, 'recall': 0.6, 'f1': 0.5294117647058824, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9655667144906743, 'recall': 0.9697406340057637, 'f1': 0.9676491732566499, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9521345407503234, 'recall': 0.9658792650918635, 'f1': 0.9589576547231271, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9867452135493373, 'recall': 0.9882005899705014, 'f1': 0.9874723655121592, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1': 0.4, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807692307692307, 'recall': 0.9807692307692307, 'f1': 0.9807692307692307, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9527410207939508, 'recall': 0.9710982658959537, 'f1': 0.9618320610687022, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9705304518664047, 'recall': 0.9821073558648111, 'f1': 0.9762845849802371, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.625, 'f1': 0.5555555555555556, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4186046511627907, 'recall': 0.6, 'f1': 0.49315068493150693, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8484848484848485, 'recall': 0.8484848484848485, 'f1': 0.8484848484848486, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.5, 'f1': 0.37499999999999994, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9641319942611191, 'recall': 0.968299711815562, 'f1': 0.9662113587347233, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9472329472329473, 'recall': 0.9658792650918635, 'f1': 0.9564652371669916, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9764705882352941, 'recall': 0.9822485207100592, 'f1': 0.9793510324483775, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9283088235294118, 'recall': 0.9730250481695568, 'f1': 0.9501411100658512, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9555984555984556, 'recall': 0.9840954274353877, 'f1': 0.9696376101860921, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38461538461538464, 'recall': 0.625, 'f1': 0.4761904761904762, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3673469387755102, 'recall': 0.6, 'f1': 0.45569620253164556, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9727793696275072, 'recall': 0.978386167146974, 'f1': 0.975574712643678, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9597402597402598, 'recall': 0.9698162729658792, 'f1': 0.9647519582245431, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9882352941176471, 'recall': 0.9911504424778761, 'f1': 0.9896907216494845, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'f1': 0.30769230769230765, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000 (score: 0.9693140794223826).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9593639575971732, 'recall': 0.9667655786350149, 'f1': 0.9630505468519067, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8362427265170407, 'recall': 0.9195612431444241, 'f1': 0.8759251197213757, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9079925650557621, 'recall': 0.9476236663433559, 'f1': 0.9273849074513526, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2283464566929134, 'recall': 0.4603174603174603, 'f1': 0.30526315789473685, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3076923076923077, 'recall': 0.5063291139240507, 'f1': 0.3827751196172249, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8478260869565217, 'recall': 0.9069767441860465, 'f1': 0.8764044943820224, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5882352941176471, 'recall': 0.6060606060606061, 'f1': 0.5970149253731343, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9417091114883984, 'recall': 0.9524899828277046, 'f1': 0.9470688673875926, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945213060320974, 'recall': 0.9552572706935123, 'f1': 0.9502086230876217, 'number': 1788}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9823261117445838, 'recall': 0.9840091376356368, 'f1': 0.9831669044222539, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9807976366322009, 'recall': 0.9822485207100592, 'f1': 0.9815225424981524, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.945179584120983, 'recall': 0.9633911368015414, 'f1': 0.9541984732824428, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9647058823529412, 'recall': 0.9781312127236581, 'f1': 0.9713721618953604, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42105263157894735, 'recall': 0.5, 'f1': 0.45714285714285713, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.40476190476190477, 'recall': 0.5666666666666667, 'f1': 0.4722222222222222, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2727272727272727, 'recall': 0.5, 'f1': 0.3529411764705882, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656160458452722, 'recall': 0.9711815561959655, 'f1': 0.9683908045977012, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9583333333333334, 'recall': 0.9658792650918635, 'f1': 0.9620915032679739, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838472834067548, 'recall': 0.9882005899705014, 'f1': 0.986019131714496, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "loading file sentencepiece.bpe.model from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"HueyNemud/das22-10-camembert_pretrained\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O+O\",\n",
      "    \"1\": \"I-b_PER+O\",\n",
      "    \"2\": \"I-i_PER+O\",\n",
      "    \"3\": \"I-b_PER+b_TITREH\",\n",
      "    \"4\": \"I-i_PER+b_TITREH\",\n",
      "    \"5\": \"I-i_PER+i_TITREH\",\n",
      "    \"6\": \"I-b_ACT+O\",\n",
      "    \"7\": \"I-i_ACT+O\",\n",
      "    \"8\": \"I-b_DESC+O\",\n",
      "    \"9\": \"I-i_DESC+O\",\n",
      "    \"10\": \"I-b_DESC+b_ACT\",\n",
      "    \"11\": \"I-i_DESC+b_ACT\",\n",
      "    \"12\": \"I-i_DESC+i_ACT\",\n",
      "    \"13\": \"I-b_DESC+b_TITREP\",\n",
      "    \"14\": \"I-i_DESC+b_TITREP\",\n",
      "    \"15\": \"I-i_DESC+i_TITREP\",\n",
      "    \"16\": \"I-b_SPAT+O\",\n",
      "    \"17\": \"I-i_SPAT+O\",\n",
      "    \"18\": \"I-b_SPAT+b_LOC\",\n",
      "    \"19\": \"I-i_SPAT+b_LOC\",\n",
      "    \"20\": \"I-i_SPAT+i_LOC\",\n",
      "    \"21\": \"I-b_SPAT+b_CARDINAL\",\n",
      "    \"22\": \"I-i_SPAT+b_CARDINAL\",\n",
      "    \"23\": \"I-i_SPAT+i_CARDINAL\",\n",
      "    \"24\": \"I-b_SPAT+b_FT\",\n",
      "    \"25\": \"I-i_SPAT+b_FT\",\n",
      "    \"26\": \"I-i_SPAT+i_FT\",\n",
      "    \"27\": \"I-b_TITRE+O\",\n",
      "    \"28\": \"I-i_TITRE+O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-b_ACT+O\": 6,\n",
      "    \"I-b_DESC+O\": 8,\n",
      "    \"I-b_DESC+b_ACT\": 10,\n",
      "    \"I-b_DESC+b_TITREP\": 13,\n",
      "    \"I-b_PER+O\": 1,\n",
      "    \"I-b_PER+b_TITREH\": 3,\n",
      "    \"I-b_SPAT+O\": 16,\n",
      "    \"I-b_SPAT+b_CARDINAL\": 21,\n",
      "    \"I-b_SPAT+b_FT\": 24,\n",
      "    \"I-b_SPAT+b_LOC\": 18,\n",
      "    \"I-b_TITRE+O\": 27,\n",
      "    \"I-i_ACT+O\": 7,\n",
      "    \"I-i_DESC+O\": 9,\n",
      "    \"I-i_DESC+b_ACT\": 11,\n",
      "    \"I-i_DESC+b_TITREP\": 14,\n",
      "    \"I-i_DESC+i_ACT\": 12,\n",
      "    \"I-i_DESC+i_TITREP\": 15,\n",
      "    \"I-i_PER+O\": 2,\n",
      "    \"I-i_PER+b_TITREH\": 4,\n",
      "    \"I-i_PER+i_TITREH\": 5,\n",
      "    \"I-i_SPAT+O\": 17,\n",
      "    \"I-i_SPAT+b_CARDINAL\": 22,\n",
      "    \"I-i_SPAT+b_FT\": 25,\n",
      "    \"I-i_SPAT+b_LOC\": 19,\n",
      "    \"I-i_SPAT+i_CARDINAL\": 23,\n",
      "    \"I-i_SPAT+i_FT\": 26,\n",
      "    \"I-i_SPAT+i_LOC\": 20,\n",
      "    \"I-i_TITRE+O\": 28,\n",
      "    \"O+O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /lrde/home2/stual/.cache/huggingface/hub/models--HueyNemud--das22-10-camembert_pretrained/snapshots/a54f5177528f2e319b97b1f3960d0a00fd9e3ef3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6084\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 110053661\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1400' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1400/5000 06:00 < 15:28, 3.88 it/s, Epoch 3/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision-l1</th>\n",
       "      <th>Recall-l1</th>\n",
       "      <th>F1-l1</th>\n",
       "      <th>Accuracy-l1</th>\n",
       "      <th>Precision-l2</th>\n",
       "      <th>Recall-l2</th>\n",
       "      <th>F1-l2</th>\n",
       "      <th>Accuracy-l2</th>\n",
       "      <th>Precision-das</th>\n",
       "      <th>Recall-das</th>\n",
       "      <th>F1-das</th>\n",
       "      <th>Accuracy-das</th>\n",
       "      <th>Precision-l1l2</th>\n",
       "      <th>Recall-l1l2</th>\n",
       "      <th>F1-l1l2</th>\n",
       "      <th>Accuracy-l1l2</th>\n",
       "      <th>Precision-all</th>\n",
       "      <th>Recall-all</th>\n",
       "      <th>F1-all</th>\n",
       "      <th>Accuracy-all</th>\n",
       "      <th>Per</th>\n",
       "      <th>Act</th>\n",
       "      <th>Act L1</th>\n",
       "      <th>Act L2</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Titreh</th>\n",
       "      <th>Titrep</th>\n",
       "      <th>Spat</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Cardinal</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.664550</td>\n",
       "      <td>0.943617</td>\n",
       "      <td>0.930816</td>\n",
       "      <td>0.937173</td>\n",
       "      <td>0.933814</td>\n",
       "      <td>0.913244</td>\n",
       "      <td>0.933858</td>\n",
       "      <td>0.923436</td>\n",
       "      <td>0.944951</td>\n",
       "      <td>0.944672</td>\n",
       "      <td>0.920772</td>\n",
       "      <td>0.932569</td>\n",
       "      <td>0.966338</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.929609</td>\n",
       "      <td>0.930475</td>\n",
       "      <td>0.950772</td>\n",
       "      <td>0.931699</td>\n",
       "      <td>0.927637</td>\n",
       "      <td>0.929664</td>\n",
       "      <td>0.934067</td>\n",
       "      <td>0.926729</td>\n",
       "      <td>0.928089</td>\n",
       "      <td>0.927409</td>\n",
       "      <td>0.955644</td>\n",
       "      <td>{'precision': 0.9344978165938864, 'recall': 0.9497041420118343, 'f1': 0.942039618488628, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8791208791208791, 'recall': 0.9248554913294798, 'f1': 0.9014084507042254, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8791208791208791, 'recall': 0.9542743538767395, 'f1': 0.9151572926596758, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9188811188811189, 'recall': 0.946685878962536, 'f1': 0.9325762952448545, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9326424870466321, 'recall': 0.9448818897637795, 'f1': 0.9387222946544981, 'number': 762}</td>\n",
       "      <td>{'precision': 0.958092485549133, 'recall': 0.9778761061946902, 'f1': 0.9678832116788321, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386687</td>\n",
       "      <td>0.947656</td>\n",
       "      <td>0.941442</td>\n",
       "      <td>0.944539</td>\n",
       "      <td>0.939256</td>\n",
       "      <td>0.924820</td>\n",
       "      <td>0.942782</td>\n",
       "      <td>0.933715</td>\n",
       "      <td>0.948874</td>\n",
       "      <td>0.944293</td>\n",
       "      <td>0.925433</td>\n",
       "      <td>0.934768</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.942644</td>\n",
       "      <td>0.940543</td>\n",
       "      <td>0.956720</td>\n",
       "      <td>0.937229</td>\n",
       "      <td>0.941587</td>\n",
       "      <td>0.939403</td>\n",
       "      <td>0.939636</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.935134</td>\n",
       "      <td>0.934174</td>\n",
       "      <td>0.958112</td>\n",
       "      <td>{'precision': 0.9355783308931186, 'recall': 0.9452662721893491, 'f1': 0.9403973509933775, 'number': 676}</td>\n",
       "      <td>{'precision': 0.8876811594202898, 'recall': 0.9441233140655106, 'f1': 0.9150326797385622, 'number': 519}</td>\n",
       "      <td>{'precision': 0.8876811594202898, 'recall': 0.974155069582505, 'f1': 0.928909952606635, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.03333333333333333, 'f1': 0.05714285714285715, 'number': 30}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9487179487179487, 'recall': 0.9596541786743515, 'f1': 0.9541547277936963, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9260204081632653, 'recall': 0.952755905511811, 'f1': 0.9391979301423026, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9651162790697675, 'recall': 0.9793510324483776, 'f1': 0.9721815519765741, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268705</td>\n",
       "      <td>0.953107</td>\n",
       "      <td>0.946643</td>\n",
       "      <td>0.949864</td>\n",
       "      <td>0.951025</td>\n",
       "      <td>0.934905</td>\n",
       "      <td>0.957480</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.938288</td>\n",
       "      <td>0.941411</td>\n",
       "      <td>0.939847</td>\n",
       "      <td>0.973931</td>\n",
       "      <td>0.960565</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.961102</td>\n",
       "      <td>0.971906</td>\n",
       "      <td>0.941717</td>\n",
       "      <td>0.953211</td>\n",
       "      <td>0.947429</td>\n",
       "      <td>0.951278</td>\n",
       "      <td>0.936379</td>\n",
       "      <td>0.950396</td>\n",
       "      <td>0.943336</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>{'precision': 0.9689807976366323, 'recall': 0.9704142011834319, 'f1': 0.9696969696969697, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9190207156308852, 'recall': 0.9402697495183044, 'f1': 0.9295238095238095, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9190207156308852, 'recall': 0.9701789264413518, 'f1': 0.9439071566731141, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 30}</td>\n",
       "      <td>{'precision': 0.29545454545454547, 'recall': 0.3939393939393939, 'f1': 0.3376623376623376, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9530583214793741, 'recall': 0.9654178674351584, 'f1': 0.9591982820329277, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9430051813471503, 'recall': 0.9553805774278216, 'f1': 0.9491525423728813, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214816</td>\n",
       "      <td>0.954690</td>\n",
       "      <td>0.952747</td>\n",
       "      <td>0.953717</td>\n",
       "      <td>0.953683</td>\n",
       "      <td>0.935252</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.945209</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.952445</td>\n",
       "      <td>0.946738</td>\n",
       "      <td>0.949583</td>\n",
       "      <td>0.974690</td>\n",
       "      <td>0.962454</td>\n",
       "      <td>0.964246</td>\n",
       "      <td>0.963349</td>\n",
       "      <td>0.973678</td>\n",
       "      <td>0.947353</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.952147</td>\n",
       "      <td>0.954062</td>\n",
       "      <td>0.942716</td>\n",
       "      <td>0.951570</td>\n",
       "      <td>0.947122</td>\n",
       "      <td>0.967477</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9102803738317757, 'recall': 0.9383429672447013, 'f1': 0.9240986717267552, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9102803738317757, 'recall': 0.9681908548707754, 'f1': 0.9383429672447013, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.1935483870967742, 'recall': 0.2, 'f1': 0.19672131147540983, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5365853658536586, 'recall': 0.6666666666666666, 'f1': 0.5945945945945946, 'number': 33}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9513590844062947, 'recall': 0.9582132564841499, 'f1': 0.9547738693467337, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9491525423728814, 'recall': 0.9553805774278216, 'f1': 0.9522563767168084, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.203907</td>\n",
       "      <td>0.951609</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.953756</td>\n",
       "      <td>0.955328</td>\n",
       "      <td>0.938880</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.949117</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.933027</td>\n",
       "      <td>0.946072</td>\n",
       "      <td>0.939504</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>0.955383</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.960163</td>\n",
       "      <td>0.974184</td>\n",
       "      <td>0.940639</td>\n",
       "      <td>0.957861</td>\n",
       "      <td>0.949172</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.936311</td>\n",
       "      <td>0.953625</td>\n",
       "      <td>0.944889</td>\n",
       "      <td>0.968173</td>\n",
       "      <td>{'precision': 0.9648093841642229, 'recall': 0.9733727810650887, 'f1': 0.9690721649484536, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9266917293233082, 'recall': 0.9499036608863198, 'f1': 0.9381541389153186, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}</td>\n",
       "      <td>{'precision': 0.35714285714285715, 'recall': 0.3333333333333333, 'f1': 0.3448275862068965, 'number': 30}</td>\n",
       "      <td>{'precision': 0.4166666666666667, 'recall': 0.6060606060606061, 'f1': 0.4938271604938272, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9461756373937678, 'recall': 0.962536023054755, 'f1': 0.9542857142857143, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.193918</td>\n",
       "      <td>0.951170</td>\n",
       "      <td>0.955686</td>\n",
       "      <td>0.953423</td>\n",
       "      <td>0.952670</td>\n",
       "      <td>0.931795</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>0.942672</td>\n",
       "      <td>0.961655</td>\n",
       "      <td>0.945803</td>\n",
       "      <td>0.952730</td>\n",
       "      <td>0.949254</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>0.954781</td>\n",
       "      <td>0.959404</td>\n",
       "      <td>0.957087</td>\n",
       "      <td>0.968362</td>\n",
       "      <td>0.944190</td>\n",
       "      <td>0.958733</td>\n",
       "      <td>0.951406</td>\n",
       "      <td>0.953050</td>\n",
       "      <td>0.937915</td>\n",
       "      <td>0.953331</td>\n",
       "      <td>0.945560</td>\n",
       "      <td>0.967540</td>\n",
       "      <td>{'precision': 0.9560117302052786, 'recall': 0.9644970414201184, 'f1': 0.9602356406480118, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9172932330827067, 'recall': 0.9402697495183044, 'f1': 0.928639391056137, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9207547169811321, 'recall': 0.9701789264413518, 'f1': 0.9448209099709584, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.24242424242424243, 'recall': 0.26666666666666666, 'f1': 0.253968253968254, 'number': 30}</td>\n",
       "      <td>{'precision': 0.5652173913043478, 'recall': 0.7878787878787878, 'f1': 0.6582278481012658, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.948936170212766, 'recall': 0.9639769452449568, 'f1': 0.956397426733381, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9457364341085271, 'recall': 0.9606299212598425, 'f1': 0.9531249999999999, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.167527</td>\n",
       "      <td>0.957619</td>\n",
       "      <td>0.960434</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.937020</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.948678</td>\n",
       "      <td>0.965452</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.973931</td>\n",
       "      <td>0.960326</td>\n",
       "      <td>0.964618</td>\n",
       "      <td>0.962467</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.950834</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>0.955918</td>\n",
       "      <td>0.958238</td>\n",
       "      <td>0.944428</td>\n",
       "      <td>0.957734</td>\n",
       "      <td>0.951035</td>\n",
       "      <td>0.969691</td>\n",
       "      <td>{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9020332717190388, 'recall': 0.9402697495183044, 'f1': 0.9207547169811321, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9104477611940298, 'recall': 0.9701789264413518, 'f1': 0.9393647738209817, 'number': 503}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2647058823529412, 'recall': 0.3, 'f1': 0.28125, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7428571428571429, 'recall': 0.7878787878787878, 'f1': 0.7647058823529412, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1': 0.4444444444444444, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9558404558404558, 'recall': 0.9668587896253602, 'f1': 0.9613180515759313, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9458762886597938, 'recall': 0.963254593175853, 'f1': 0.954486345903771, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.166053</td>\n",
       "      <td>0.959317</td>\n",
       "      <td>0.964956</td>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.956087</td>\n",
       "      <td>0.954922</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.961147</td>\n",
       "      <td>0.964819</td>\n",
       "      <td>0.945395</td>\n",
       "      <td>0.956724</td>\n",
       "      <td>0.951026</td>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.968343</td>\n",
       "      <td>0.967262</td>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.954231</td>\n",
       "      <td>0.963383</td>\n",
       "      <td>0.958785</td>\n",
       "      <td>0.957099</td>\n",
       "      <td>0.950725</td>\n",
       "      <td>0.962724</td>\n",
       "      <td>0.956687</td>\n",
       "      <td>0.967477</td>\n",
       "      <td>{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9168207024029574, 'recall': 0.9556840077071291, 'f1': 0.9358490566037737, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9461538461538461, 'recall': 0.9781312127236581, 'f1': 0.9618768328445748, 'number': 503}</td>\n",
       "      <td>{'precision': 0.19047619047619047, 'recall': 0.25, 'f1': 0.2162162162162162, 'number': 16}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8709677419354839, 'recall': 0.8181818181818182, 'f1': 0.84375, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9641833810888252, 'recall': 0.9697406340057637, 'f1': 0.9669540229885057, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9420849420849421, 'recall': 0.9606299212598425, 'f1': 0.9512670565302145, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.966381</td>\n",
       "      <td>0.965831</td>\n",
       "      <td>0.951081</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.960229</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.952037</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>0.967037</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.969731</td>\n",
       "      <td>0.981144</td>\n",
       "      <td>0.958585</td>\n",
       "      <td>0.968614</td>\n",
       "      <td>0.963573</td>\n",
       "      <td>0.966464</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>0.967420</td>\n",
       "      <td>0.959395</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>{'precision': 0.9750367107195301, 'recall': 0.9822485207100592, 'f1': 0.978629329403095, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9314814814814815, 'recall': 0.9691714836223507, 'f1': 0.9499527856468366, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9518304431599229, 'recall': 0.9821073558648111, 'f1': 0.9667318982387475, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.5625, 'f1': 0.4864864864864864, 'number': 16}</td>\n",
       "      <td>{'precision': 0.36585365853658536, 'recall': 0.5, 'f1': 0.4225352112676056, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8205128205128205, 'recall': 0.9696969696969697, 'f1': 0.8888888888888888, 'number': 33}</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9614835948644793, 'recall': 0.9711815561959655, 'f1': 0.9663082437275986, 'number': 694}</td>\n",
       "      <td>{'precision': 0.953185955786736, 'recall': 0.9619422572178478, 'f1': 0.9575440888308295, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.175086</td>\n",
       "      <td>0.964916</td>\n",
       "      <td>0.963825</td>\n",
       "      <td>0.964371</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.952257</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>0.957724</td>\n",
       "      <td>0.967730</td>\n",
       "      <td>0.953612</td>\n",
       "      <td>0.958056</td>\n",
       "      <td>0.955829</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.962551</td>\n",
       "      <td>0.966853</td>\n",
       "      <td>0.964697</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.958345</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.952852</td>\n",
       "      <td>0.960963</td>\n",
       "      <td>0.956890</td>\n",
       "      <td>0.970893</td>\n",
       "      <td>{'precision': 0.9633967789165446, 'recall': 0.9733727810650887, 'f1': 0.9683590875643855, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}</td>\n",
       "      <td>{'precision': 0.95703125, 'recall': 0.974155069582505, 'f1': 0.9655172413793103, 'number': 503}</td>\n",
       "      <td>{'precision': 0.5333333333333333, 'recall': 0.5, 'f1': 0.5161290322580646, 'number': 16}</td>\n",
       "      <td>{'precision': 0.5862068965517241, 'recall': 0.5666666666666667, 'f1': 0.576271186440678, 'number': 30}</td>\n",
       "      <td>{'precision': 0.7297297297297297, 'recall': 0.8181818181818182, 'f1': 0.7714285714285715, 'number': 33}</td>\n",
       "      <td>{'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1': 0.4444444444444444, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9530583214793741, 'recall': 0.9654178674351584, 'f1': 0.9591982820329277, 'number': 694}</td>\n",
       "      <td>{'precision': 0.954248366013072, 'recall': 0.958005249343832, 'f1': 0.9561231172233137, 'number': 762}</td>\n",
       "      <td>{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.156365</td>\n",
       "      <td>0.961022</td>\n",
       "      <td>0.969930</td>\n",
       "      <td>0.965455</td>\n",
       "      <td>0.960643</td>\n",
       "      <td>0.957535</td>\n",
       "      <td>0.970604</td>\n",
       "      <td>0.964025</td>\n",
       "      <td>0.969501</td>\n",
       "      <td>0.952725</td>\n",
       "      <td>0.966045</td>\n",
       "      <td>0.959339</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.965989</td>\n",
       "      <td>0.973184</td>\n",
       "      <td>0.969573</td>\n",
       "      <td>0.979119</td>\n",
       "      <td>0.955378</td>\n",
       "      <td>0.970648</td>\n",
       "      <td>0.962952</td>\n",
       "      <td>0.961149</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.968594</td>\n",
       "      <td>0.961959</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>{'precision': 0.9780058651026393, 'recall': 0.9866863905325444, 'f1': 0.9823269513991164, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9683794466403162, 'recall': 0.974155069582505, 'f1': 0.9712586719524281, 'number': 503}</td>\n",
       "      <td>{'precision': 0.42857142857142855, 'recall': 0.5625, 'f1': 0.4864864864864864, 'number': 16}</td>\n",
       "      <td>{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.168442</td>\n",
       "      <td>0.962065</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.965533</td>\n",
       "      <td>0.958618</td>\n",
       "      <td>0.949948</td>\n",
       "      <td>0.966404</td>\n",
       "      <td>0.958106</td>\n",
       "      <td>0.965958</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>0.954741</td>\n",
       "      <td>0.970640</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>0.968715</td>\n",
       "      <td>0.966196</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.956047</td>\n",
       "      <td>0.967161</td>\n",
       "      <td>0.961572</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.948888</td>\n",
       "      <td>0.964485</td>\n",
       "      <td>0.956623</td>\n",
       "      <td>0.968299</td>\n",
       "      <td>{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9236499068901304, 'recall': 0.9556840077071291, 'f1': 0.9393939393939394, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9494163424124513, 'recall': 0.9701789264413518, 'f1': 0.95968534906588, 'number': 503}</td>\n",
       "      <td>{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}</td>\n",
       "      <td>{'precision': 0.36363636363636365, 'recall': 0.5333333333333333, 'f1': 0.43243243243243246, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}</td>\n",
       "      <td>{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9572039942938659, 'recall': 0.9668587896253602, 'f1': 0.9620071684587814, 'number': 694}</td>\n",
       "      <td>{'precision': 0.944516129032258, 'recall': 0.9606299212598425, 'f1': 0.9525048796356538, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9780701754385965, 'recall': 0.9867256637168141, 'f1': 0.9823788546255506, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.171261</td>\n",
       "      <td>0.960414</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.957226</td>\n",
       "      <td>0.937468</td>\n",
       "      <td>0.960105</td>\n",
       "      <td>0.948651</td>\n",
       "      <td>0.963174</td>\n",
       "      <td>0.948617</td>\n",
       "      <td>0.958722</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.970893</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.968343</td>\n",
       "      <td>0.964213</td>\n",
       "      <td>0.977474</td>\n",
       "      <td>0.952080</td>\n",
       "      <td>0.964255</td>\n",
       "      <td>0.958129</td>\n",
       "      <td>0.957732</td>\n",
       "      <td>0.942346</td>\n",
       "      <td>0.959495</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.967034</td>\n",
       "      <td>{'precision': 0.9720588235294118, 'recall': 0.977810650887574, 'f1': 0.9749262536873157, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9146567717996289, 'recall': 0.9499036608863198, 'f1': 0.9319470699432891, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9314285714285714, 'recall': 0.9721669980119284, 'f1': 0.9513618677042801, 'number': 503}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.25, 'f1': 0.26666666666666666, 'number': 16}</td>\n",
       "      <td>{'precision': 0.2894736842105263, 'recall': 0.36666666666666664, 'f1': 0.32352941176470584, 'number': 30}</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.8484848484848485, 'f1': 0.823529411764706, 'number': 33}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}</td>\n",
       "      <td>{'precision': 0.943502824858757, 'recall': 0.962536023054755, 'f1': 0.9529243937232525, 'number': 694}</td>\n",
       "      <td>{'precision': 0.944516129032258, 'recall': 0.9606299212598425, 'f1': 0.9525048796356538, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}</td>\n",
       "      <td>{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.150995</td>\n",
       "      <td>0.958754</td>\n",
       "      <td>0.966991</td>\n",
       "      <td>0.962855</td>\n",
       "      <td>0.960137</td>\n",
       "      <td>0.946989</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>0.956341</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.959387</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.960385</td>\n",
       "      <td>0.966108</td>\n",
       "      <td>0.963238</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>0.950158</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.957011</td>\n",
       "      <td>0.961023</td>\n",
       "      <td>0.944988</td>\n",
       "      <td>0.963017</td>\n",
       "      <td>0.953918</td>\n",
       "      <td>0.971969</td>\n",
       "      <td>{'precision': 0.9779086892488954, 'recall': 0.9822485207100592, 'f1': 0.9800738007380073, 'number': 676}</td>\n",
       "      <td>{'precision': 0.9099264705882353, 'recall': 0.953757225433526, 'f1': 0.9313264346190028, 'number': 519}</td>\n",
       "      <td>{'precision': 0.9549019607843138, 'recall': 0.9681908548707754, 'f1': 0.9615004935834156, 'number': 503}</td>\n",
       "      <td>{'precision': 0.23529411764705882, 'recall': 0.5, 'f1': 0.31999999999999995, 'number': 16}</td>\n",
       "      <td>{'precision': 0.3090909090909091, 'recall': 0.5666666666666667, 'f1': 0.39999999999999997, 'number': 30}</td>\n",
       "      <td>{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}</td>\n",
       "      <td>{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}</td>\n",
       "      <td>{'precision': 0.9442282749675746, 'recall': 0.9553805774278216, 'f1': 0.949771689497717, 'number': 762}</td>\n",
       "      <td>{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.42857142857142855, 'f1': 0.6, 'number': 7}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9344978165938864, 'recall': 0.9497041420118343, 'f1': 0.942039618488628, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8791208791208791, 'recall': 0.9248554913294798, 'f1': 0.9014084507042254, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8791208791208791, 'recall': 0.9542743538767395, 'f1': 0.9151572926596758, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9188811188811189, 'recall': 0.946685878962536, 'f1': 0.9325762952448545, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9326424870466321, 'recall': 0.9448818897637795, 'f1': 0.9387222946544981, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.958092485549133, 'recall': 0.9778761061946902, 'f1': 0.9678832116788321, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9355783308931186, 'recall': 0.9452662721893491, 'f1': 0.9403973509933775, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8876811594202898, 'recall': 0.9441233140655106, 'f1': 0.9150326797385622, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8876811594202898, 'recall': 0.974155069582505, 'f1': 0.928909952606635, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.03333333333333333, 'f1': 0.05714285714285715, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9487179487179487, 'recall': 0.9596541786743515, 'f1': 0.9541547277936963, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9260204081632653, 'recall': 0.952755905511811, 'f1': 0.9391979301423026, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9651162790697675, 'recall': 0.9793510324483776, 'f1': 0.9721815519765741, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9689807976366323, 'recall': 0.9704142011834319, 'f1': 0.9696969696969697, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9190207156308852, 'recall': 0.9402697495183044, 'f1': 0.9295238095238095, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9190207156308852, 'recall': 0.9701789264413518, 'f1': 0.9439071566731141, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.29545454545454547, 'recall': 0.3939393939393939, 'f1': 0.3376623376623376, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530583214793741, 'recall': 0.9654178674351584, 'f1': 0.9591982820329277, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9430051813471503, 'recall': 0.9553805774278216, 'f1': 0.9491525423728813, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9795620437956204, 'recall': 0.9896755162241888, 'f1': 0.9845928099779897, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9102803738317757, 'recall': 0.9383429672447013, 'f1': 0.9240986717267552, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9102803738317757, 'recall': 0.9681908548707754, 'f1': 0.9383429672447013, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.1935483870967742, 'recall': 0.2, 'f1': 0.19672131147540983, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5365853658536586, 'recall': 0.6666666666666666, 'f1': 0.5945945945945946, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9513590844062947, 'recall': 0.9582132564841499, 'f1': 0.9547738693467337, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9491525423728814, 'recall': 0.9553805774278216, 'f1': 0.9522563767168084, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.14285714285714285, 'f1': 0.22222222222222224, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9648093841642229, 'recall': 0.9733727810650887, 'f1': 0.9690721649484536, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9266917293233082, 'recall': 0.9499036608863198, 'f1': 0.9381541389153186, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9265536723163842, 'recall': 0.9781312127236581, 'f1': 0.9516441005802708, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.0625, 'f1': 0.11764705882352941, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.35714285714285715, 'recall': 0.3333333333333333, 'f1': 0.3448275862068965, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4166666666666667, 'recall': 0.6060606060606061, 'f1': 0.4938271604938272, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9461756373937678, 'recall': 0.962536023054755, 'f1': 0.9542857142857143, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9295774647887324, 'recall': 0.952755905511811, 'f1': 0.9410239792611794, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838709677419355, 'recall': 0.9896755162241888, 'f1': 0.9867647058823529, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9560117302052786, 'recall': 0.9644970414201184, 'f1': 0.9602356406480118, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9172932330827067, 'recall': 0.9402697495183044, 'f1': 0.928639391056137, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9207547169811321, 'recall': 0.9701789264413518, 'f1': 0.9448209099709584, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.24242424242424243, 'recall': 0.26666666666666666, 'f1': 0.253968253968254, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5652173913043478, 'recall': 0.7878787878787878, 'f1': 0.6582278481012658, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.948936170212766, 'recall': 0.9639769452449568, 'f1': 0.956397426733381, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9457364341085271, 'recall': 0.9606299212598425, 'f1': 0.9531249999999999, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809663250366032, 'recall': 0.9882005899705014, 'f1': 0.9845701689933871, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.25, 'recall': 0.14285714285714285, 'f1': 0.18181818181818182, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9720998531571219, 'recall': 0.9792899408284024, 'f1': 0.9756816507000737, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9020332717190388, 'recall': 0.9402697495183044, 'f1': 0.9207547169811321, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9104477611940298, 'recall': 0.9701789264413518, 'f1': 0.9393647738209817, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2647058823529412, 'recall': 0.3, 'f1': 0.28125, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7428571428571429, 'recall': 0.7878787878787878, 'f1': 0.7647058823529412, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1': 0.4444444444444444, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9558404558404558, 'recall': 0.9668587896253602, 'f1': 0.9613180515759313, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9458762886597938, 'recall': 0.963254593175853, 'f1': 0.954486345903771, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9852941176470589, 'recall': 0.9882005899705014, 'f1': 0.9867452135493373, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9793205317577548, 'recall': 0.9807692307692307, 'f1': 0.9800443458980044, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9168207024029574, 'recall': 0.9556840077071291, 'f1': 0.9358490566037737, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9461538461538461, 'recall': 0.9781312127236581, 'f1': 0.9618768328445748, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.19047619047619047, 'recall': 0.25, 'f1': 0.2162162162162162, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5, 'f1': 0.4615384615384615, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8709677419354839, 'recall': 0.8181818181818182, 'f1': 0.84375, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9641833810888252, 'recall': 0.9697406340057637, 'f1': 0.9669540229885057, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9420849420849421, 'recall': 0.9606299212598425, 'f1': 0.9512670565302145, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809941520467836, 'recall': 0.9896755162241888, 'f1': 0.9853157121879589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750367107195301, 'recall': 0.9822485207100592, 'f1': 0.978629329403095, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9314814814814815, 'recall': 0.9691714836223507, 'f1': 0.9499527856468366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9518304431599229, 'recall': 0.9821073558648111, 'f1': 0.9667318982387475, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5625, 'f1': 0.4864864864864864, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36585365853658536, 'recall': 0.5, 'f1': 0.4225352112676056, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8205128205128205, 'recall': 0.9696969696969697, 'f1': 0.8888888888888888, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614835948644793, 'recall': 0.9711815561959655, 'f1': 0.9663082437275986, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.953185955786736, 'recall': 0.9619422572178478, 'f1': 0.9575440888308295, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-800] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9633967789165446, 'recall': 0.9733727810650887, 'f1': 0.9683590875643855, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9449715370018975, 'recall': 0.9595375722543352, 'f1': 0.9521988527724664, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.95703125, 'recall': 0.974155069582505, 'f1': 0.9655172413793103, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5333333333333333, 'recall': 0.5, 'f1': 0.5161290322580646, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5862068965517241, 'recall': 0.5666666666666667, 'f1': 0.576271186440678, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7297297297297297, 'recall': 0.8181818181818182, 'f1': 0.7714285714285715, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1': 0.4444444444444444, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9530583214793741, 'recall': 0.9654178674351584, 'f1': 0.9591982820329277, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.954248366013072, 'recall': 0.958005249343832, 'f1': 0.9561231172233137, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.97953216374269, 'recall': 0.9882005899705014, 'f1': 0.9838472834067548, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780058651026393, 'recall': 0.9866863905325444, 'f1': 0.9823269513991164, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9468690702087287, 'recall': 0.9614643545279383, 'f1': 0.954110898661568, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9683794466403162, 'recall': 0.974155069582505, 'f1': 0.9712586719524281, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5625, 'f1': 0.4864864864864864, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.38636363636363635, 'recall': 0.5666666666666667, 'f1': 0.4594594594594595, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9375, 'recall': 0.9090909090909091, 'f1': 0.923076923076923, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1': 0.26666666666666666, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9656652360515021, 'recall': 0.9726224783861671, 'f1': 0.9691313711414213, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9496124031007752, 'recall': 0.9645669291338582, 'f1': 0.95703125, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9838945827232797, 'recall': 0.9911504424778761, 'f1': 0.9875091844232182, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9808541973490427, 'recall': 0.985207100591716, 'f1': 0.9830258302583026, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9236499068901304, 'recall': 0.9556840077071291, 'f1': 0.9393939393939394, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9494163424124513, 'recall': 0.9701789264413518, 'f1': 0.95968534906588, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.34782608695652173, 'recall': 0.5, 'f1': 0.41025641025641024, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.36363636363636365, 'recall': 0.5333333333333333, 'f1': 0.43243243243243246, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9393939393939394, 'recall': 0.9393939393939394, 'f1': 0.9393939393939394, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9572039942938659, 'recall': 0.9668587896253602, 'f1': 0.9620071684587814, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944516129032258, 'recall': 0.9606299212598425, 'f1': 0.9525048796356538, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9780701754385965, 'recall': 0.9867256637168141, 'f1': 0.9823788546255506, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9720588235294118, 'recall': 0.977810650887574, 'f1': 0.9749262536873157, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9146567717996289, 'recall': 0.9499036608863198, 'f1': 0.9319470699432891, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9314285714285714, 'recall': 0.9721669980119284, 'f1': 0.9513618677042801, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.25, 'f1': 0.26666666666666666, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2894736842105263, 'recall': 0.36666666666666664, 'f1': 0.32352941176470584, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8, 'recall': 0.8484848484848485, 'f1': 0.823529411764706, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2857142857142857, 'recall': 0.3333333333333333, 'f1': 0.30769230769230765, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943502824858757, 'recall': 0.962536023054755, 'f1': 0.9529243937232525, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944516129032258, 'recall': 0.9606299212598425, 'f1': 0.9525048796356538, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824304538799414, 'recall': 0.9896755162241888, 'f1': 0.9860396767083027, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.42857142857142855, 'f1': 0.5454545454545454, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9779086892488954, 'recall': 0.9822485207100592, 'f1': 0.9800738007380073, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9099264705882353, 'recall': 0.953757225433526, 'f1': 0.9313264346190028, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9549019607843138, 'recall': 0.9681908548707754, 'f1': 0.9615004935834156, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.23529411764705882, 'recall': 0.5, 'f1': 0.31999999999999995, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3090909090909091, 'recall': 0.5666666666666667, 'f1': 0.39999999999999997, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9117647058823529, 'recall': 0.9393939393939394, 'f1': 0.9253731343283583, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.3333333333333333, 'f1': 0.3636363636363636, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9613733905579399, 'recall': 0.968299711815562, 'f1': 0.964824120603015, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9442282749675746, 'recall': 0.9553805774278216, 'f1': 0.949771689497717, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9809384164222874, 'recall': 0.9867256637168141, 'f1': 0.9838235294117647, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 1.0, 'recall': 0.42857142857142855, 'f1': 0.6, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400\n",
      "Configuration saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/config.json\n",
      "Model weights saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1300] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-900 (score: 0.9663808664259927).\n",
      "Deleting older checkpoint [/work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1685\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9407971864009379, 'recall': 0.9525222551928784, 'f1': 0.946623414921852, 'number': 1685}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.860726643598616, 'recall': 0.9095063985374772, 'f1': 0.8844444444444446, 'number': 1094}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9138257575757576, 'recall': 0.9359844810863239, 'f1': 0.9247724005749881, 'number': 1031}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.3, 'recall': 0.47619047619047616, 'f1': 0.3680981595092025, 'number': 63}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.31654676258992803, 'recall': 0.5569620253164557, 'f1': 0.40366972477064217, 'number': 79}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.72, 'recall': 0.8372093023255814, 'f1': 0.7741935483870969, 'number': 43}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.53125, 'recall': 0.5151515151515151, 'f1': 0.5230769230769231, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9396503102086858, 'recall': 0.9536348025186033, 'f1': 0.9465909090909091, 'number': 1747}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456159822419534, 'recall': 0.9530201342281879, 'f1': 0.9493036211699164, 'number': 1788}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9778283115406481, 'recall': 0.9822958309537407, 'f1': 0.9800569800569802, 'number': 1751}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.45454545454545453, 'recall': 0.35714285714285715, 'f1': 0.4, 'number': 14}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 676\n",
      "  Batch size = 16\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O+O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/lrde/home2/stual/.venv/python_3_9/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9750367107195301, 'recall': 0.9822485207100592, 'f1': 0.978629329403095, 'number': 676}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9314814814814815, 'recall': 0.9691714836223507, 'f1': 0.9499527856468366, 'number': 519}\" of type <class 'dict'> for key \"eval/ACT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9518304431599229, 'recall': 0.9821073558648111, 'f1': 0.9667318982387475, 'number': 503}\" of type <class 'dict'> for key \"eval/ACT_L1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.5625, 'f1': 0.4864864864864864, 'number': 16}\" of type <class 'dict'> for key \"eval/ACT_L2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.36585365853658536, 'recall': 0.5, 'f1': 0.4225352112676056, 'number': 30}\" of type <class 'dict'> for key \"eval/DESC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8205128205128205, 'recall': 0.9696969696969697, 'f1': 0.8888888888888888, 'number': 33}\" of type <class 'dict'> for key \"eval/TITREH\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'number': 6}\" of type <class 'dict'> for key \"eval/TITREP\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9614835948644793, 'recall': 0.9711815561959655, 'f1': 0.9663082437275986, 'number': 694}\" of type <class 'dict'> for key \"eval/SPAT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.953185955786736, 'recall': 0.9619422572178478, 'f1': 0.9575440888308295, 'number': 762}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9824046920821115, 'recall': 0.9882005899705014, 'f1': 0.9852941176470589, 'number': 678}\" of type <class 'dict'> for key \"eval/CARDINAL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4, 'recall': 0.2857142857142857, 'f1': 0.3333333333333333, 'number': 7}\" of type <class 'dict'> for key \"eval/FT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/TITRE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time is equal to 0:08:59.110869\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "if RUN_PTRN_CAMEMBERT_IOB2:\n",
    "    assert _convert_tokenizer.name_or_path == MODEL\n",
    "    \n",
    "    # MODEL CONSTS\n",
    "    MODEL_METRICS_DIR = METRICS_OUTPUT_DIR / f\"{FOLDER}\"\n",
    "    MODEL_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    MODEL_OUTPUT_MODEL_PATH = OUT_BASE / f\"tmp/{FOLDER}\"\n",
    "    MODEL_METRICS_DIR, MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Set config output dir\n",
    "    local_config = TRAINING_CONFIG.copy() \n",
    "    local_config[\"output_dir\"]=MODEL_OUTPUT_MODEL_PATH\n",
    "\n",
    "    # Run the main loop\n",
    "    h = time.time()\n",
    "    train_bert(MODEL_METRICS_DIR)\n",
    "    runtime = (time.time()- h)/N_RUNS\n",
    "    print(f\"Run-time is equal to {str(datetime.timedelta(seconds=runtime))}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipped finetuning pretrained model for IOB2 labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c3379a1",
   "metadata": {},
   "source": [
    "Best model : /work/stual/res_ICDAR/method_3/tmp/324-pretrained-camembert-ner-hierarchical-loss-iob2/checkpoint-1200 (score: 0.9669710291962574)\n",
    "Rin time : 06:49"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
